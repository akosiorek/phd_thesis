{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_files = glob.glob('text/**/*.tex', recursive=True)\n",
    "ref_pattern = re.compile(r'\\\\cite[t|p]?{([\\w,]+)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bib_key(bib_key):\n",
    "    return ''.join([word.lower().capitalize() for word in bib_key.replace('-', '_').split('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_refs(tex_content):\n",
    "    found_refs = ref_pattern.findall(tex_content)\n",
    "    \n",
    "    all_refs = set()\n",
    "    for ref in found_refs:\n",
    "        all_refs = all_refs.union(set(ref.split(',')))\n",
    "        \n",
    "    return all_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_used_refs = set()\n",
    "\n",
    "for tex_file in tex_files:\n",
    "    tex_file_content = open(tex_file).read()\n",
    "    all_used_refs = all_used_refs.union(extract_refs(tex_file_content))\n",
    "    \n",
    "all_used_refs = sorted(list(set([format_bib_key(ref) for ref in all_refs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adams2010learning',\n",
       " 'Adc',\n",
       " 'Ae',\n",
       " 'Ba2016layern',\n",
       " 'Bae2017confidence',\n",
       " 'Bamler2017perturbative',\n",
       " 'Bamlerperturbative2017',\n",
       " 'Battaglia2016',\n",
       " 'Bengio2009',\n",
       " 'Bewley2016sort',\n",
       " 'Blei2003latent',\n",
       " 'Bomultrasonic1971',\n",
       " 'Booth1973applying',\n",
       " 'Bornschein2015reweighted',\n",
       " 'Bourlard1988auto',\n",
       " 'Brabandere2016dfn',\n",
       " 'Bravatasystematic2007',\n",
       " 'Burda2015importance',\n",
       " 'Burda2016',\n",
       " 'Burda2016importance',\n",
       " 'Burgess2019monet',\n",
       " 'Chater2006probabilistic',\n",
       " 'Chatterjee2018sample',\n",
       " 'Chen2014fast',\n",
       " 'Chen2016variational',\n",
       " 'Chen2018stochastic',\n",
       " 'Cheung2016gtc',\n",
       " 'Cho2015unsupervised',\n",
       " 'Chung2015',\n",
       " 'Clevert2015elu',\n",
       " 'Cohen2016group',\n",
       " 'Cohen2016steerable',\n",
       " 'Cremer2017reinterpreting',\n",
       " 'Danesh19',\n",
       " 'Dayan1995helmholtz',\n",
       " 'Dayan2001',\n",
       " 'Dempster1977maximum',\n",
       " 'Denton2017unsupervised',\n",
       " 'Dronedataset',\n",
       " 'Duarte',\n",
       " 'Earley1970efficient',\n",
       " 'Edlerultrasonic1957',\n",
       " 'Encapsule',\n",
       " 'Eslami2016',\n",
       " 'Eslami2016attend',\n",
       " 'Eth',\n",
       " 'Footdemographics2000',\n",
       " 'Fort2017mcmc',\n",
       " 'Gael2009',\n",
       " 'Gagliardicardiac1996',\n",
       " 'Gagliardirontgen1996',\n",
       " 'Gagliardiultrasonography1996',\n",
       " 'Gan',\n",
       " 'Geiger2013',\n",
       " 'Goodfellow2014generative',\n",
       " 'Gordon2017',\n",
       " 'Gordon2018',\n",
       " 'Grathwohl2018backpropagation',\n",
       " 'Graves2014neural',\n",
       " 'Graves2014recurrent',\n",
       " 'Graves2016',\n",
       " 'Graves2016hybrid',\n",
       " 'Grefenstette2015learning',\n",
       " 'Greff2016tagger',\n",
       " 'Greff2017neuralem',\n",
       " 'Greff2019multi',\n",
       " 'Gregor2016towards',\n",
       " 'Griffithsector1974',\n",
       " 'Gu2016muprop',\n",
       " 'Gulrajani2016pixelvae',\n",
       " 'Gutmann2010nce',\n",
       " 'Ha2018worldm',\n",
       " 'Harveyexercitatio1628',\n",
       " 'Held2016',\n",
       " 'Held2016goturn',\n",
       " 'Hesterberg1988advances',\n",
       " 'Hesterberg1995weighted',\n",
       " 'Hinton1994autoencoders',\n",
       " 'Hinton1995wake',\n",
       " 'Hinton2011tae',\n",
       " 'Hinton2015rmsprop',\n",
       " 'Hinton2018capsule',\n",
       " 'Hjelm2019deepinfomax',\n",
       " 'Hologan',\n",
       " 'Hsieh2018ddpae',\n",
       " 'Igp',\n",
       " 'Iic',\n",
       " 'Ilin2017recurrentln',\n",
       " 'Ilsvrc15',\n",
       " 'Imsat',\n",
       " 'Itseez2015opencv',\n",
       " 'Jacobsen2016struc',\n",
       " 'Jacobsen2017dynamic',\n",
       " 'Jaderberg2015',\n",
       " 'Jaderberg2016',\n",
       " 'Jaiswal',\n",
       " 'Jang2017categorical',\n",
       " 'Juang1991hidden',\n",
       " 'Kahou15',\n",
       " 'Kahou2015ratm',\n",
       " 'Karl2017',\n",
       " 'Kemp2006learning',\n",
       " 'Kemp2008discovery',\n",
       " 'Kendall2017adaptive',\n",
       " 'Keuper2018motion',\n",
       " 'Kim2018disentangling',\n",
       " 'Kingma2013auto',\n",
       " 'Kingma2014adam',\n",
       " 'Kingma2014auto',\n",
       " 'Kingma2015adam',\n",
       " 'Kingma2016improving',\n",
       " 'Klein2003parsing',\n",
       " 'Kocvok',\n",
       " 'Kosiorek17',\n",
       " 'Kosiorek2017hierch',\n",
       " 'Kosiorek2018sequential',\n",
       " 'Kosiorek2018sqair',\n",
       " 'Krizhevsky2012',\n",
       " 'Krueger2016',\n",
       " 'Kthactivityrecognition',\n",
       " 'Kuhn1955hungarian',\n",
       " 'Kwak2015unsupervised',\n",
       " 'Lake2018emergence',\n",
       " 'Lalonde',\n",
       " 'Lari1990estimation',\n",
       " 'Le2017auto',\n",
       " 'Le2017inference',\n",
       " 'Le2018autoencoding',\n",
       " 'Lecun1989backpropagation',\n",
       " 'Lecun1998gradient',\n",
       " 'Lecun2015deep',\n",
       " 'Lee2019set',\n",
       " 'Lee2019settransformer',\n",
       " 'Leesoncardiovascular2011',\n",
       " 'Lenssen',\n",
       " 'Li2016renyi',\n",
       " 'Maaloeauxiliary2016',\n",
       " 'Maddison2017concrete',\n",
       " 'Maddison2017filtering',\n",
       " 'Mallat',\n",
       " 'Manning1999foundations',\n",
       " 'Mcbook',\n",
       " 'Milan2014',\n",
       " 'Minka2005divergence',\n",
       " 'Mnih2014',\n",
       " 'Mnih2014neural',\n",
       " 'Mnih2016',\n",
       " 'Mnih2016variational',\n",
       " 'Mohamed2016learning',\n",
       " 'Mot16',\n",
       " 'Naesseth2017variational',\n",
       " 'Nam2016',\n",
       " 'Neal1992connectionist',\n",
       " 'Neiswanger2012unsupervised',\n",
       " 'Neiswanger2014dependent',\n",
       " 'Ning2016',\n",
       " 'Ning2017',\n",
       " 'Olshausen2016foveal',\n",
       " 'Oord2016cond',\n",
       " 'Osep2017',\n",
       " 'Otb',\n",
       " 'Paige2016inference',\n",
       " 'Posner2016',\n",
       " 'Rainforth2017opportunities',\n",
       " 'Rainforth2017thesis',\n",
       " 'Rainforth2018tighter',\n",
       " 'Ranganath2016hierarchical',\n",
       " 'Ranzato2014video',\n",
       " 'Rasmus2015ladder',\n",
       " 'Rasmussen2000infinite',\n",
       " 'Redmon15',\n",
       " 'Rezende2014stochastic',\n",
       " 'Rezendevariational2015',\n",
       " 'Ristani2016performance',\n",
       " 'Robbins1951stochastic',\n",
       " 'Roberts2009signal',\n",
       " 'Rolfe2016dvae',\n",
       " 'Rudenko2018joint',\n",
       " 'Sabour2017capsule',\n",
       " 'Salimansmarkov2015',\n",
       " 'Santoro2017',\n",
       " 'Saqur',\n",
       " 'Savarese2016goturn',\n",
       " 'Scholler2019simpler',\n",
       " 'Schulter2017deepnf',\n",
       " 'Shi2016subpixel',\n",
       " 'Sisson2018handbook',\n",
       " 'Sonderbyladder2016',\n",
       " 'Sousanew2005',\n",
       " 'Sparsecaps',\n",
       " 'Srivastava2015unsupervised',\n",
       " 'Steenkiste2018',\n",
       " 'Steenkiste2018relationalnem',\n",
       " 'Stollenga2014',\n",
       " 'Sun20183dof',\n",
       " 'Tieleman2012rms',\n",
       " 'Tieleman2014thesis',\n",
       " 'Tranvariational2015',\n",
       " 'Tucker2017rebar',\n",
       " 'Tucker2019doubly',\n",
       " 'Tulyakov2017mocogan',\n",
       " 'Turner2011two',\n",
       " 'Ucy',\n",
       " 'Ungerleider2000',\n",
       " 'Upadhyay',\n",
       " 'Vahdat2018dvaehash',\n",
       " 'Vahdat2018dvaepp',\n",
       " 'Valmadre2017',\n",
       " 'Valmadre2017cfnn',\n",
       " 'Valmadre2017corr',\n",
       " 'Valmadre2017end',\n",
       " 'Varshneya2017human',\n",
       " 'Vaswani17',\n",
       " 'Vinyals2014',\n",
       " 'Vongoethewilhelm1829',\n",
       " 'Vot2016',\n",
       " 'Wagstaff2019',\n",
       " 'Wang2018optimization',\n",
       " 'Watters2017',\n",
       " 'Webbintroduction2002',\n",
       " 'Weber2017imagination',\n",
       " 'Wen15',\n",
       " 'Williams1992simple',\n",
       " 'Xiang2015',\n",
       " 'Xiao2016track',\n",
       " 'Xu2015show',\n",
       " 'Yamaguchi2011you',\n",
       " 'Younger1967recognition',\n",
       " 'Yu2016unitbox',\n",
       " 'Zaheer2017',\n",
       " 'Zaheer2017deeps',\n",
       " 'Zhang2008',\n",
       " 'Zhang2018fast',\n",
       " 'Zhao20183d']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_used_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text/MOHART/library.bib', 'text/SCA/library.bib', 'text/RRWS/main.bib', 'text/SQAIR/library.bib', 'text/HART/library.bib', 'text/tighter_bounds/refs.bib', 'text/tighter_bounds/max.bib']\n"
     ]
    }
   ],
   "source": [
    "bib_files = glob.glob('text/**/*.bib', recursive=True)\n",
    "print(bib_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bib = '\\n'.join(open(bib_file).read() for bib_file in bib_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_entries = []\n",
    "\n",
    "for entry in master_bib.split('@'):\n",
    "    entry = entry.strip()\n",
    "    if entry:\n",
    "#         print(entry)\n",
    "        bib_entries.append('@' + entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None [] @mit.edu  },\n",
      "title = {{Learning Chaotic Attractors by Neural Networks}},\n",
      "opturl = {http://www.mitpressjournals.org/optdoi/10.1162/089976600300014971},\n",
      "volume = {12},\n",
      "year = {2000}\n",
      "}\n",
      "None [] @mit.edu},\n",
      "title = {{A Fast Learning Algorithm for Deep Belief Nets}},\n",
      "opturl = {http://www.mitpressjournals.org/optdoi/10.1162/neco.2006.18.7.1527},\n",
      "volume = {18},\n",
      "year = {2006}\n",
      "}\n",
      "None [] @article{\n",
      "\tanonymous2018auto-encoding,\n",
      "\ttitle={Auto-Encoding Sequential Monte Carlo},\n",
      "\tauthor={Anonymous},\n",
      "\tjournal={International Conference on Learning Representations},\n",
      "\tyear={2018}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "formatted_bib_entries = dict()\n",
    "ref_map = dict()\n",
    "\n",
    "key_pattern = re.compile(r'@\\w+{([\\w-]+),')\n",
    "for entry in bib_entries:\n",
    "    found_key = key_pattern.findall(entry)\n",
    "    if not found_key:\n",
    "        print('None', found_key, entry)\n",
    "    else:\n",
    "        found_key = found_key[0]\n",
    "        target_key = format_bib_key(found_key)\n",
    "#         print(found_key, target_key)\n",
    "        \n",
    "        entry = entry.replace(found_key, target_key)\n",
    "        formatted_bib_entries[target_key] = entry\n",
    "        \n",
    "        if found_key != target_key:\n",
    "            ref_map[found_key] = target_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kosiorek17': '@article{Kosiorek17,\\n  author    = {Adam R. Kosiorek and\\n               Alex Bewley and\\n               Ingmar Posner},\\n  title     = {Hierarchical Attentive Recurrent Tracking},\\n  journal   = {Neural Information Processing Systems},\\n  year      = {2017},\\n}',\n",
       " 'Vaswani17': '@article{Vaswani17,\\n  author    = {Ashish Vaswani and\\n               Noam Shazeer and\\n               Niki Parmar and\\n               Jakob Uszkoreit and\\n               Llion Jones and\\n               Aidan N. Gomez and\\n               Lukasz Kaiser and\\n               Illia Polosukhin},\\n  title     = {Attention Is All You Need},\\n  journal   = {Neural Information Processing Systems},\\n  year      = {2017}\\n}',\n",
       " 'Kahou15': '@article{Kahou15,\\n  author    = {Samira Ebrahimi Kahou and\\n               Vincent Michalski and\\n               Roland Memisevic},\\n  title     = {{RATM:} Recurrent Attentive Tracking Model},\\n  journal   = {IEEE Conference on Computer Vision and Pattern Recognition Workshops},\\n  year      = {2017}\\n}',\n",
       " 'Redmon15': '@article{Redmon15,\\n  author    = {Joseph Redmon and\\n               Santosh Kumar Divvala and\\n               Ross B. Girshick and\\n               Ali Farhadi},\\n  title     = {You Only Look Once: Unified, Real-Time Object Detection},\\n  journal   = {Conference on Computer Vision and Pattern Recognition},\\n  year      = {2016},\\n}',\n",
       " 'Gordon17': '@article{Gordon17,\\n  author    = {Daniel Gordon and\\n               Ali Farhadi and\\n               Dieter Fox},\\n  title     = {Re3 : Real-Time Recurrent Regression Networks for Object Tracking},\\n  journal   = {IEEE Robotics and Automation Letters},\\n  year      = {2018},\\n}',\n",
       " 'Mot16': \"@article{Mot16,\\n\\ttitle = {{MOT}16: {A} Benchmark for Multi-Object Tracking},\\n\\tshorttitle = {Mot16},\\n\\tauthor = {Milan, A. and Leal-Taix\\\\'{e}, L. and Reid, I. and Roth, S. and Schindler, K.},\\n\\tyear = {2016},\\n\\tnote = {arXiv: 1603.00831},\\n\\tkeywords = {Computer Science - Computer Vision and Pattern Recognition}\\n}\",\n",
       " 'Wen15': '@article{Wen15,\\n  author    = {Longyin Wen and\\n               Dawei Du and\\n               Zhaowei Cai and\\n               Zhen Lei and\\n               Ming{-}Ching Chang and\\n               Honggang Qi and\\n               Jongwoo Lim and\\n               Ming{-}Hsuan Yang and\\n               Siwei Lyu},\\n  title     = {{DETRAC:} {A} New Benchmark and Protocol for Multi-Object Tracking},\\n  journal   = {arXiv},\\n  volume    = {1511.04136},\\n  year      = {2015},\\n  timestamp = {Mon, 13 Aug 2018 16:49:08 +0200},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}',\n",
       " 'Held2016goturn': '@inproceedings{Held2016goturn,\\n  title={Learning to track at 100 fps with deep regression networks},\\n  author={Held, David and Thrun, Sebastian and Savarese, Silvio},\\n  booktitle={European Conference on Computer Vision},\\n  year={2016},\\n}',\n",
       " 'Valmadre2017corr': '@article{Valmadre2017corr,\\n  title={End-to-End Representation Learning for Correlation Filter Based Tracking},\\n  author={Jack Valmadre and Luca Bertinetto and Jo{\\\\~a}o F. Henriques and Andrea Vedaldi and Philip Hilaire Sean Torr},\\n  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\\n  year={2017},\\n}',\n",
       " 'Zaheer2017': \"@inproceedings{Zaheer2017,\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1703.06114v3},\\nauthor = {Zaheer, Manzil and Kottur, Satwik and Ravanbhakhsh, Siamak and P{\\\\'{o}}czos, Barnab{\\\\'{a}}s and Salakhutdinov, Ruslan and Smola, Alexander},\\nbooktitle = {Advances in Neural Information Processing Systems},\\neprint = {arXiv:1703.06114v3},\\ntitle = {{Deep Sets}},\\nyear = {2017}\\n}\",\n",
       " 'Wagstaff2019': '@article{Wagstaff2019,\\n  author    = {Edward Wagstaff and\\n               Fabian B. Fuchs and\\n               Martin Engelcke and\\n               Ingmar Posner and\\n               Michael A. Osborne},\\n  title     = {On the Limitations of Representing Functions on Sets},\\n  journal   = {International Conference on Machine Learning},\\n  year      = {2019},\\n}',\n",
       " 'Gupta2019': '@article{Gupta2019,\\n  author    = {Agrim Gupta and\\n               Justin Johnson and\\n               Li Fei{-}Fei and\\n               Silvio Savarese and\\n               Alexandre Alahi},\\n  title     = {Social {GAN:} Socially Acceptable Trajectories with Generative Adversarial\\n               Networks},\\n  journal   = {IEEE/CVF Conference on Computer Vision and Pattern Recognition},\\n  year      = {2018},\\n}',\n",
       " 'Dronedataset': '@article{Dronedataset,\\n  author    = {A. Robicquet and\\n               A. Sadeghian and\\n               A. Alahi and\\n               S. Savaresei},\\n  title     = { Learning Social Etiquette: Human Trajectory Prediction In Crowded Scenes},\\n  journal   = {European Conference on Computer Vision},\\n  year      = {2016},\\n}',\n",
       " 'Gordon2018': '@article{Gordon2018,\\narchivePrefix = {arXiv},\\nauthor = {Gordon, Daniel and Farhadi, Ali and Fox, Dieter},\\njournal = {RA-L},\\ntitle = {{Re3 : Real-Time Recurrent Regression Networks for Visual Tracking of Generic Objects}},\\nyear = {2018}\\n}',\n",
       " 'Nam2016': '@article{Nam2016,\\nauthor = {Nam, Hyeonseob and Han, Bohyung},\\njournal = {CVPR},\\ntitle = {{Learning Multi-Domain Convolutional Neural Networks for Visual Tracking}},\\nyear = {2016}\\n}',\n",
       " 'Ning2017': '@article{Ning2017,\\nauthor = {Ning, Guanghan and Zhang, Zhi and Huang, Chen and He, Zhihai and Ren, Xiaobo and Wang, Haohong},\\njournal = {ISCAS},\\ntitle = {{Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking}},\\nyear = {2017}\\n}',\n",
       " 'Xiang2015': '@article{Xiang2015,\\nauthor = {Xiang, Yu and Alahi, Alexandre and Savarese, Silvio},\\njournal = {ICCV},\\ntitle = {{Learning to Track: Online Multi- Object Tracking by Decision Making Multi-Object Tracking}},\\nyear = {2015}\\n}',\n",
       " 'Milan2014': '@article{Milan2014,\\nauthor = {Milan, Anton and Roth, Stefan and Schindler, Konrad},\\njournal = {PAMI},\\nkeywords = {Continuous optimization,Multiobject tracking,Tracking-by-detection,Visual surveillance},\\ntitle = {{Continuous energy minimization for multitarget tracking}},\\nyear = {2014}\\n}',\n",
       " 'Zhang2008': '@article{Zhang2008,\\nauthor = {Zhang, Li and Li, Yuan and Nevatia, Ramakant},\\njournal = {CVPR},\\ntitle = {{Global data association for multi-object tracking using network flows}},\\nyear = {2008}\\n}',\n",
       " 'Osep2017': '@article{Osep2017,\\nauthor = {O{\\\\v{s}}ep, Aljo{\\\\v{s}}a and Mehner, Wolfgang and Voigtlaender, Paul and Leibe, Bastian},\\njournal = {ICRA},\\ntitle = {{Track, then Decide: Category-Agnostic Vision-based Multi-Object Tracking}},\\nyear = {2018}\\n}',\n",
       " 'Posner2016': '@article{Posner2016,\\nauthor = {Peter Ondruska and Ingmar Posner},\\njournal = {AAAI},\\nkeywords = {Technical Papers: Robotics},\\ntitle = {{Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks}},\\nyear = {2016}\\n}',\n",
       " 'Santoro2018': '@article{Santoro2018,\\nauthor = {Santoro, Adam and Faulkner, Ryan and Raposo, David and Rae, Jack and Chrzanowski, Mike and Weber, Theophane and Wierstra, Daan and Vinyals, Oriol and Pascanu, Razvan and Lillicrap, Timothy},\\neprint = {1806.01822},\\njournal = {arXiv},\\ntitle = {{Relational recurrent neural networks}},\\nyear = {2018}\\n}',\n",
       " 'Battaglia2016': '@article{Battaglia2016,\\nabstract = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},\\narchivePrefix = {arXiv},\\narxivId = {1612.00222},\\nauthor = {Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and koray Kavukcuoglu},\\neprint = {1612.00222},\\noptissn = {10495258},\\njournal = {Nips},\\nmonth = {dec},\\npages = {4502--4510},\\ntitle = {{Interaction Networks for Learning about Objects, Relations and Physics}},\\nopturl = {http://arxiv.org/abs/1612.00222},\\nyear = {2016}\\n}',\n",
       " 'Lu2018': '@article{Lu2018,\\njournal = {Neuron},\\npublisher = {Elsevier Inc.},\\ntitle = {{Revealing Detail along the Visual Hierarchy: Neural Clustering Preserves Acuity from V1 to V4}},\\nyear = {2018}\\n}',\n",
       " 'Santoro2017': '@article{Santoro2017,\\nabstract = {Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.},\\narchivePrefix = {arXiv},\\narxivId = {1706.01427},\\nauthor = {Santoro, Adam and Raposo, David and Barrett, David G.T. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},\\neprint = {1706.01427},\\njournal = {Arxiv},\\nmonth = {jun},\\npages = {1--16},\\ntitle = {{A simple neural network module for relational reasoning}},\\nopturl = {http://arxiv.org/abs/1706.01427 https://arxiv.org/abs/1706.01427},\\nyear = {2017}\\n}',\n",
       " 'Willems2007': '@article{Willems2007,\\nauthor = {Willems, Jan},\\njournal = {IEEE Control Systems Magazine},\\ntitle = {{The Behavioral Approach to Open and Interconnected Systems}},\\nurl = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4384643{\\\\%}5Cnpapers2://publication/doi/10.1109/MCS.2007.906923},\\nyear = {2007}\\n}',\n",
       " 'Watters2017': '@article{Watters2017,\\nauthor = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},\\njournal = {NIPS},\\ntitle = {{Visual Interaction Networks: Learning a Physics Simulator from Video}},\\nyear = {2017}\\n}\\n\\n\\n% trajectory prediction',\n",
       " 'Li2019way': '@inproceedings{Li2019way,\\n  title={Which Way Are You Going? Imitative Decision Learning for Path Forecasting in Dynamic Scenes},\\n  author={Li, Yuke},\\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\\n  year={2019}\\n}\\n% social behavior',\n",
       " 'Su2016crowd': '@inproceedings{Su2016crowd,\\n  title={Crowd Scene Understanding with Coherent Recurrent Neural Networks.},\\n  author={Su, Hang and Dong, Yinpeng and Zhu, Jun and Ling, Haibin and Zhang, Bo},\\n  year={2016}\\n}',\n",
       " 'Fernando2018soft': '@article{Fernando2018soft,\\n  title={Soft+ hardwired attention: An lstm framework for human trajectory prediction and abnormal event detection},\\n  author={Fernando, Tharindu and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},\\n  journal={Neural networks},\\n  year={2018},\\n  publisher={Elsevier}\\n}',\n",
       " 'Vemula2018social': '@inproceedings{Vemula2018social,\\n  title={Social attention: Modeling attention in human crowds},\\n  author={Vemula, Anirudh and Muelling, Katharina and Oh, Jean},\\n  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},\\n  year={2018},\\n  organization={IEEE}\\n}',\n",
       " 'Choi2019learning': '@inproceedings{Choi2019learning,\\n  title={Learning to Infer Relations for Future Trajectory Forecast},\\n  author={Choi, Chiho and Dariush, Behzad},\\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},\\n  year={2019}\\n}',\n",
       " 'Zhang2019sr': '@inproceedings{Zhang2019sr,\\n  title={SR-LSTM: State Refinement for LSTM towards Pedestrian Trajectory Prediction},\\n  author={Zhang, Pu and Ouyang, Wanli and Zhang, Pengfei and Xue, Jianru and Zheng, Nanning},\\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\\n  year={2019}\\n}\\n\\n% Interactions learning',\n",
       " 'Sadeghian2019sophie': '@inproceedings{Sadeghian2019sophie,\\n  title={Sophie: An attentive gan for predicting paths compliant to social and physical constraints},\\n  author={Sadeghian, Amir and Kosaraju, Vineet and Sadeghian, Ali and Hirose, Noriaki and Rezatofighi, Hamid and Savarese, Silvio},\\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\\n  year={2019}\\n}\\n\\n% end to end',\n",
       " 'Varshneya2017human': '@article{Varshneya2017human,\\n  title={Human trajectory prediction using spatially aware deep attention models},\\n  author={Varshneya, Daksh and Srinivasaraghavan, G},\\n  journal={arXiv preprint:1705.09436},\\n  year={2017}\\n}',\n",
       " 'Scholler2019simpler': '@article{Scholler2019simpler,\\n  title={The Simpler the Better: Constant Velocity for Pedestrian Motion Prediction},\\n  author={Sch{\\\\\"o}ller, Christoph and Aravantinos, Vincent and Lay, Florian and Knoll, Alois},\\n  journal={arXiv preprint arXiv:1903.07933},\\n  year={2019}\\n}\\n\\n% old literatures',\n",
       " 'Ucy': '@inproceedings{Ucy,\\n  title={Crowds by example},\\n  author={Lerner, Alon and Chrysanthou, Yiorgos and Lischinski, Dani},\\n  booktitle={Computer Graphics Forum},\\n  year={2007}\\n}',\n",
       " 'Eth': \"@inproceedings{Eth,\\n  title={You'll never walk alone: Modeling social behavior for multi-target tracking},\\n  author={Pellegrini, Stefano and Ess, Andreas and Schindler, Konrad and Van Gool, Luc},\\n  booktitle={ICCV 2009}\\n}\",\n",
       " 'Grewal2011kalman': '@incollection{Grewal2011kalman,\\n  title={Kalman filtering},\\n  author={Grewal, Mohinder S},\\n  booktitle={International Encyclopedia of Statistical Science},\\n  year={2011}\\n}',\n",
       " 'Igp': '@inproceedings{Igp,\\n  title={Unfreezing the robot: Navigation in dense, interacting crowds},\\n  author={Trautman, Peter and Krause, Andreas},\\n  booktitle={IROS},\\n  year={2010}\\n}',\n",
       " 'Rudenko2018joint': '@inproceedings{Rudenko2018joint,\\n  title={Joint long-term prediction of human motion using a planning-based social force approach},\\n  author={Rudenko, Andrey and Palmieri, Luigi and Arras, Kai O},\\n  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},\\n  year={2018},\\n  organization={IEEE}\\n}',\n",
       " 'Yamaguchi2011you': '@inproceedings{Yamaguchi2011you,\\n  title={Who are you with and where are you going?},\\n  author={Yamaguchi, Kota and Berg, Alexander C and Ortiz, Luis E and Berg, Tamara L},\\n  booktitle={CVPR},\\n  year={2011}\\n}',\n",
       " 'SocialLstm': '@inproceedings{SocialLstm,\\n  title={Social {LSTM}: Human trajectory prediction in crowded spaces},\\n  author={Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},\\n  booktitle={CVPR},\\n  year={2016}\\n}',\n",
       " 'Sun20183dof': '@inproceedings{Sun20183dof,\\n  title={3DOF pedestrian trajectory prediction learned from long-term autonomous mobile robot deployment data},\\n  author={Sun, Li and Yan, Zhi and Mellado, Sergi Molina and Hanheide, Marc and Duckett, Tom},\\n  booktitle={2018 IEEE International Conference on Robotics and Automation},\\n  year={2018},\\n  organization={IEEE}\\n}',\n",
       " 'Danesh19': '@article{Danesh19,\\nauthor = {Rasouli Danesh, Maryam and Yadav, Srishti and Herath, Sachini and Vaghei, Yasaman and Payandeh, Shahram},\\nyear = {2019},\\nmonth = {02},\\npages = {750},\\ntitle = {Deep Attention Models for Human Tracking Using RGBD},\\nvolume = {19},\\njournal = {Sensors},\\n}',\n",
       " 'Lee2019settransformer': '@inproceedings{Lee2019settransformer,\\n  title={Set transformer},\\n  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam R and Choi, Seungjin and Teh, Yee Whye},\\n  booktitle={International Conference on Machine Learning},\\n  year={2019}\\n}\\n\\n\\n% tracking by detection',\n",
       " 'Bae2017confidence': '@article{Bae2017confidence,\\n  title={Confidence-based data association and discriminative deep appearance learning for robust online multi-object tracking},\\n  author={Bae, Seung-Hwan and Yoon, Kuk-Jin},\\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\\n  year={2017},\\n}',\n",
       " 'Keuper2018motion': '@article{Keuper2018motion,\\n  title={Motion segmentation \\\\& multiple object tracking by correlation co-clustering},\\n  author={Keuper, Margret and Tang, Siyu and Andres, Bjorn and Brox, Thomas and Schiele, Bernt},\\n  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\\n  year={2018},\\n  publisher={IEEE}\\n}',\n",
       " 'Kosiorek2018sqair': '@inproceedings{Kosiorek2018sqair,\\n  title={Sequential Attend, Infer, Repeat: Generative modelling of moving objects},\\n  author={Kosiorek, Adam and Kim, Hyunjik and Teh, Yee Whye and Posner, Ingmar},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={8606--8616},\\n  archivePrefix = {arXiv},\\n  eprint = {1806.01794},\\n  year={2018}\\n}',\n",
       " 'Steenkiste2018': '@article{Steenkiste2018,\\n  author    = {Sjoerd van Steenkiste and\\n               Michael Chang and\\n               Klaus Greff and\\n               J{\\\\\"{u}}rgen Schmidhuber},\\n  title     = {Relational Neural Expectation Maximization: Unsupervised Discovery\\n               of Objects and their Interactions},\\n  journal   = {ICLR},\\n  year      = {2018},\\n}',\n",
       " 'Eslami2016': '@inproceedings{Eslami2016,\\nabstract = {We present a framework for efficient inference in structured image models that explicitly reason about objects. We achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time. Crucially, the model itself learns to choose the appropriate number of inference steps. We use this scheme to learn to perform inference in partially specified 2D models (variable-sized variational auto-encoders) and fully specified 3D models (probabilistic renderers). We show that such models learn to identify multiple objects - counting, locating and classifying the elements of a scene - without any supervision, e.g., decomposing 3D images with various numbers of objects in a single forward pass of a neural network. We further show that the networks produce accurate inferences when compared to supervised counterparts, and that their structure leads to improved generalization.},\\narchivePrefix = {arXiv},\\narxivId = {1603.08575},\\nauthor = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E.},\\nbooktitle = {NIPS},\\neprint = {1603.08575},\\noptissn = {10495258},\\ntitle = {{Attend, Infer, Repeat: Fast Scene Understanding with Generative Models}},\\nopturl = {http://arxiv.org/abs/1603.08575},\\nyear = {2016}\\n}',\n",
       " 'Gael2009': '@inproceedings{Gael2009,\\nabstract = {We introduce a new probability distribution over a potentially infinite number of binary Markov chains which we call the Markov Indian buffet process. This process extends the IBP to allow temporal dependencies in the hidden variables. We use this stochastic process to build a nonparametric extension of the factorial hidden Markov model. After constructing an inference scheme which combines slice sampling and dynamic programming we demonstrate how the infinite factorial hidden Markov model can be used for blind source separation.},\\nauthor = {Gael, Jurgen Van and Teh, Yee Whye and Ghahramani, Zoubin},\\nbooktitle = {NIPS},\\nfile = {:Users/adam/Documents/Mendeley/Gael, Teh, Ghahramani - 2009 - The Infinite Factorial Hidden Markov Model.pdf:pdf},\\nisbn = {9781605609492},\\npages = {1697--1704},\\ntitle = {{The Infinite Factorial Hidden Markov Model}},\\nurl = {https://papers.nips.cc/paper/3518-the-infinite-factorial-hidden-markov-model},\\nyear = {2009}\\n}',\n",
       " 'Graves2016': \"@article{Graves2016,\\nabstract = {Artificial neural networks are remarkably adept at sensory processing, sequence learning and reinforcement learning, but are limited in their ability to represent variables and data structures and to store data over long timescales, owing to the lack of an external memory. Here we introduce a machine learning model called a differentiable neural computer (DNC), which consists of a neural network that can read from and write to an external memory matrix, analogous to the random-access memory in a conventional computer. Like a conventional computer, it can use its memory to represent and manipulate complex data structures, but, like a neural network, it can learn to do so from data. When trained with supervised learning, we demonstrate that a DNC can successfully answer synthetic questions designed to emulate reasoning and inference problems in natural language. We show that it can learn tasks such as finding the shortest path between specified points and inferring the missing links in randomly generated graphs, and then generalize these tasks to specific graphs such as transport networks and family trees. When trained with reinforcement learning, a DNC can complete a moving blocks puzzle in which changing goals are specified by sequences of symbols. Taken together, our results demonstrate that DNCs have the capacity to solve complex, structured tasks that are inaccessible to neural networks without external readâ€“write memory.},\\nauthor = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\\\\'{n}}ska, Agnieszka and Colmenarejo, Sergio G{\\\\'{o}}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adri{\\\\`{a}} Puigdom{\\\\`{e}}nech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},\\noptissn = {0028-0836},\\njournal = {Nature},\\nmonth = {oct},\\nnumber = {7626},\\npages = {471--476},\\npublisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},\\ntitle = {{Hybrid computing using a neural network with dynamic external memory}},\\nopturl = {http://dx.optdoi.org/10.1038/nature20101 http://10.0.4.14/nature20101 http://www.nature.com/nature/journal/v538/n7626/abs/nature20101.html{\\\\#}supplementary-information},\\nvolume = {538},\\nyear = {2016}\\n}\",\n",
       " 'Jaderberg2015': '@inproceedings{Jaderberg2015,\\nabstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1506.02025v1},\\nauthor = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},\\nbooktitle = {NIPS},\\noptdoi = {10.1038/nbt.3343},\\neprint = {arXiv:1506.02025v1},\\noptisbn = {9781627480031},\\noptissn = {1087-0156},\\npmid = {26571099},\\ntitle = {{Spatial Transformer Networks}},\\nyear = {2015}\\n}',\n",
       " 'Kosiorek2017hierch': '@inproceedings{Kosiorek2017hierch,\\nabstract = {Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \"where\" and \"what\" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset.},\\narchivePrefix = {arXiv},\\narxivId = {1706.09262},\\nauthor = {Kosiorek, Adam R. and Bewley, Alex and Posner, Ingmar},\\nbooktitle = {NIPS},\\neprint = {1706.09262},\\nmonth = jun,\\ntitle = {{Hierarchical Attentive Recurrent Tracking}},\\nurl = {http://arxiv.org/abs/1706.09262},\\nyear = {2017}\\n}',\n",
       " 'Mnih2014': '@inproceedings{Mnih2014,\\nabstract = {Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference model gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1402.0030v2},\\nauthor = {Mnih, Andriy and Gregor, Karol},\\nbooktitle = {ICML},\\neprint = {arXiv:1402.0030v2},\\noptisbn = {9781634393973},\\nkeywords = {belief networks,deep learning,variational inference},\\nmonth = {jan},\\ntitle = {{Neural Variational Inference and Learning in Belief Networks}},\\nopturl = {http://arxiv.org/abs/1402.0030},\\nyear = {2014}\\n}',\n",
       " 'Mnih2016': '@inproceedings{Mnih2016,\\nabstract = {Recent progress in deep latent variable models has largely been driven by the development of flexible and scalable variational inference methods. Variational training of this type involves maximizing a lower bound on the log-likelihood, using samples from the variational posterior to compute the required gradients. Recently, Burda et al. (2016) have derived a tighter lower bound using a multi-sample importance sampling estimate of the likelihood and showed that optimizing it yields models that use more of their capacity and achieve higher likelihoods. This development showed the importance of such multi-sample objectives and explained the success of several related approaches. We extend the multi-sample approach to discrete latent variables and analyze the difficulty encountered when estimating the gradients involved. We then develop the first unbiased gradient estimator designed for importance-sampled objectives and evaluate it at training generative and structured output prediction models. The resulting estimator, which is based on low-variance per-sample learning signals, is both simpler and more effective than the NVIL estimator proposed for the single-sample variational objective, and is competitive with the currently used biased estimators.},\\narchivePrefix = {arXiv},\\narxivId = {1602.06725},\\nauthor = {Mnih, Andriy and Rezende, Danilo J.},\\nbooktitle = {ICML},\\neprint = {1602.06725},\\nissn = {1938-7228},\\nmonth = feb,\\ntitle = {{Variational inference for Monte Carlo objectives}},\\nurl = {http://arxiv.org/abs/1602.06725},\\nyear = {2016}\\n}',\n",
       " 'Burda2016': \"@inproceedings{Burda2016,\\nabstract = {The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.},\\narchivePrefix = {arXiv},\\neprint = {1509.00519},\\nauthor = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},\\nbooktitle = {ICLR},\\nissn = {1312.6114v10},\\nmonth = sep,\\ntitle = {{Importance Weighted Autoencoders}},\\nurl = {http://arxiv.org/abs/1509.00519},\\nyear = {2016}\\n}\",\n",
       " 'Chung2015': '@inproceedings{Chung2015,\\nabstract = {In this paper, we explore the inclusion of latent random variables into the dynamic hidden state of a recurrent neural network (RNN) by combining elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamic hidden state.},\\narchivePrefix = {arXiv},\\narxivId = {1506.02216},\\nauthor = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron and Bengio, Yoshua},\\nbooktitle = {NIPS},\\neprint = {1506.02216},\\nissn = {10495258},\\nmonth = jun,\\ntitle = {{A Recurrent Latent Variable Model for Sequential Data}},\\nurl = {http://arxiv.org/abs/1506.02216},\\nyear = {2015}\\n}',\n",
       " 'Krizhevsky2012': '@inproceedings{Krizhevsky2012,\\nauthor = {{A. Krizhevsky} and {I. Sutskever} and Hinton, Geoffrey E.},\\nbooktitle = {NIPS},\\npages = {1097--1105},\\ntitle = {{ImageNet Classification with Deep Convolutional Neural Networks}},\\nopturl = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks},\\nyear = {2012}\\n}',\n",
       " 'Lecun2015deep': '@article{Lecun2015deep,\\n  title={Deep learning},\\n  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},\\n  journal={Nature},\\n  volume={521},\\n  number={7553},\\n  pages={436},\\n  year={2015},\\n  publisher={Nature Publishing Group}\\n}',\n",
       " 'Kemp2008discovery': '@article{Kemp2008discovery,\\n  title={The discovery of structural form},\\n  author={Kemp, Charles and Tenenbaum, Joshua B},\\n  journal={Proceedings of the National Academy of Sciences},\\n  volume={105},\\n  number={31},\\n  pages={10687--10692},\\n  year={2008},\\n  publisher={National Acad Sciences}\\n}',\n",
       " 'Lecun1989backpropagation': '@article{Lecun1989backpropagation,\\n  title={Backpropagation applied to handwritten zip code recognition},\\n  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},\\n  journal={Neural computation},\\n  volume={1},\\n  number={4},\\n  pages={541--551},\\n  year={1989},\\n  publisher={MIT Press}\\n}',\n",
       " 'Cho2015unsupervised': '@article{Cho2015unsupervised,\\n  title={Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals},\\n  author={Cho, Minsu and Kwak, Suha and Schmid, Cordelia and Ponce, Jean},\\n  journal={CoRR},\\n%   volume={abs/1501.06170},\\n  archivePrefix = {arXiv},\\n  eprint = {1501.06170},\\n  year={2015}\\n}',\n",
       " 'Kwak2015unsupervised': '@inproceedings{Kwak2015unsupervised,\\n  title={Unsupervised object discovery and tracking in video collections},\\n  author={Kwak, Suha and Cho, Minsu and Laptev, Ivan and Ponce, Jean and Schmid, Cordelia},\\n  booktitle={ICCV},\\n  pages={3173--3181},\\n  year={2015},\\n  organization={IEEE}\\n}',\n",
       " 'Xiao2016track': '@inproceedings{Xiao2016track,\\n  title={Track and segment: An iterative unsupervised approach for video object proposals},\\n  author={Xiao, Fanyi and Jae Lee, Yong},\\n  booktitle={CVPR},\\n  pages={933--942},\\n  year={2016}\\n}',\n",
       " 'Babaeizadeh2017stochastic': '@article{Babaeizadeh2017stochastic,\\n  title={Stochastic Variational Video Prediction},\\n  author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},\\n  journal={CoRR},\\n  year={2017},\\n    archivePrefix = {arXiv},\\n    eprint = {1710.11252},\\n}',\n",
       " 'Tulyakov2017mocogan': '@article{Tulyakov2017mocogan,\\n  title={Mocogan: Decomposing motion and content for video generation},\\n  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},\\n  journal={CVPR},\\n  year={2018}\\n}',\n",
       " 'Denton2017unsupervised': '@inproceedings{Denton2017unsupervised,\\n  title={Unsupervised learning of disentangled representations from video},\\n  author={Denton, Emily and Birodkar, Vighnesh},\\n  booktitle={NIPS},\\n  pages={4417--4426},\\n  year={2017}\\n}',\n",
       " 'Ranzato2014video': '@article{Ranzato2014video,\\n  title={Video (language) modeling: a baseline for generative models of natural videos},\\n  author={Ranzato, MarcAurelio and Szlam, Arthur and Bruna, Joan and Mathieu, Michael and Collobert, Ronan and Chopra, Sumit},\\n  journal={CoRR},\\n    archivePrefix = {arXiv},\\neprint = {1412.6604},\\n  year={2014}\\n}',\n",
       " 'Srivastava2015unsupervised': '@inproceedings{Srivastava2015unsupervised,\\n  title={Unsupervised Learning of Video Representations using LSTMs.},\\n  author={Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},\\n  booktitle={ICML},\\n  pages={843--852},\\n  year={2015}\\n}',\n",
       " 'Neiswanger2012unsupervised': '@article{Neiswanger2012unsupervised,\\n  title={Unsupervised Detection and Tracking of Arbitrary Objects with Dependent Dirichlet Process Mixtures},\\n  author={Neiswanger, Willie and Wood, Frank},\\n  journal={CoRR},\\n    archivePrefix = {arXiv},\\neprint = {1210.3288},\\n  year={2012}\\n}',\n",
       " 'Weber2017imagination': \"@inproceedings{Weber2017imagination,\\n  title={Imagination-augmented agents for deep reinforcement learning},\\n  author={Weber, Th{\\\\'e}ophane and Racani{\\\\`e}re, S{\\\\'e}bastien and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo Jimenez and Badia, Adria Puigdom{\\\\`e}nech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},\\n  booktitle={NIPS},\\n  year={2017}\\n}\",\n",
       " 'Kingma2013auto': '@article{Kingma2013auto,\\n  title={Auto-encoding variational bayes},\\n  author={Kingma, Diederik P and Welling, Max},\\n  journal={arXiv preprint arXiv:1312.6114},\\n  year={2013}\\n}',\n",
       " 'Ristani2016performance': '@inproceedings{Ristani2016performance,\\n  title={Performance measures and a data set for multi-target, multi-camera tracking},\\n  author={Ristani, Ergys and Solera, Francesco and Zou, Roger and Cucchiara, Rita and Tomasi, Carlo},\\n  booktitle={ECCV},\\n  pages={17--35},\\n  year={2016},\\n  organization={Springer}\\n}',\n",
       " 'Tieleman2012rms': '@misc{Tieleman2012rms,\\n  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},\\n  author={Tieleman, T. and Hinton, G.},\\n  howpublished={COURSERA: Neural Networks for Machine Learning},\\n  year={2012}\\n}',\n",
       " 'Maddison2017filtering': '@article{Maddison2017filtering,\\n  title={Filtering Variational Objectives},\\n  author={Maddison, Chris J and Lawson, Dieterich and Tucker, George and Heess, Nicolas and Norouzi, Mohammad and Mnih, Andriy and Doucet, Arnaud and Teh, Yee Whye},\\n  journal={arXiv preprint arXiv:1705.09279},\\n  year={2017}\\n}',\n",
       " 'Gulrajani2016pixelvae': '@article{Gulrajani2016pixelvae,\\n  title={Pixelvae: A latent variable model for natural images},\\n  author={Gulrajani, Ishaan and Kumar, Kundan and Ahmed, Faruk and Taiga, Adrien Ali and Visin, Francesco and Vazquez, David and Courville, Aaron},\\n  journal={CoRR},\\n    archivePrefix = {arXiv},\\neprint = {1611.05013},\\n  year={2016}\\n}',\n",
       " 'Kim2018disentangling': '@inproceedings{Kim2018disentangling,\\n  title={Disentangling by factorising},\\n  author={Kim, Hyunjik and Mnih, Andriy},\\n  booktitle={ICML},\\n    archivePrefix = {arXiv},\\neprint = {1802.05983},\\n  year={2018}\\n}',\n",
       " 'Itseez2015opencv': '@misc{Itseez2015opencv,\\n  title={Open Source Computer Vision Library},\\n  author={Itseez},\\n  year={2015},\\n  howpublished = {\\\\url{https://github.com/itseez/opencv}}\\n}',\n",
       " 'Clevert2015elu': \"@article{Clevert2015elu,\\n  title={Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)},\\n  author={Djork-Arn{\\\\'e} Clevert and Thomas Unterthiner and Sepp Hochreiter},\\n  journal={CoRR},\\n  year={2015},\\n%   volume={abs/1511.07289}\\n  archivePrefix = {arXiv},\\neprint = {1511.07289},\\n  \\n}\",\n",
       " 'Schulter2017deepnf': '@inproceedings{Schulter2017deepnf,\\n  title={Deep Network Flow for Multi-object Tracking},\\n  author={Samuel Schulter and Paul Vernaza and Wongun Choi and Manmohan Krishna Chandraker},\\n  booktitle={CVPR},\\n  year={2017},\\n  pages={2730-2739}\\n}',\n",
       " 'Bewley2016sort': '@inproceedings{Bewley2016sort,\\n  title={Simple online and realtime tracking},\\n  author={Alex Bewley and ZongYuan Ge and Lionel Ott and Fabio Tozeto Ramos and Ben Upcroft},\\n  booktitle={ICIP},\\n  year={2016},\\n  pages={3464-3468}\\n}',\n",
       " 'Valmadre2017end': '@inproceedings{Valmadre2017end,\\nabstract = {The Correlation Filter is an algorithm that trains a linear template to discriminate between images and their translations. It is well suited to object tracking because its formulation in the Fourier domain provides a fast solution, enabling the detector to be re-trained once per frame. Previous works that use the Correlation Filter, however, have adopted features that were either manually designed or trained for a different task. This work is the first to overcome this limitation by interpreting the Correlation Filter learner, which has a closed-form solution, as a differentiable layer in a deep neural network. This enables learning deep features that are tightly coupled to the Correlation Filter. Experiments illustrate that our method has the important practical benefit of allowing lightweight architectures to achieve state-of-the-art performance at high framerates.},\\narchivePrefix = {arXiv},\\narxivId = {1704.06036},\\nauthor = {Valmadre, Jack and Bertinetto, Luca and Henriques, Jo{\\\\~{a}}o F. and Vedaldi, Andrea and Torr, Philip H. S.},\\nbooktitle = {CVPR},\\neprint = {1704.06036},\\ntitle = {{End-to-end representation learning for Correlation Filter based tracking}},\\nopturl = {http://arxiv.org/abs/1704.06036},\\nyear = {2017}\\n}',\n",
       " 'Karl2017dvbf': '@inproceedings{Karl2017dvbf,\\nabstract = {We introduce Deep Variational Bayes Filters (DVBF), a new methhttps://arxiv.org/pdf/1605.06432.pdfod for unsupervised learning of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions by means of variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.},\\narchivePrefix = {arXiv},\\narxivId = {1605.06432},\\nauthor = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},\\nbooktitle = {ICLR},\\neprint = {1605.06432},\\nfile = {:Users/adam/Documents/Mendeley/Karl et al. - 2017 - Deep Variational Bayes Filters Unsupervised Learning of State Space Models from Raw Data.pdf:pdf},\\ntitle = {{Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}},\\nopturl = {http://arxiv.org/abs/1605.06432 https://arxiv.org/pdf/1605.06432.pdf},\\nyear = {2017}\\n}',\n",
       " 'Ondruska2016deepts': '@inproceedings{Ondruska2016deepts,\\n  title={Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks},\\n  author={Peter Ondruska and Ingmar Posner},\\n  booktitle={AAAI},\\n  year={2016}\\n}',\n",
       " 'Shi2016subpixel': '@article{Shi2016subpixel,\\n  title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network},\\n  author={Wenzhe Shi and Jose Caballero and Ferenc Huszar and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},\\n  journal={CVPR},\\n  year={2016},\\n  pages={1874-1883}\\n}',\n",
       " 'Kingma2015adam': '@article{Kingma2015adam,\\n  title={Adam: A Method for Stochastic Optimization},\\n  author={Diederik P. Kingma and Jimmy Ba},\\n  journal={ICLR},\\n  year={2015},\\n%   volume={abs/1412.6980}\\n    archivePrefix = {arXiv},\\neprint = {1412.6980},\\n}',\n",
       " 'Zaheer2017deeps': \"@inproceedings{Zaheer2017deeps,\\n  title={Deep Sets},\\n  author={Manzil Zaheer and Satwik Kottur and Siamak Ravanbakhsh and Barnab{\\\\'a}s P{\\\\'o}czos and Ruslan R. Salakhutdinov and Alexander J. Smola},\\n  booktitle={NIPS},\\n  year={2017}\\n}\",\n",
       " 'Ha2018worldm': '@article{Ha2018worldm,\\n  title={World Models},\\n  author={David Ha and J{\\\\\"u}rgen Schmidhuber},\\n  journal={CoRR},\\n  year={2018},\\n%   volume={abs/1803.10122}\\n    archivePrefix = {arXiv},\\neprint = {1603.10122},\\n}',\n",
       " 'Jacobsen2016struc': '@inproceedings{Jacobsen2016struc,\\nabstract = {Learning powerful feature representations with CNNs is hard when training data are limited. Pre-training is one way to overcome this, but it requires large datasets suffi-ciently similar to the target domain. Another option is to de-sign priors into the model, which can range from tuned hy-perparameters to fully engineered representations like Scat-tering Networks. We combine these ideas into structured receptive field networks, a model which has a fixed filter basis and yet retains the flexibility of CNNs. This flexibil-ity is achieved by expressing receptive fields in CNNs as a weighted sum over a fixed basis which is similar in spirit to Scattering Networks. The key difference is that we learn arbitrary effective filter sets from the basis rather than mod-eling the filters. This approach explicitly connects clas-sical multiscale image analysis with general CNNs. With structured receptive field networks, we improve consider-ably over unstructured CNNs for small and medium dataset scenarios as well as over Scattering for large datasets. We validate our findings on ILSVRC2012, Cifar-10, Cifar-100 and MNIST. As a realistic small dataset example, we show state-of-the-art classification results on popular 3D MRI brain-disease datasets where pre-training is difficult due to a lack of large public datasets in a similar domain.},\\nauthor = {Jacobsen, J{\\\\\"{o}}rn-Henrik and {Van Gemert}, Jan and Lou, Zhongyou and Smeulders, Arnold W M},\\nbooktitle = {CVPR},\\nfile = {:Users/adam/Documents/Mendeley/Jacobsen et al. - 2016 - Structured Receptive Fields in CNNs.pdf:pdf},\\ntitle = {{Structured Receptive Fields in CNNs}},\\nurl = {https://www.cv-foundation.org/openaccess/content{\\\\_}cvpr{\\\\_}2016/papers/Jacobsen{\\\\_}Structured{\\\\_}Receptive{\\\\_}Fields{\\\\_}CVPR{\\\\_}2016{\\\\_}paper.pdf},\\nyear = {2016}\\n}',\n",
       " 'Oord2016cond': '@inproceedings{Oord2016cond,\\nabstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},\\narchivePrefix = {arXiv},\\narxivId = {1606.05328},\\nauthor = {van den Oord, Aaron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},\\nbooktitle = {NIPS},\\neprint = {1606.05328},\\nmonth = {jun},\\ntitle = {{Conditional Image Generation with PixelCNN Decoders}},\\nurl = {http://arxiv.org/abs/1606.05328},\\nyear = {2016}\\n}',\n",
       " 'Oord2018cpc': '@article{Oord2018cpc,\\n  title={Representation Learning with Contrastive Predictive Coding},\\n  author={A{\\\\\"a}ron van den Oord and Yazhe Li and Oriol Vinyals},\\n  journal={CoRR},\\n  year={2018},\\n  volume={abs/1807.03748}\\n}',\n",
       " 'Comon1994ica': '@article{Comon1994ica,\\n  title={Independent component analysis, A new concept?},\\n  author={Pierre Comon},\\n  journal={Signal Processing},\\n  year={1994},\\n  volume={36},\\n  pages={287-314}\\n}',\n",
       " 'Hyvrinen1999nica': '@article{Hyvrinen1999nica,\\n  title={Nonlinear independent component analysis: Existence and uniqueness results},\\n  author={Aapo Hyv{\\\\\"a}rinen and Petteri Pajunen},\\n  journal={Neural networks : the official journal of the International Neural Network Society},\\n  year={1999},\\n  volume={12 3},\\n  pages={\\n          429-439\\n        }\\n}',\n",
       " 'Hyvrinen2018cica': '@article{Hyvrinen2018cica,\\n  title={Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning},\\n  author={Aapo Hyv{\\\\\"a}rinen and Hiroaki Sasaki and Richard E. Turner},\\n  journal={CoRR},\\n  year={2018},\\n  volume={abs/1805.08651}\\n}',\n",
       " 'Hyvrinen2017tica': '@inproceedings{Hyvrinen2017tica,\\n  title={Nonlinear ICA of Temporally Dependent Stationary Sources},\\n  author={Aapo Hyv{\\\\\"a}rinen and Hiroshi Morioka},\\n  booktitle={AISTATS},\\n  year={2017}\\n}',\n",
       " 'Rasmus2015ladder': '@inproceedings{Rasmus2015ladder,\\n  title={Semi-supervised Learning with Ladder Networks},\\n  author={Antti Rasmus and Mathias Berglund and Mikko Honkala and Harri Valpola and Tapani Raiko},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  year={2015}\\n}',\n",
       " 'Sabour2017capsule': '@inproceedings{Sabour2017capsule,\\n  title={Dynamic Routing Between Capsules},\\n  author={Sabour, Sara and Frosst, Nick and Hinton, G. E.},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  year={2017}\\n}',\n",
       " 'Hinton2018capsule': '@inproceedings{Hinton2018capsule,\\n  title={Matrix Capsules with EM routing},\\n  author={Hinton, G. E. and Sabour, Sara and Frosst, Nick},\\n  booktitle={International Conference on Learning Representations},\\n  year={2018}\\n}',\n",
       " 'Graves2016mixture': '@article{Graves2016mixture,\\n  title={Stochastic Backpropagation through Mixture Density Distributions},\\n  author={Alex Graves},\\n  journal={CoRR},\\n  year={2016},\\n  volume={abs/1607.05690}\\n}',\n",
       " 'Jang2016gumbel': '@article{Jang2016gumbel,\\n  title={Categorical Reparameterization with Gumbel-Softmax},\\n  author={Eric Jang and Shixiang Gu and Ben Poole},\\n  journal={CoRR},\\n  year={2016},\\n  volume={abs/1611.01144}\\n}',\n",
       " 'Maddison2016concrete': '@article{Maddison2016concrete,\\n  title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},\\n  author={Chris J. Maddison and Andriy Mnih and Yee Whye Teh},\\n  journal={CoRR},\\n  year={2016},\\n  volume={abs/1611.00712}\\n}',\n",
       " 'Maale2016auxdgm': '@inproceedings{Maale2016auxdgm,\\n  title={Auxiliary Deep Generative Models},\\n  author={Maal{\\\\o}e, Lars and S{\\\\o}nderby, Casper Kaae and S{\\\\o}nderby, S{\\\\o}ren Kaae and Winther, Ole},\\n  booktitle={International Conference on Machine Learning},\\n  year={2016}\\n}',\n",
       " 'Sonderby2016ladder': '@inproceedings{Sonderby2016ladder,\\n  title={Ladder Variational Autoencoders},\\n  author={Casper Kaae S{\\\\o}nderby and Tapani Raiko and Lars Maal{\\\\o}e and S{\\\\o}ren Kaae S{\\\\o}nderby and Ole Winther},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  year={2016}\\n}',\n",
       " 'Maaloe2019biva': \"@inproceedings{Maaloe2019biva,\\n  title={BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling},\\n  author={Lars Maal{\\\\o}e and Marco Fraccaro and Valentin Li'evin and Ole Winther},\\n  year={2019}\\n}\",\n",
       " 'Vaswani2017transformer': '@inproceedings{Vaswani2017transformer,\\n  title={Attention Is All You Need},\\n  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  year={2017}\\n}',\n",
       " 'Parmar2018imtransf': '@inproceedings{Parmar2018imtransf,\\n  title={Image Transformer},\\n  author={Niki Parmar and Ashish Vaswani and Jakob Uszkoreit and Lukasz Kaiser and Noam Shazeer and Alexander Ku},\\n  booktitle={International Conference on Machine Learning},\\n  year={2018}\\n}',\n",
       " 'Lee2019set': '@inproceedings{Lee2019set,\\n  title={Set Transformer},\\n  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam R and Choi, Seungjin and Teh, Yee Whye},\\n  booktitle={International Conference on Machine Learning},\\n  eprint={1810.00825},\\n  archivePrefix = {arXiv},\\n  year={2019},\\n}',\n",
       " 'Golovin2017vizier': '@inproceedings{Golovin2017vizier,\\n  title={Google vizier: A service for black-box optimization},\\n  author={Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D},\\n  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},\\n  pages={1487--1495},\\n  year={2017},\\n  organization={ACM}\\n}',\n",
       " 'Tieleman2014thesis': '@book{Tieleman2014thesis,\\n  title={Optimizing Neural Networks That Generate Images},\\n  author={Tieleman, Tijmen},\\n  year={2014},\\n  publisher={University of Toronto, Canada}\\n}',\n",
       " 'Maddison2017concrete': '@inproceedings{Maddison2017concrete,\\n  title        = {The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},\\n  author       = {Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2017\\n}',\n",
       " 'Hinton2011tae': '@inproceedings{Hinton2011tae,\\n  title={Transforming Auto-Encoders},\\n  author = {Hinton, G. E. and Krizhevsky, A. and Wang, S. D.},\\n  booktitle={International Conference on Artifical Neural Networks},\\n  year={2011}\\n}',\n",
       " 'Lalonde': '@article{Lalonde,\\n  title={Capsules for object segmentation},\\n  author={LaLonde, Rodney and Bagci, Ulas},\\n  journal={arXiv preprint arXiv:1804.04241},\\n  year={2018}\\n}',\n",
       " 'Lenssen': '@inproceedings{Lenssen,\\n  title={Group Equivariant Capsule Networks},\\n  author={Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={8844--8853},\\n  year={2018}\\n}',\n",
       " 'Duarte': '@inproceedings{Duarte,\\n  title={Videocapsulenet: A simplified network for action detection},\\n  author={Duarte, Kevin and Rawat, Yogesh and Shah, Mubarak},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={7610--7619},\\n  year={2018}\\n}',\n",
       " 'Encapsule': '@article{Encapsule,\\n  author    = {Hongyang Li and\\n              Xiaoyang Guo and\\n              Bo Dai and\\n              Wanli Ouyang and\\n              Xiaogang Wang},\\n  title     = {Neural Network Encapsulation},\\n  journal   = {CoRR},\\n%   volume    = {abs/1808.03749},\\n  year      = {2018},\\n%   url       = {http://arxiv.org/abs/1808.03749},\\n  archivePrefix = {arXiv},\\n  eprint    = {1808.03749},\\n%   timestamp = {Sun, 02 Sep 2018 15:01:55 +0200},\\n%   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-03749},\\n%   bibsource = {dblp computer science bibliography, https://dblp.org}\\n}',\n",
       " 'Zhang2018fast': '@inproceedings{Zhang2018fast,\\n  title={Fast Dynamic Routing Based on Weighted Kernel Density Estimation},\\n  author={Zhang, Suofei and Zhou, Quan and Wu, Xiaofu},\\n  booktitle={International Symposium on Artificial Intelligence and Robotics},\\n  pages={301--309},\\n  year={2018},\\n%   organization={Springer}\\n}',\n",
       " 'Wang2018optimization': '@inproceedings{Wang2018optimization,\\n  title={An Optimization View on Dynamic Routing Between Capsules},\\n  author={Wang, Dilin and Liu, Qiang},\\n  journal={ICLR Workshop},\\n  year={2018}\\n}',\n",
       " 'Saqur': '@article{Saqur,\\n  title={CapsGAN: Using dynamic routing for generative adversarial networks},\\n  author={Saqur, Raeid and Vivona, Sal},\\n  journal={arXiv preprint arXiv:1806.03968},\\n  year={2018}\\n}',\n",
       " 'Jaiswal': '@inproceedings{Jaiswal,\\n  title={Capsulegan: Generative adversarial capsule network},\\n  author={Jaiswal, Ayush and AbdAlmageed, Wael and Wu, Yue and Natarajan, Premkumar},\\n  booktitle={European Conference on Computer Vision (ECCV)},\\n%   pages={0--0},\\n  year={2018}\\n}',\n",
       " 'Upadhyay': '@article{Upadhyay,\\n  title={Generative adversarial network architectures for image synthesis using capsule networks},\\n  author={Upadhyay, Yash and Schrater, Paul},\\n  journal={arXiv preprint arXiv:1806.03796},\\n  year={2018}\\n}',\n",
       " 'Zhao20183d': '@article{Zhao20183d,\\n  title={3D Point-Capsule Networks},\\n  author={Zhao, Yongheng and Birdal, Tolga and Deng, Haowen and Tombari, Federico},\\n  journal={arXiv preprint arXiv:1812.10775},\\n  year={2018}\\n}',\n",
       " 'Mallat': \"@inproceedings{Mallat,\\n  title={Deep Roto-Translation Scattering for Object Classification},\\n  author={Oyallon, Edouard and Mallat, St{\\\\'e}phane},\\n  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},\\n  pages={2865--2873},\\n  year={2015}\\n}\",\n",
       " 'Sparsecaps': '@article{Sparsecaps,\\n  title={Sparse Unsupervised Capsules Generalize Better},\\n  author={Rawlinson, David and Ahmed, Abdelrahman and Kowadlo, Gideon},\\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  eprint={1804.06094},\\n  year={2018}\\n}',\n",
       " 'Kocvok': '@article{Kocvok,\\n  title={Exploiting Cyclic Symmetry in Convolutional Neural Networks},\\n  author={Dieleman, Sander and De Fauw, Jeffrey and Kavukcuoglu, Koray},\\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  eprint = {1602.02660},\\n  year={2016}\\n}',\n",
       " 'Imsat': '@inproceedings{Imsat,\\n  title={Learning Discrete Representations via Information Maximizing Self-augmented Training},\\n  author={Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},\\n  booktitle={International Conference on Machine Learning},\\n  pages={1558--1567},\\n  year={2017},\\n%   organization={JMLR. org}\\n}',\n",
       " 'Iic': '@article{Iic,\\n  author    = {Xu Ji and\\n              Jo{\\\\~{a}}o F. Henriques and\\n              Andrea Vedaldi},\\n  title     = {Invariant Information Distillation for Unsupervised Image Segmentation\\n              and Clustering},\\n  journal   = {CoRR},\\n%   volume    = {abs/1807.06653},\\n  year      = {2018},\\n  url       = {http://arxiv.org/abs/1807.06653},\\n  archivePrefix = {arXiv},\\n  eprint    = {1807.06653},\\n%   timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},\\n%   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-06653},\\n%   bibsource = {dblp computer science bibliography, https://dblp.org}\\n}',\n",
       " 'Gan': '@article{Gan,\\n  title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},\\n  author={Radford, Alec and Metz, Luke and Chintala, Soumith},\\n  journal={International Conference on Learning Representations},\\n  year={2016}\\n}',\n",
       " 'Ae': '@inproceedings{Ae,\\n  title={Greedy Layer-wise Training of Deep Networks},\\n  author={Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={153--160},\\n  year={2007}\\n}',\n",
       " 'Adc': '@inproceedings{Adc,\\n  title={Associative Deep Clustering: Training a Classification Network with No Labels},\\n  author={Haeusser, Philip and Plapp, Johannes and Golkov, Vladimir and Aljalbout, Elie and Cremers, Daniel},\\n  booktitle={German Conference on Pattern Recognition},\\n  pages={18--32},\\n  year={2018},\\n%   organization={Springer}\\n}',\n",
       " 'Jacobsen2017dynamic': '@article{Jacobsen2017dynamic,\\n  title={Dynamic steerable blocks in deep residual networks},\\n  author={Jacobsen, J{\\\\\"o}rn-Henrik and De Brabandere, Bert and Smeulders, Arnold WM},\\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  eprint={1706.00598},\\n  year={2017}\\n}',\n",
       " 'Gutmann2010nce': '@inproceedings{Gutmann2010nce,\\n  title={Noise-contrastive Estimation: A New Estimation Principle for Unnormalized Statistical Models},\\n  author={Gutmann, Michael and Hyv{\\\\\"a}rinen, Aapo},\\n  booktitle={International Conference on Artificial Intelligence and Statistics},\\n  pages={297--304},\\n  year={2010}\\n}',\n",
       " 'Cohen2016group': '@inproceedings{Cohen2016group,\\n  title={Group Equivariant Convolutional Networks},\\n  author={Cohen, Taco and Welling, Max},\\n  booktitle={International Conference on Machine Learning},\\n  pages={2990--2999},\\n  year={2016}\\n}',\n",
       " 'Cohen2016steerable': '@inproceedings{Cohen2016steerable,\\n  title={Steerable CNNs},\\n  author={Cohen, Taco and Welling, Max},\\n  booktitle={International Conference on Representation Learning},\\n  year={2017}\\n}',\n",
       " 'Hjelm2019deepinfomax': '@article{Hjelm2019deepinfomax,\\n  title={Learning Deep Representations by Mutual Information Estimation and Maximization},\\n  author={R. Devon Hjelm and Alex Fedorov and Samuel Lavoie-Marchildon and Karan Grewal and Adam Trischler and Yoshua Bengio},  \\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  year={2019},\\n  eprint={1808.06670}\\n}',\n",
       " 'Rock73': '@book{Rock73,\\n  title={Orientation and form},\\n  author={Rock, Irvin},\\n  year={1973},\\n  publisher={Academic Press}\\n}',\n",
       " 'Hinton79': '@article{Hinton79,\\n  author = \\t {Hinton, G. E.},\\n  title = \\t {Some Demonstrations of the Effects of Structural Descriptions in Mental Imagery},\\n  journal =  {Cognitive Science},\\n  year = \\t {1979},\\n  volume = \\t {3},\\n  pages = \\t {231--250},\\n}',\n",
       " 'Burgess2019monet': '@article{Burgess2019monet,\\n  title={MONet: Unsupervised Scene Decomposition and Representation},\\n  author={Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},\\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  eprint = {1901.11390},\\n  year={2019}\\n}',\n",
       " 'Greff2019multi': '@article{Greff2019multi,\\n  title={Multi-Object Representation Learning with Iterative Variational Inference},\\n  author={Greff, Klaus and Kaufmann, Rapha{\\\\\"e}l Lopez and Kabra, Rishab and Watters, Nick and Burgess, Chris and Zoran, Daniel and Matthey, Loic and Botvinick, Matthew and Lerchner, Alexander},\\n  journal={arXiv preprint arXiv:1903.00450},\\n  year={2019}\\n}',\n",
       " 'Kuhn1955hungarian': '@article{Kuhn1955hungarian,\\n  title={The Hungarian Method for the Assignment Problem},\\n  author={Kuhn, Harold W},\\n  journal={Naval Research Logistics Quarterly},\\n%   volume={2},\\n%   number={1-2},\\n  pages={83--97},\\n  year={1955},\\n  publisher={Wiley Online Library}\\n}',\n",
       " 'Liu2019soft': '@article{Liu2019soft,\\n  title={Soft Rasterizer: Differentiable Rendering for Unsupervised Single-View Mesh Reconstruction},\\n  author={Liu, Shichen and Chen, Weikai and Li, Tianye and Li, Hao},\\n  journal={CoRR},\\n  archivePrefix = {arXiv},\\n  eprint = {1901.05567},\\n  year={2019}\\n}',\n",
       " 'Ba2016layern': '@article{Ba2016layern,\\n%   title={Layer Normalization},\\n%   author={Jimmy Ba and Jamie Kiros and G E Hinton},\\n%   journal={CoRR},\\n%   year={2016},\\n%   volume={abs/1607.06450}\\n% }',\n",
       " 'Hinton1995wake': '@article{Hinton1995wake,\\n\\ttitle={The\" wake-sleep\" algorithm for unsupervised neural networks},\\n\\tauthor={Hinton, Geoffrey E and Dayan, Peter and Frey, Brendan J and Neal, Radford M},\\n\\tjournal={Science},\\n\\tvolume={268},\\n\\tnumber={5214},\\n\\tpages={1158--1161},\\n\\tyear={1995},\\n\\tpublisher={American Association for the Advancement of Science}\\n}',\n",
       " 'Bornschein2015reweighted': '@inproceedings{Bornschein2015reweighted,\\n  title        = {Reweighted Wake-Sleep},\\n  author       = {Bornschein, J{\\\\\"o}rg and Bengio, Yoshua},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2015\\n}',\n",
       " 'Jang2017categorical': '@inproceedings{Jang2017categorical,\\n  title        = {Categorical Reparameterization with {G}umbel-Softmax},\\n  author       = {Jang, Eric and Gu, Shixiang and Poole, Ben},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2017\\n}',\n",
       " 'Tucker2017rebar': '@inproceedings{Tucker2017rebar,\\n  title        = {REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models},\\n  author       = {Tucker, George and Mnih, Andriy and Maddison, Chris J and Lawson, John and Sohl-Dickstein, Jascha},\\n  booktitle    = {Advances in Neural Information Processing Systems},\\n  pages        = {2624--2633},\\n  year         = 2017\\n}',\n",
       " 'Grathwohl2018backpropagation': '@inproceedings{Grathwohl2018backpropagation,\\n  title        = {Backpropagation through the Void: Optimizing control variates for black-box gradient estimation},\\n  author       = {Will Grathwohl and Dami Choi and Yuhuai Wu and Geoff Roeder and David Duvenaud},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2018\\n}',\n",
       " 'Burda2016importance': '@inproceedings{Burda2016importance,\\n  title = {Importance Weighted Autoencoders},\\n  author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},\\n  year = {2016},\\n  booktitle = {ICLR}\\n}',\n",
       " 'Mnih2016variational': '@inproceedings{Mnih2016variational,\\n  title        = {Variational inference for {M}onte {C}arlo objectives},\\n  author       = {Mnih, Andriy and Rezende, Danilo},\\n  booktitle    = {International Conference on Machine Learning},\\n  pages        = {2188--2196},\\n  year         = 2016\\n}',\n",
       " 'Kingma2014auto': '@inproceedings{Kingma2014auto,\\n  title={Auto-encoding variational {Bayes}},\\n  author={Kingma, Diederik P and Welling, Max},\\n  year = {2014},\\n  booktitle = {ICLR}\\n}',\n",
       " 'Rezende2014stochastic': '@inproceedings{Rezende2014stochastic,\\n  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan },\\n  title = {Stochastic backpropagation and approximate inference in deep generative models},\\n  booktitle = {ICML},\\n  year = {2014},\\n}',\n",
       " 'Naesseth2017variational': '@article{Naesseth2017variational,\\n  title={Variational Sequential Monte Carlo},\\n  author={Naesseth, Christian A and Linderman, Scott W and Ranganath, Rajesh and Blei, David M},\\n  journal={arXiv preprint arXiv:1705.11140},\\n  year={2017}\\n}',\n",
       " 'Le2018autoencoding': '@inproceedings{Le2018autoencoding,\\n  title = {Auto-Encoding Sequential {M}onte {C}arlo},\\n  author = {Le, Tuan Anh and Igl, Maximilian and Rainforth, Tom and Jin, Tom and Wood, Frank},\\n  booktitle = {International Conference on Learning Representations},\\n  year = {2018}\\n}',\n",
       " 'Rainforth2018tighter': '@inproceedings{Rainforth2018tighter,\\n  title={Tighter Variational Bounds are Not Necessarily Better},\\n  author={Rainforth, Tom and Kosiorek, Adam R and Le, Tuan Anh and Maddison, Chris J and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},\\n  booktitle={International Conference on Machine Learning},\\n  year={2018}\\n}',\n",
       " 'Williams1992simple': '@article{Williams1992simple,\\n  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},\\n  author = {Williams, Ronald J},\\n  journal = {Machine learning},\\n  volume = {8},\\n  number = {3-4},\\n  pages = {229--256},\\n  year = {1992},\\n  publisher = {Springer}\\n}',\n",
       " 'Mnih2014neural': '@inproceedings{Mnih2014neural,\\n  title={Neural Variational Inference and Learning in Belief Networks},\\n  author={Mnih, Andriy and Gregor, Karol},\\n  booktitle={Proceedings of The 31st International Conference on Machine Learning},\\n  pages={1791--1799},\\n  year={2014}\\n}',\n",
       " 'Dayan1995helmholtz': '@article{Dayan1995helmholtz,\\n  title={The {Helmholtz} machine},\\n  author={Dayan, Peter and Hinton, Geoffrey E and Neal, Radford M and Zemel, Richard S},\\n  journal={Neural computation},\\n  volume={7},\\n  number={5},\\n  pages={889--904},\\n  year={1995},\\n  publisher={MIT Press}\\n}',\n",
       " 'Eslami2016attend': '@inproceedings{Eslami2016attend,\\n    title={Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},\\n    author={S. M. Ali Eslami and Nicolas Heess and Theophane Weber and Yuval Tassa and David Szepesvari and Koray Kavukcuoglu and Geoffrey E. Hinton},\\n    booktitle={Advances in Neural Information Processing Systems},\\n    year={2016}\\n}',\n",
       " 'Miao2016language': '@inproceedings{Miao2016language,\\n  title={Language as a latent variable: Discrete generative models for sentence compression},\\n  author={Miao, Y and Blunsom, P},\\n  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},\\n  pages={319--328},\\n  year={2016}\\n}',\n",
       " 'Goodfellow2014generative': '@inproceedings{Goodfellow2014generative,\\n  title={Generative adversarial nets},\\n  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},\\n  booktitle={Advances in neural information processing systems},\\n  pages={2672--2680},\\n  year={2014}\\n}',\n",
       " 'Mohamed2016learning': '@article{Mohamed2016learning,\\n  title={Learning in implicit generative models},\\n  author={Mohamed, Shakir and Lakshminarayanan, Balaji},\\n  journal={arXiv preprint arXiv:1610.03483},\\n  year={2016}\\n}',\n",
       " 'Le2017inference': '@inproceedings{Le2017inference,\\n  title={Inference Compilation and Universal Probabilistic Programming},\\n  author={Le, Tuan Anh and Baydin, Atilim Gunes and Wood, Frank},\\n  booktitle={AISTATS},\\n  year={2017}\\n}',\n",
       " 'Gershman2014amortized': '@inproceedings{Gershman2014amortized,\\n  author = {Gershman, Sam and Goodman, Noah D.},\\n  booktitle = {Proceedings of the Thirty-Sixth Annual Conference of the {C}ognitive {S}cience {S}ociety},\\n  title = {Amortized inference in probabilistic reasoning},\\n  year = {2014}\\n}',\n",
       " 'Schulman2015gradient': '@inproceedings{Schulman2015gradient,\\n  title={Gradient estimation using stochastic computation graphs},\\n  author={Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},\\n  booktitle={NIPS},\\n  pages={3528--3536},\\n  year={2015}\\n}',\n",
       " 'Johnson2016composing': '@inproceedings{Johnson2016composing,\\n  title={Composing graphical models with neural networks for structured representations and fast inference},\\n  author={Johnson, Matthew and Duvenaud, David K and Wiltschko, Alex and Adams, Ryan P and Datta, Sandeep R},\\n  booktitle={Advances in neural information processing systems},\\n  pages={2946--2954},\\n  year={2016}\\n}',\n",
       " 'Adams2010learning': '@inproceedings{Adams2010learning,\\n  title={Learning the structure of deep sparse graphical models},\\n  author={Adams, Ryan and Wallach, Hanna and Ghahramani, Zoubin},\\n  booktitle={International Conference on Artificial Intelligence and Statistics},\\n  year={2010}\\n}',\n",
       " 'Neiswanger2014dependent': '@inproceedings{Neiswanger2014dependent,\\n  title={The dependent {D}irichlet process mixture of objects for detection-free tracking and object modeling},\\n  author={Neiswanger, Willie and Wood, Frank and Xing, Eric},\\n  booktitle={Artificial Intelligence and Statistics},\\n  pages={660--668},\\n  year={2014}\\n}',\n",
       " 'Rasmussen2000infinite': '@inproceedings{Rasmussen2000infinite,\\n  title={The infinite {G}aussian mixture model},\\n  author={Rasmussen, Carl Edward},\\n  booktitle={Advances in neural information processing systems},\\n  pages={554--560},\\n  year={2000}\\n}',\n",
       " 'Kemp2006learning': '@inproceedings{Kemp2006learning,\\n  title={Learning systems of concepts with an infinite relational model},\\n  author={Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, Takeshi and Ueda, Naonori},\\n  year={2006}\\n}',\n",
       " 'Blei2003latent': '@article{Blei2003latent,\\n  title={Latent dirichlet allocation},\\n  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},\\n  journal={Journal of machine Learning research},\\n  volume={3},\\n  number={Jan},\\n  pages={993--1022},\\n  year={2003}\\n}',\n",
       " 'Ghahramani1996factorial': '@inproceedings{Ghahramani1996factorial,\\n  title={Factorial hidden Markov models},\\n  author={Ghahramani, Zoubin and Jordan, Michael I},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={472--478},\\n  year={1996}\\n}',\n",
       " 'Juang1991hidden': '@article{Juang1991hidden,\\n  title={Hidden Markov models for speech recognition},\\n  author={Juang, Biing Hwang and Rabiner, Laurence R},\\n  journal={Technometrics},\\n  volume={33},\\n  number={3},\\n  pages={251--272},\\n  year={1991},\\n  publisher={Taylor \\\\& Francis}\\n}',\n",
       " 'Chater2006probabilistic': '@article{Chater2006probabilistic,\\n  title={Probabilistic models of language processing and acquisition},\\n  author={Chater, Nick and Manning, Christopher D},\\n  journal={Trends in cognitive sciences},\\n  volume={10},\\n  number={7},\\n  pages={335--344},\\n  year={2006},\\n  publisher={Elsevier}\\n}',\n",
       " 'Fei2003bayesian': '@inproceedings{Fei2003bayesian,\\n  title={A Bayesian approach to unsupervised one-shot learning of object categories},\\n  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},\\n  booktitle={Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on},\\n  pages={1134--1141},\\n  year={2003},\\n  organization={IEEE}\\n}',\n",
       " 'Kemp2006learningoverhypotheses': '@inproceedings{Kemp2006learningoverhypotheses,\\n  title={Learning overhypotheses},\\n  author={Kemp, Charles and Perfors, Amy and Tenenbaum, J},\\n  year={2006},\\n  organization={Cognitive Science Society}\\n}',\n",
       " 'Gu2016muprop': '@inproceedings{Gu2016muprop,\\n  title={MuProp: Unbiased backpropagation for stochastic neural networks},\\n  author={Gu, Shixiang and Levine, Sergey and Sutskever, Ilya and Mnih, Andriy},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2016\\n}',\n",
       " 'Owen2000safe': '@article{Owen2000safe,\\n  title={Safe and effective importance sampling},\\n  author={Owen, Art and Zhou, Yi},\\n  journal={Journal of the American Statistical Association},\\n  volume={95},\\n  number={449},\\n  pages={135--143},\\n  year={2000},\\n  publisher={Taylor \\\\& Francis Group}\\n}',\n",
       " 'Hesterberg1995weighted': '@article{Hesterberg1995weighted,\\n  title={Weighted average importance sampling and defensive mixture distributions},\\n  author={Hesterberg, Tim},\\n  journal={Technometrics},\\n  volume={37},\\n  number={2},\\n  pages={185--194},\\n  year={1995},\\n  publisher={Taylor \\\\& Francis}\\n}',\n",
       " 'Saul1996mean': '@article{Saul1996mean,\\n  title={Mean field theory for sigmoid belief networks},\\n  author={Saul, Lawrence K and Jaakkola, Tommi and Jordan, Michael I},\\n  journal={Journal of artificial intelligence research},\\n  volume={4},\\n  pages={61--76},\\n  year={1996}\\n}',\n",
       " 'Lake2018emergence': '@article{Lake2018emergence,\\n  title={The Emergence of Organizing Structure in Conceptual Representation},\\n  author={Lake, Brenden M and Lawrence, Neil D and Tenenbaum, Joshua B},\\n  journal={Cognitive science},\\n  publisher={Wiley Online Library},\\n  year={2018}\\n}',\n",
       " 'Paige2016inference': '@inproceedings{Paige2016inference,\\n  title={Inference networks for Sequential {M}onte {C}arlo in graphical models},\\n  author={Paige, Brooks and Wood, Frank},\\n  booktitle={ICML},\\n  year={2016}\\n}',\n",
       " 'Robbins1951stochastic': '@article{Robbins1951stochastic,\\n  title={A stochastic approximation method},\\n  author={Robbins, Herbert and Monro, Sutton},\\n  journal={The annals of mathematical statistics},\\n  pages={400--407},\\n  year={1951},\\n  publisher={JSTOR}\\n}',\n",
       " 'Neal1992connectionist': '@article{Neal1992connectionist,\\n  title={Connectionist learning of belief networks},\\n  author={Neal, Radford M},\\n  journal={Artificial intelligence},\\n  volume={56},\\n  number={1},\\n  pages={71--113},\\n  year={1992},\\n  publisher={Elsevier}\\n}',\n",
       " 'Graves2014neural': '@article{Graves2014neural,\\n  title={Neural {T}uring machines},\\n  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},\\n  journal={arXiv preprint arXiv:1410.5401},\\n  year={2014}\\n}',\n",
       " 'Sukhbaatar2015end': '@inproceedings{Sukhbaatar2015end,\\n  title={End-to-end memory networks},\\n  author={Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob and others},\\n  booktitle={Advances in neural information processing systems},\\n  pages={2440--2448},\\n  year={2015}\\n}',\n",
       " 'Graves2016hybrid': \"@article{Graves2016hybrid,\\n  title={Hybrid computing using a neural network with dynamic external memory},\\n  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\\\\'n}ska, Agnieszka and Colmenarejo, Sergio G{\\\\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},\\n  journal={Nature},\\n  volume={538},\\n  number={7626},\\n  pages={471},\\n  year={2016},\\n  publisher={Nature Publishing Group}\\n}\",\n",
       " 'Graves2016adaptive': '@article{Graves2016adaptive,\\n  title={Adaptive computation time for recurrent neural networks},\\n  author={Graves, Alex},\\n  journal={arXiv preprint arXiv:1603.08983},\\n  year={2016}\\n}',\n",
       " 'Xu2015show': '@inproceedings{Xu2015show,\\n  title={Show, attend and tell: Neural image caption generation with visual attention},\\n  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},\\n  booktitle={International Conference on Machine Learning},\\n  pages={2048--2057},\\n  year={2015}\\n}',\n",
       " 'Grefenstette2015learning': '@inproceedings{Grefenstette2015learning,\\n  title={Learning to transduce with unbounded memory},\\n  author={Grefenstette, Edward and Hermann, Karl Moritz and Suleyman, Mustafa and Blunsom, Phil},\\n  booktitle={Advances in Neural Information Processing Systems},\\n  pages={1828--1836},\\n  year={2015}\\n}',\n",
       " 'Rolfe2016dvae': '@inproceedings{Rolfe2016dvae,\\n\\ttitle={Discrete Variational Autoencoders},\\n\\tauthor={Jason Tyler Rolfe},\\n\\tbooktitle={International Conference on Learning Representations},\\n\\tyear={2017}\\n}',\n",
       " 'Vahdat2018dvaepp': '@inproceedings{Vahdat2018dvaepp,\\n\\ttitle={DVAE++: Discrete Variational Autoencoders with Overlapping Transformations},\\n\\tauthor={Arash Vahdat and William G. Macready and Zhengbing Bian and Amir Khoshaman},\\n\\tbooktitle={International Conference on Machine Learning},\\n\\tyear={2018}\\n}',\n",
       " 'Vahdat2018dvaehash': '@inproceedings{Vahdat2018dvaehash,\\n\\ttitle={DVAE\\\\#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors},\\n\\tauthor={Arash Vahdat and Evgeny Andriyash and William G. Macready},\\n\\tbooktitle={Advances in Neural Information Processing Systems},\\n\\tyear={2018}\\n}',\n",
       " 'Minka2005divergence': '@techreport{Minka2005divergence,\\n  title = {Divergence measures and message passing},\\n  author = {Minka, Tom},\\n  year = {2005},\\n  institution = {Technical report, Microsoft Research}\\n}',\n",
       " 'Chatterjee2018sample': '@article{Chatterjee2018sample,\\n  title={The sample size required in importance sampling},\\n  author={Chatterjee, Sourav and Diaconis, Persi and others},\\n  journal={The Annals of Applied Probability},\\n  volume={28},\\n  number={2},\\n  pages={1099--1135},\\n  year={2018},\\n  publisher={Institute of Mathematical Statistics}\\n}',\n",
       " 'Owen2013monte': '@book{Owen2013monte,\\n   author = {Art B. Owen},\\n   year = 2013,\\n   title = {{Monte Carlo} theory, methods and examples}\\n}',\n",
       " 'Chen2018stochastic': '@article{Chen2018stochastic,\\n  title={Stochastic gradient descent with biased but consistent gradient estimators},\\n  author={Chen, Jie and Luss, Ronny},\\n  journal={arXiv preprint arXiv:1807.11880},\\n  year={2018}\\n}',\n",
       " 'Manning1999foundations': '@book{Manning1999foundations,\\n  title={Foundations of statistical natural language processing},\\n  author={Manning, Christopher D and Manning, Christopher D and Sch{\\\\\"u}tze, Hinrich},\\n  year={1999},\\n  publisher={MIT press}\\n}',\n",
       " 'Sisson2018handbook': '@book{Sisson2018handbook,\\n  title={Handbook of Approximate Bayesian Computation},\\n  author={Sisson, Scott A and Fan, Yanan and Beaumont, Mark},\\n  year={2018},\\n  publisher={Chapman and Hall/CRC}\\n}',\n",
       " 'Oord2017neural': '@incollection{Oord2017neural,\\n  title        = {Neural Discrete Representation Learning},\\n  author       = {van den Oord, Aaron and Vinyals, Oriol and kavukcuoglu, koray},\\n  booktitle    = {Advances in Neural Information Processing Systems 30},\\n  editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R.\\n                  Garnett},\\n  pages        = {6306--6315},\\n  year         = 2017,\\n  publisher    = {Curran Associates, Inc.}\\n}',\n",
       " 'Tucker2019doubly': '@inproceedings{Tucker2019doubly,\\n  title        = {Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives},\\n  author       = {Tucker, George and Lawson, Dieterich and Gu, Shixiang and Maddison, Chris J.},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2019\\n}',\n",
       " 'Lari1990estimation': '@article{Lari1990estimation,\\n  title={The estimation of stochastic context-free grammars using the inside-outside algorithm},\\n  author={Lari, Karim and Young, Steve J},\\n  journal={Computer speech \\\\& language},\\n  volume={4},\\n  number={1},\\n  pages={35--56},\\n  year={1990},\\n  publisher={Elsevier}\\n}',\n",
       " 'Earley1970efficient': '@article{Earley1970efficient,\\n  title={An efficient context-free parsing algorithm},\\n  author={Earley, Jay},\\n  journal={Communications of the ACM},\\n  volume={13},\\n  number={2},\\n  pages={94--102},\\n  year={1970},\\n  publisher={ACM}\\n}',\n",
       " 'Booth1973applying': '@article{Booth1973applying,\\n  title={Applying probability measures to abstract languages},\\n  author={Booth, Taylor L and Thompson, Richard A},\\n  journal={IEEE transactions on Computers},\\n  volume={100},\\n  number={5},\\n  pages={442--450},\\n  year={1973},\\n  publisher={IEEE}\\n}',\n",
       " 'Chen2014fast': '@inproceedings{Chen2014fast,\\n  title={A fast and accurate dependency parser using neural networks},\\n  author={Chen, Danqi and Manning, Christopher},\\n  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},\\n  pages={740--750},\\n  year={2014}\\n}',\n",
       " 'Tai2015improved': '@article{Tai2015improved,\\n  title={Improved semantic representations from tree-structured long short-term memory networks},\\n  author={Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},\\n  journal={arXiv preprint arXiv:1503.00075},\\n  year={2015}\\n}',\n",
       " 'Neural2017neural': '@inproceedings{Neural2017neural,\\n  title={Neural Scene De-rendering},\\n  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},\\n  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\\n  year={2017}\\n}',\n",
       " 'Younger1967recognition': '@article{Younger1967recognition,\\n  title={Recognition and parsing of context-free languages in time n3},\\n  author={Younger, Daniel H},\\n  journal={Information and control},\\n  volume={10},\\n  number={2},\\n  pages={189--208},\\n  year={1967},\\n  publisher={Elsevier}\\n}',\n",
       " 'Dempster1977maximum': '@article{Dempster1977maximum,\\n  title={Maximum likelihood from incomplete data via the EM algorithm},\\n  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},\\n  journal={Journal of the royal statistical society. Series B (methodological)},\\n  pages={1--38},\\n  year={1977},\\n  publisher={JSTOR}\\n}',\n",
       " 'Klein2003parsing': '@inproceedings{Klein2003parsing,\\n  title={A parsing: fast exact Viterbi parse selection},\\n  author={Klein, Dan and Manning, Christopher D},\\n  booktitle={Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1},\\n  pages={40--47},\\n  year={2003},\\n  organization={Association for Computational Linguistics}\\n}',\n",
       " 'Kosiorek2018sequential': '@inproceedings{Kosiorek2018sequential,\\n\\ttitle={Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects},\\n\\tauthor={Adam R. Kosiorek and Hyunjik Kim and Ingmar Posner and Yee Whye Teh},\\n\\tbooktitle={Advances in Neural Information Processing Systems},\\n\\tyear={2018}\\n}',\n",
       " 'Goodman2008church': '@inproceedings{Goodman2008church,\\n  title={Church: A language for generative models},\\n  author={Goodman, Noah D and Mansinghka, Vikash K and Roy, Daniel M and Bonawitz, Keith and Tenenbaum, Joshua B},\\n  booktitle={Uncertainty in Artificial Intelligence},\\n  year={2008}\\n}',\n",
       " 'Wood2014new': '@inproceedings{Wood2014new,\\n  title={A New Approach to Probabilistic Programming Inference},\\n  author={Wood, Frank and van de Meent, Jan Willem and Mansinghka, Vikash},\\n  booktitle={Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics},\\n  pages={1024--1032},\\n  year={2014}\\n}',\n",
       " 'Mansinghka2014venture': '@article{Mansinghka2014venture,\\n  title={Venture: a higher-order probabilistic programming platform with programmable inference},\\n  author={Mansinghka, Vikash and Selsam, Daniel and Perov, Yura},\\n  journal={arXiv preprint arXiv:1404.0099},\\n  year={2014}\\n}',\n",
       " 'Siddharth2017learning': '@inproceedings{Siddharth2017learning,\\n  title\\t       = {Learning Disentangled Representations with Semi-Supervised Deep Generative Models},\\n  author       = {N. Siddharth and Brooks Paige and Jan-Willem van de Meent and Alban Desmaison and Noah D. Goodman and Pushmeet Kohli and Frank Wood and Philip H.~S. Torr},\\n  booktitle    = {Advances in Neural Information Processing Systems ({NIPS})},\\n  editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},\\n  pages\\t       = {5927--5937},\\n  month\\t       = dec,\\n  year\\t       = 2017,\\n  publisher    = {Curran Associates, Inc.}\\n}',\n",
       " 'Bingham2019pyro': '@article{Bingham2019pyro,\\n  title={Pyro: Deep universal probabilistic programming},\\n  author={Bingham, Eli and Chen, Jonathan P and Jankowiak, Martin and Obermeyer, Fritz and Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and Horsfall, Paul and Goodman, Noah D},\\n  journal={The Journal of Machine Learning Research},\\n  volume={20},\\n  number={1},\\n  pages={973--978},\\n  year={2019},\\n  publisher={JMLR.org}\\n}',\n",
       " 'Tran2017deep': '@inproceedings{Tran2017deep,\\n  author       = {Dustin Tran and Matthew D. Hoffman and Rif A. Saurous and Eugene Brevdo and Kevin Murphy and David M.\\n                  Blei},\\n  title        = {Deep probabilistic programming},\\n  booktitle    = {International Conference on Learning Representations},\\n  year         = 2017\\n}',\n",
       " 'Vandemeent2018intro': '@article{Vandemeent2018intro,\\n  author       = {{van de Meent}, Jan-Willem and {Paige}, Brooks and {Yang}, Hongseok and {Wood}, Frank},\\n  title        = \"{An Introduction to Probabilistic Programming}\",\\n  journal      = {arXiv e-prints},\\n  year         = 2018,\\n  month        = \"Sep\",\\n  eid          = {arXiv:1809.10756},\\n  archivePrefix= {arXiv},\\n  eprint       = {1809.10756},\\n  primaryClass = {stat.ML}\\n}',\n",
       " 'Denton2018stochastic': '@inproceedings{Denton2018stochastic,\\n  title={Stochastic Video Generation with a Learned Prior},\\n  author={Denton, Emily and Fergus, Rob},\\n  booktitle={ICML},\\n  year={2018}\\n}',\n",
       " 'Greff2017neuralem': '@inproceedings{Greff2017neuralem,\\n  title={Neural Expectation Maximization},\\n  author={Klaus Greff and Sjoerd van Steenkiste and J{\\\\\"u}rgen Schmidhuber},\\n  booktitle={NIPS},\\n  year={2017}\\n}',\n",
       " 'Steenkiste2018relationalnem': '@inproceedings{Steenkiste2018relationalnem,\\n  title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},\\n  author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and J{\\\\\"u}rgen Schmidhuber},\\n  booktitle={ICLR},\\n  year={2018},\\n}',\n",
       " 'Greff2016tagger': '@inproceedings{Greff2016tagger,\\n  title={Tagger: Deep Unsupervised Perceptual Grouping},\\n  author={Klaus Greff and Antti Rasmus and Mathias Berglund and Tele Hotloo Hao and Harri Valpola and J{\\\\\"u}rgen Schmidhuber},\\n  booktitle={NIPS},\\n  year={2016}\\n}',\n",
       " 'Ilin2017recurrentln': \"@inproceedings{Ilin2017recurrentln,\\n  title={Recurrent Ladder Networks},\\n  author={Alexander Ilin and Isabeau Pr{\\\\'e}mont-Schwarz and Tele Hotloo Hao and Antti Rasmus and Rinu Boney and Harri Valpola},\\n  booktitle={NIPS},\\n  year={2017}\\n}\",\n",
       " 'Hsieh2018ddpae': '@inproceedings{Hsieh2018ddpae,\\n  title={Learning to Decompose and Disentangle Representations for Video Prediction},\\n  author={Jun-Ting Hsieh and Bingbin Liu and De-An Huang and Li Fei-Fei and Juan Carlos Niebles},\\n  booktitle={NIPS},\\n  year={2018},\\n}\\nAutomatically generated by Mendeley Desktop 1.17.10\\nAny changes to this file will be lost if it is regenerated by Mendeley.\\n\\nBibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop',\n",
       " 'Rosa2016': \"@article{Rosa2016,\\nabstract = {There is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the 'big picture'. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century.},\\narchivePrefix = {arXiv},\\narxivId = {1611.00685},\\nauthor = {Rosa, Marek and Feyereisl, Jan and {The GoodAI Collective}},\\neprint = {1611.00685},\\njournal = {to be Publ. Nov. 2016},\\nmonth = {nov},\\ntitle = {{A Framework for Searching for General Artificial Intelligence}},\\nopturl = {http://arxiv.org/abs/1611.00685},\\nyear = {2016}\\n}\",\n",
       " 'Bialek2001': '@article{Bialek2001,\\nabstract = {We de predictive information Ipred(T) as the mutual information be-tween the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times T: I pred (T) can remain grow logarithmically, or grow as a fractional power law. If the time series allows us to learn a model with a number of param-eters, then I pred (T) grows logarithmically with a coef that counts the dimensionality of the model space. In contrast, power-law growth is associated, for example, with the learning of in parameter (or non-parametric) models such as continuous functions with smoothness con-straints. There are connections between the predictive information and measures of complexity that have been de both in learning theory and the analysis of physical systems through statistical mechanics and dynamical systems theory. Furthermore, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of Ipred(T) provides the unique measure for the complexity of dynam-ics underlying a time series. Finally, we discuss how these ideas may be useful in problems in physics, statistics, and biology.},\\nauthor = {Bialek, William and Nemenman, Ilya and Tishby, Naftali},\\noptdoi = {10.1162/089976601753195969},\\noptissn = {0899-7667},\\njournal = {Neural Comput.},\\nnumber = {11},\\npages = {2409--2463},\\ntitle = {{Predictability, Complexity, and Learning}},\\nopturl = {http://www.mitpressjournals.org/optdoi/10.1162/089976601753195969},\\nvolume = {13},\\nyear = {2001}\\n}',\n",
       " 'Duan2016a': '@article{Duan2016a,\\nabstract = {Deep reinforcement learning (deep RL) has been successful in learning sophis-ticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, bene-fiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \" fast \" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL 2 , the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\" slow \") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including ob-servations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \" fast \" RL algorithm on the current (previously unseen) MDP. We evaluate RL 2 experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL 2 is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL 2 on a vision-based navigation task and show that it scales up to high-dimensional problems.},\\narchivePrefix = {arXiv},\\narxivId = {1611.02779},\\nauthor = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter and Sutskever, Ilya and Abbeel, Pieter},\\noptdoi = {10.1051/0004-6361/201527329},\\neprint = {1611.02779},\\noptisbn = {2004012439},\\noptissn = {0004-6361},\\njournal = {arXiv},\\npages = {1--14},\\npmid = {23459267},\\ntitle = {{RL{\\\\^{}}2: Fast Reinforcement Learning Via Slow Reinforcement Learning}},\\nopturl = {https://arxiv.org/pdf/1611.02779v2.pdf},\\nyear = {2016}\\n}',\n",
       " 'Oconnor2017': \"@article{Oconnor2017,\\nabstract = {The vast majority of natural sensory data is temporally redundant. Video frames or audio samples which are sampled at nearby points in time tend to have similar values. Typically, deep learning algorithms take no advantage of this redundancy to reduce computation. This can be an obscene waste of energy. We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data. We do this by having neurons communicate a combination of their state, and their temporal change in state. Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a weight-update rule that is equivalent to a form of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain. We demonstrate that on MNIST and a temporal variant of MNIST, our algorithm performs about as well as a Multilayer Perceptron trained with backpropagation, despite only communicating discrete values between layers.},\\narchivePrefix = {arXiv},\\narxivId = {1706.04159},\\nauthor = {O'Connor, Peter and Gavves, Efstratios and Welling, Max},\\neprint = {1706.04159},\\ntitle = {{Temporally Efficient Deep Learning with Spikes}},\\nopturl = {http://arxiv.org/abs/1706.04159},\\nyear = {2017}\\n}\",\n",
       " 'Hornik1989': '@article{Hornik1989,\\nabstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators. ?? 1989.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},\\noptdoi = {10.1016/0893-6080(89)90020-8},\\neprint = {arXiv:1011.1669v3},\\noptisbn = {08936080 (optissn)},\\noptissn = {08936080},\\njournal = {Neural Networks},\\nkeywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},\\nmonth = {jan},\\nnumber = {5},\\npages = {359--366},\\npmid = {74},\\npublisher = {Elsevier Limited},\\ntitle = {{Multilayer feedforward networks are universal approximators}},\\nopturl = {http://linkinghub.elsevier.com/retrieve/pii/0893608089900208},\\nvolume = {2},\\nyear = {1989}\\n}',\n",
       " 'Bronstein2016': '@article{Bronstein2016,\\nabstract = {Many signal processing problems involve data whose underlying structure is non-Euclidean, but may be modeled as a manifold or (combinatorial) graph. For instance, in social networks, the characteristics of users can be modeled as signals on the vertices of the social graph. Sensor networks are graph models of distributed interconnected sensors, whose readings are modelled as time-dependent signals on the vertices. In genetics, gene expression data are modeled as signals defined on the regulatory network. In neuroscience, graph models are used to represent anatomical and functional structures of the brain. Modeling data given as points in a high-dimensional Euclidean space using nearest neighbor graphs is an increasingly popular trend in data science, allowing practitioners access to the intrinsic structure of the data. In computer graphics and vision, 3D objects are modeled as Riemannian manifolds (surfaces) endowed with properties such as color texture. Even more complex examples include networks of operators, e.g., functional correspondences or difference operators in a collection of 3D shapes, or orientations of overlapping cameras in multi-view vision (\"structure from motion\") problems. The complexity of geometric data and the availability of very large datasets (in the case of social networks, on the scale of billions) suggest the use of machine learning techniques. In particular, deep learning has recently proven to be a powerful tool for problems with large datasets with underlying Euclidean structure. The purpose of this paper is to overview the problems arising in relation to geometric deep learning and present solutions existing today for this class of problems, as well as key difficulties and future research directions.},\\narchivePrefix = {arXiv},\\narxivId = {1611.08097},\\nauthor = {Bronstein, Michael M and Bruna, Joan and Lecun, Yann and Szlam, Arthur and Vandergheynst, Pierre},\\noptdoi = {10.1109/MSP.2017.2693418},\\neprint = {1611.08097},\\noptissn = {1053-5888},\\njournal = {arXiv:1611.08097 [cs.CV]},\\nmonth = {nov},\\npages = {1--20},\\ntitle = {{Geometric deep learning: going beyond Euclidean data}},\\nopturl = {https://arxiv.org/abs/1611.08097{\\\\%}5Cnhttp://torch.ch/blog/2016/02/04/resnets.html},\\nyear = {2016}\\n}',\n",
       " 'Willia1992': '@article{Willia1992,\\nabstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},\\nauthor = {Willia, Ronald J.},\\noptdoi = {10.1023/A:1022672621406},\\noptisbn = {0885-6125},\\noptissn = {15730565},\\njournal = {Mach. Learn.},\\nkeywords = {Reinforcement learning,connectionist networks,gradient descent,mathematical analysis},\\nmonth = {may},\\nnumber = {3},\\npages = {229--256},\\npmid = {903},\\npublisher = {Kluwer Academic Publishers},\\ntitle = {{Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}},\\nopturl = {http://link.springer.com/10.1007/BF00992696},\\nvolume = {8},\\nyear = {1992}\\n}',\n",
       " 'Heess2017': '@article{Heess2017,\\nabstract = {The reinforcement learning paradigm allows, in principle, for complex behaviours to be learned directly from simple reward signals. In practice, however, it is common to carefully hand-design the reward function to encourage a particular solution, or to derive it from demonstration data. In this paper explore how a rich environment can help to promote the learning of complex behavior. Specifically, we train agents in diverse environmental contexts, and find that this encourages the emergence of robust behaviours that perform well across a suite of tasks. We demonstrate this principle for locomotion -- behaviours that are known for their sensitivity to the choice of reward. We train several simulated bodies on a diverse set of challenging terrains and obstacles, using a simple reward function based on forward progress. Using a novel scalable variant of policy gradient reinforcement learning, our agents learn to run, jump, crouch and turn as required by the environment without explicit reward-based guidance. A visual depiction of highlights of the learned behavior can be viewed following https://youtu.be/hx{\\\\_}bgoTF7bs .},\\narchivePrefix = {arXiv},\\narxivId = {1707.02286},\\nauthor = {Heess, Nicolas and TB, Dhruva and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, S. M. Ali and Riedmiller, Martin and Silver, David},\\neprint = {1707.02286},\\nmonth = {jul},\\ntitle = {{Emergence of Locomotion Behaviours in Rich Environments}},\\nopturl = {http://arxiv.org/abs/1707.02286},\\nyear = {2017}\\n}',\n",
       " 'Zhang2016': '@article{Zhang2016,\\nabstract = {In this paper, we systematically analyse the connecting architectures of recurrent neural networks (RNNs). Our main contribution is twofold: first, we present a rigorous graph-theoretic framework describing the connecting architectures of RNNs in general. Second, we propose three architecture complexity measures of RNNs: (a) the recurrent depth, which captures the RNN\\'s over-time nonlinear complexity, (b) the feedforward depth, which captures the local input-output nonlinearity (similar to the \"depth\" in feedforward neural networks (FNNs)), and (c) the recurrent skip coefficient which captures how rapidly the information propagates over time. Our experimental results show that RNNs might benefit from larger recurrent depth and feedforward depth. We further demonstrate that increasing recurrent skip coefficient offers performance boosts on long term dependency problems, as we improve the state-of-the-art for sequential MNIST dataset.},\\narchivePrefix = {arXiv},\\narxivId = {1602.08210},\\nauthor = {Zhang, Saizheng and Wu, Yuhuai and Che, Tong and Lin, Zhouhan and Memisevic, Roland and Salakhutdinov, Ruslan and Bengio, Yoshua},\\noptdoi = {10.1201/9781420049176},\\neprint = {1602.08210},\\noptisbn = {9789537619084},\\noptissn = {10495258},\\njournal = {Icml},\\nkeywords = {Complexity Measure,RNN},\\nmonth = {feb},\\nnumber = {Nips},\\npages = {19},\\ntitle = {{Architectural Complexity Measures of Recurrent Neural Networks}},\\nopturl = {http://arxiv.org/abs/1602.08210},\\nyear = {2016}\\n}',\n",
       " 'Krotov2016': '@article{Krotov2016,\\nabstract = {A model of associative memory is studied, which stores and reliably retrieves many more patterns than the number of neurons in the network. We propose a simple duality between this dense associative memory and neural networks commonly used in deep learning. On the associative memory side of this duality, a family of models that smoothly interpolates between two limiting cases can be constructed. One limit is referred to as the feature-matching mode of pattern recognition, and the other one as the prototype regime. On the deep learning side of the duality, this family corresponds to feedforward neural networks with one hidden layer and various activation functions, which transmit the activities of the visible neurons to the hidden layer. This family of activation functions includes logistics, rectified linear units, and rectified polynomials of higher degrees. The proposed duality makes it possible to apply energy-based intuition from associative memory to analyze computational properties of neural networks with unusual activation functions - the higher rectified polynomials which until now have not been used for training neural networks. The utility of the dense memories is illustrated for two test cases: the logical gate XOR and the recognition of handwritten digits from the MNIST data set.},\\narchivePrefix = {arXiv},\\narxivId = {1606.01164},\\nauthor = {Krotov, Dmitry and Hopfield, John J},\\neprint = {1606.01164},\\noptissn = {10495258},\\njournal = {Adv. Neural Inf. Process. Syst. 29 (NIPS 2016)},\\nnumber = {Nips},\\npages = {1--13},\\ntitle = {{Dense Associative Memory for Pattern Recognition}},\\nopturl = {http://arxiv.org/abs/1606.01164},\\nyear = {2016}\\n}',\n",
       " 'Jindal2017': \"@article{Jindal2017,\\nabstract = {Abstractâ€”Large datasets often have unreliable labelsâ€”such as those obtained from Amazon's Mechanical Turk or social media platformsâ€”and classifiers trained on mislabeled datasets often exhibit poor performance. We present a simple, effective technique for accounting for label noise when training deep neural networks. We augment a standard deep network with a softmax layer that models the label noise statistics. Then, we train the deep network and noise model jointly via end- to-end stochastic gradient descent on the (perhaps mislabeled) dataset. The augmented model is underdetermined, so in order to encourage the learning of a non-trivial noise model, we apply dropout regularization to the weights of the noise model during training. Numerical experiments on noisy versions of the CIFAR-10 and MNIST datasets show that the proposed dropout technique outperforms state-of-the-art methods.},\\narchivePrefix = {arXiv},\\narxivId = {1705.03419},\\nauthor = {Jindal, Ishan and Nokleby, Matthew and Chen, Xuewen},\\noptdoi = {10.1109/ICDM.2016.124},\\neprint = {1705.03419},\\noptisbn = {9781509054725},\\noptissn = {15504786},\\njournal = {Proc. - IEEE Int. Conf. Data Mining, ICDM},\\nkeywords = {Convolutional neural networks,Deep learning,Dropout regularization,Label noise,Supervised learning},\\nmonth = {may},\\npages = {967--972},\\ntitle = {{Learning deep networks from noisy labels with dropout regularization}},\\nopturl = {http://arxiv.org/abs/1705.03419},\\nyear = {2017}\\n}\",\n",
       " 'Duan2016': '@article{Duan2016,\\nabstract = {Recently, researchers have made significant progress combining the advances in deep learn-ing for learning feature representations with rein-forcement learning. Some notable examples in-clude training agents to play Atari games based on raw pixel data and to acquire advanced ma-nipulation skills using raw sensory inputs. How-ever, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of contin-uous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning al-gorithms. Both the benchmark and reference im-plementations are released open-source in order to facilitate experimental reproducibility and to encourage adoption by other researchers.},\\narchivePrefix = {arXiv},\\narxivId = {1604.06778v2},\\nauthor = {Duan, Yan and Chen, Xi and Schulman, John and Abbeel, Pieter},\\noptdoi = {10.1109/CVPR.2014.180},\\neprint = {1604.06778v2},\\noptisbn = {9781510829008},\\noptissn = {10636919},\\njournal = {arXiv},\\nmonth = {apr},\\npages = {14},\\ntitle = {{Benchmarking Deep Reinforcement Learning for Continuous Control}},\\nopturl = {http://arxiv.org/abs/1604.06778},\\nvolume = {48},\\nyear = {2016}\\n}',\n",
       " 'Fabius2015': '@article{Fabius2015,\\nabstract = {In this paper we propose a model that combines the strengths of RNNs and SGVB: the Variational Recurrent Auto-Encoder (VRAE). Such a model can be used for efficient, large scale unsupervised learning on time series data, mapping the time series data to a latent vector representation. The model is generative, such that data can be generated from samples of the latent space. An important contribution of this work is that the model can make use of unlabeled data in order to facilitate supervised training of RNNs by initialising the weights and network state.},\\narchivePrefix = {arXiv},\\narxivId = {1412.6581},\\nauthor = {Fabius, Otto and van Amersfoort, Joost R.},\\neprint = {1412.6581},\\njournal = {Iclr},\\nmonth = {dec},\\nnumber = {2013},\\npages = {1--5},\\ntitle = {{Variational Recurrent Auto-Encoders}},\\nopturl = {http://arxiv.org/abs/1412.6581},\\nyear = {2015}\\n}',\n",
       " 'Nguyen2017': '@article{Nguyen2017,\\nabstract = {Generating high-resolution, photo-realistic images has been a long-standing goal in machine learning. Recently, Nguyen et al. [36] showed one interesting way to synthesize novel images by performing gradient ascent in the latent space of a generator network to maximize the activations of one or multiple neurons in a separate classifier network. In this paper we extend this method by introducing an additional prior on the latent code, improving both sample quality and sample diversity, leading to a state-of-the-art generative model that produces high quality images at higher resolutions (227 Ã— 227) than previous generative models, and does so for all 1000 ImageNet categories. In addition, we provide a unified probabilistic interpretation of related activation maximization methods and call the general class of models â€œPlug and Play Generative Networks.â€ PPGNs are composed of 1) a generator network G that is capable of drawing a wide range of image types and 2) a replaceable â€œconditionâ€ network C that tells the generator what to draw. We demonstrate the generation of images conditioned on a class (when C is an ImageNet or MIT Places classification network) and also conditioned on a caption (when C is an image captioning network). Our method also improves the state of the art of Multifaceted Feature Visualization [39], which generates the set of synthetic inputs that activate a neuron in order to better understand how deep neural networks operate. Finally, we show that our model performs reasonably well at the task of image inpainting. While image models are used in this paper, the approach is modality-agnostic and can be applied to many types of data.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:submit/1738978},\\nauthor = {Nguyen, Anh and Yosinski, Jason and Bengio, Yoshua and Dosovitskiy, Alexey and Clune, Jeff},\\noptdoi = {10.1109/CVPR.2017.374},\\neprint = {1738978},\\njournal = {Iccv},\\nmonth = {nov},\\nnumber = {3},\\npages = {33},\\nprimaryClass = {arXiv:submit},\\ntitle = {{Plug {\\\\&} Play Generative Networks: Conditional Iterative Generation of Images in Latent Space}},\\nopturl = {http://arxiv.org/abs/1612.00005},\\nyear = {2017}\\n}',\n",
       " 'Andrychowicz2017': '@article{Andrychowicz2017,\\nabstract = {Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum. We demonstrate our approach on the task of manipulating objects with a robotic arm. In particular, we run experiments on three different tasks: pushing, sliding, and pick-and-place, in each case using only binary rewards indicating whether or not the task is completed. Our ablation studies show that Hindsight Experience Replay is a crucial ingredient which makes training possible in these challenging environments. We show that our policies trained on a physics simulation can be deployed on a physical robot and successfully complete the task.},\\narchivePrefix = {arXiv},\\narxivId = {1707.01495},\\nauthor = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},\\neprint = {1707.01495},\\ntitle = {{Hindsight Experience Replay}},\\nopturl = {http://arxiv.org/abs/1707.01495},\\nyear = {2017}\\n}',\n",
       " 'Rezende2016': '@inproceedings{Rezende2016,\\nabstract = {A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.},\\nauthor = {Rezende, Danilo Jimenez and Eslami, S. M. Ali and Mohamed, Shakir and Battaglia, Peter and Jaderberg, Max and Heess, Nicolas},\\nbooktitle = {NIPS},\\ntitle = {{Unsupervised Learning of 3D Structure from Images}},\\nopturl = {http://papers.nips.cc/paper/6600-unsupervised-learning-of-3d-structure-from-images http://arxiv.org/abs/1607.00662},\\nyear = {2016}\\n}',\n",
       " 'SÃ¸nderby2016': '@article{SÃ¸nderby2016,\\nabstract = {Variational Autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difficult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model, the Ladder Variational Autoencoder, that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally, we observe that batch normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.},\\narchivePrefix = {arXiv},\\narxivId = {1602.02282},\\nauthor = {S{\\\\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\\\\o}e, Lars and S{\\\\o}nderby, S{\\\\o}ren Kaae and Winther, Ole},\\neprint = {1602.02282},\\noptissn = {10495258},\\njournal = {Nips},\\nnumber = {Nips},\\ntitle = {{How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks}},\\nopturl = {http://arxiv.org/abs/1602.02282},\\nvolume = {48},\\nyear = {2016}\\n}',\n",
       " 'Versteeg2014': '@article{Versteeg2014,\\nabstract = {We consider a set of probabilistic functions of some input variables as a representation of the inputs. We present bounds on how informative a representation is about input data. We extend these bounds to hierarchical representations so that we can quantify the contribution of each layer towards capturing the information in the original data. The special form of these bounds leads to a simple, bottom-up optimization procedure to construct hierarchical representations that are also maximally informative about the data. This optimization has linear computational complexity and constant sample complexity in the number of variables. These results establish a new approach to unsupervised learning of deep representations that is both principled and practical. We demonstrate the usefulness of the approach on both synthetic and real-world data.},\\narchivePrefix = {arXiv},\\narxivId = {1410.7404},\\nauthor = {{Ver Steeg}, Greg and Galstyan, Aram},\\neprint = {1410.7404},\\noptisbn = {1410.7404},\\noptissn = {15337928},\\njournal = {arXiv},\\nmonth = {oct},\\npages = {13},\\ntitle = {{Maximally Informative Hierarchical Representations of High-Dimensional Data}},\\nopturl = {http://arxiv.org/abs/1410.7404},\\nyear = {2014}\\n}',\n",
       " 'Canziani2017': '@article{Canziani2017,\\nabstract = {In the past five years we have observed the rise of incredibly well performing feed-forward neural networks trained supervisedly for vision related tasks. These models have achieved super-human performance on object recognition, localisation, and detection in still images. However, there is a need to identify the best strategy to employ these networks with temporal visual inputs and obtain a robust and stable representation of video data. Inspired by the human visual system, we propose a deep neural network family, CortexNet, which features not only bottom-up feed-forward connections, but also it models the abundant top-down feedback and lateral connections, which are present in our visual cortex. We introduce two training schemes - the unsupervised MatchNet and weakly supervised TempoNet modes - where a network learns how to correctly anticipate a subsequent frame in a video clip or the identity of its predominant subject, by learning egomotion clues and how to automatically track several objects in the current scene. Find the project website at https://engineering.purdue.edu/elab/CortexNet/.},\\narchivePrefix = {arXiv},\\narxivId = {1706.02735},\\nauthor = {Canziani, Alfredo and Culurciello, Eugenio},\\neprint = {1706.02735},\\nmonth = {jun},\\ntitle = {{CortexNet: a Generic Network Family for Robust Visual Temporal Representations}},\\nopturl = {http://arxiv.org/abs/1706.02735},\\nyear = {2017}\\n}',\n",
       " 'Zhao2016': '@article{Zhao2016,\\nabstract = {We introduce the \"Energy-based Generative Adversarial Network\" (EBGAN) model which views the discriminator in GAN framework as an energy function that associates low energies with the regions near the data manifold and higher energies everywhere else. Similar to the probabilistic GANs, a generator is trained to produce contrastive samples with minimal energies, while the energy function is trained to assign high energies to those generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary discriminant network. Among them, an instantiation of EBGANs is to use an auto-encoder architecture alongside the energy being the reconstruction error. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.},\\narchivePrefix = {arXiv},\\narxivId = {1609.03126},\\nauthor = {Zhao, Junbo and Mathieu, Michael and LeCun, Yann},\\noptdoi = {10.1016/j.neunet.2014.10.001},\\neprint = {1609.03126},\\noptisbn = {9781509008063},\\noptissn = {18792782},\\njournal = {Nips},\\nmonth = {sep},\\nnumber = {2006},\\npages = {1--15},\\npmid = {25462632},\\ntitle = {{Energy-based Generative Adversarial Network}},\\nopturl = {http://arxiv.org/abs/1609.03126},\\nyear = {2016}\\n}',\n",
       " 'Valentin2016': \"@inproceedings{Valentin2016,\\nabstract = {In this paper, we present a novel and efficient architecture for addressing computer vision problems that use `Analysis by Synthesis'. Analysis by synthesis involves the minimization of the reconstruction error which is typically a non-convex function of the latent target variables. State-of-the-art methods adopt a hybrid scheme where discriminatively trained predictors like Random Forests or Convolutional Neural Networks are used to initialize local search algorithms. While these methods have been shown to produce promising results, they often get stuck in local optima. Our method goes beyond the conventional hybrid architecture by not only proposing multiple accurate initial solutions but by also defining a navigational structure over the solution space that can be used for extremely efficient gradient-free local search. We demonstrate the efficacy of our approach on the challenging problem of RGB Camera Relocalization. To make the RGB camera relocalization problem particularly challenging, we introduce a new dataset of 3D environments which are significantly larger than those found in other publicly-available datasets. Our experiments reveal that the proposed method is able to achieve state-of-the-art camera relocalization results. We also demonstrate the generalizability of our approach on Hand Pose Estimation and Image Retrieval tasks.},\\narchivePrefix = {arXiv},\\narxivId = {1603.05772},\\nauthor = {Valentin, Julien and Dai, Angela and Niessner, Matthias and Kohli, Pushmeet and Torr, Philip and Izadi, Shahram and Keskin, Cem},\\nbooktitle = {Proc. - 2016 4th Int. Conf. 3D Vision, 3DV 2016},\\noptdoi = {10.1109/3DV.2016.41},\\neprint = {1603.05772},\\noptisbn = {9781509054077},\\nmonth = {oct},\\npages = {323--332},\\npublisher = {IEEE},\\ntitle = {{Learning to navigate the energy landscape}},\\nopturl = {http://ieeexplore.ieee.org/document/7785106/},\\nyear = {2016}\\n}\",\n",
       " 'Yu2016unitbox': '@inproceedings{Yu2016unitbox,\\nabstract = {In present object detection systems, the deep convolutional neural networks (CNNs) are utilized to predict bounding boxes of object candidates, and have gained performance advantages over the traditional region proposal methods. However, existing deep CNN methods assume the object bounds to be four independent variables, which could be regressed by the l2 loss separately. Such an oversimplified assumption is contrary to the well-received observation, that those variables are correlated, resulting to less accurate localization. To address the issue, we firstly introduce a novel Intersection over Union (IoU) loss function for bounding box prediction, which regresses the four bounds of a predicted box as a whole unit. By taking the advantages of IoU loss and deep fully convolutional networks, the UnitBox is introduced, which performs accurate and efficient localization, shows robust to objects of varied shapes and scales, and converges fast. We apply UnitBox on face detection task and achieve the best performance among all published methods on the FDDB benchmark.},\\narchivePrefix = {arXiv},\\narxivId = {1608.01471},\\nauthor = {Yu, Jiahui and Jiang, Yuning and Wang, Zhangyang and Cao, Zhimin and Huang, Thomas},\\nbooktitle = {Proc. 2016 ACM Multimed. Conf.},\\noptdoi = {10.1145/2964284.2967274},\\neprint = {1608.01471},\\noptisbn = {978-1-4503-3603-1},\\nkeywords = {IoU loss,bounding box prediction,object detection},\\norganization = {ACM},\\npages = {516--520},\\ntitle = {{UnitBox: An Advanced Object Detection Network}},\\nopturl = {http://optdoi.acm.org/10.1145/2964284.2967274},\\nyear = {2016}\\n}',\n",
       " 'Lin2016': '@article{Lin2016,\\nabstract = {We show how the success of deep learning depends not only on mathematics but also on physics: although well-known mathematical theorems guarantee that neural networks can approximate arbitrary functions well, the class of functions of practical interest can be approximated through \"cheap learning\" with exponentially fewer parameters than generic ones, because they have simplifying properties tracing back to the laws of physics. The exceptional simplicity of physics-based functions hinges on properties such as symmetry, locality, compositionality and polynomial log-probability, and we explore how these properties translate into exceptionally simple neural networks approximating both natural phenomena such as images and abstract representations thereof such as drawings. We further argue that when the statistical process generating the data is of a certain hierarchical form prevalent in physics and machine-learning, a deep neural network can be more efficient than a shallow one. We formalize these claims using information theory and discuss the relation to renormalization group procedures. Various \"no-flattening theorems\" show when these efficient deep networks cannot be accurately approximated by shallow ones without efficiency loss - even for linear networks.},\\narchivePrefix = {arXiv},\\narxivId = {1608.08225},\\nauthor = {Lin, Henry W. and Tegmark, Max},\\noptdoi = {10.1109/5.726791},\\neprint = {1608.08225},\\noptisbn = {9781627480031},\\noptissn = {10495258},\\njournal = {arxiv.org e-Print Arch.},\\nmonth = {aug},\\npages = {14},\\npmid = {25246403},\\ntitle = {{Why does deep and cheap learning work so well?}},\\nopturl = {http://arxiv.org/abs/1608.08225},\\nvolume = {02139},\\nyear = {2016}\\n}',\n",
       " 'Kendall2017adaptive': \"@article{Kendall2017adaptive,\\nabstract = {Numerous deep learning applications benefit from multi-task learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task's loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.},\\narchivePrefix = {arXiv},\\narxivId = {1705.07115},\\nauthor = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},\\neprint = {1705.07115},\\njournal = {arXiv:1705.07115},\\nmonth = {may},\\ntitle = {{Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics}},\\nopturl = {http://arxiv.org/abs/1705.07115},\\nyear = {2017}\\n}\",\n",
       " 'Bahdanau2014': '@article{Bahdanau2014,\\nabstract = {Neural machine translation is a recently proposed approach to machine transla-tion. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neu-ral machine translation often belong to a family of encoderâ€“decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoderâ€“decoder architec-ture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},\\narchivePrefix = {arXiv},\\narxivId = {1409.0473},\\nauthor = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},\\noptdoi = {10.1146/annurev.neuro.26.041002.131047},\\neprint = {1409.0473},\\noptisbn = {0147-006X (Print)},\\noptissn = {0147-006X},\\njournal = {Iclr 2015},\\nkeywords = {Neural machine translation is a recently proposed,Unlike the traditional statistical machine transla,a source sentence into a fixed-length vector from,and propose to extend this by allowing a model to,bottleneck in improving the performance of this ba,for parts of a source sentence that are relevant t,having to form these parts as a hard segment expli,machine translation often belong to a family of en,maximize the translation performance. The models p,phrase-based system on the task of English-to-Fren,qualitative analysis reveals that the (soft-)align,the neural machine,translation aims at building a single neural netwo,translation. In this paper,we achieve a translation performance comparable to,we conjecture that the use of a fixed-length vecto,well with our intuition,without},\\nmonth = {sep},\\npages = {1--15},\\npmid = {14527267},\\ntitle = {{Neural Machine Translation By Jointly Learning To Align and Translate}},\\nopturl = {http://arxiv.org/abs/1409.0473v3},\\nyear = {2014}\\n}',\n",
       " 'Lu2016': '@article{Lu2016,\\nabstract = {Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as \"the\" and \"of\". Other words that may seem visual can often be predicted reliably just from the language model e.g., \"sign\" after \"behind a red stop\" or \"phone\" following \"talking on a cell\". In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.},\\narchivePrefix = {arXiv},\\narxivId = {1612.01887},\\nauthor = {Lu, Jiasen and Xiong, Caiming and Parikh, Devi and Socher, Richard},\\noptdoi = {10.1109/CVPR.2017.345},\\neprint = {1612.01887},\\njournal = {1612.01887V1},\\ntitle = {{Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning}},\\nopturl = {http://arxiv.org/abs/1612.01887},\\nyear = {2016}\\n}',\n",
       " 'Aitken2017': '@article{Aitken2017,\\nabstract = {The most prominent problem associated with the deconvolution layer is the presence of checkerboard artifacts in output images and dense labels. To combat this problem, smoothness constraints, post processing and different architecture designs have been proposed. Odena et al. highlight three sources of checkerboard artifacts: deconvolution overlap, random initialization and loss functions. In this note, we proposed an initialization method for sub-pixel convolution known as convolution NN resize. Compared to sub-pixel convolution initialized with schemes designed for standard convolution kernels, it is free from checkerboard artifacts immediately after initialization. Compared to resize convolution, at the same computational complexity, it has more modelling power and converges to solutions with smaller test errors.},\\narchivePrefix = {arXiv},\\narxivId = {1707.02937},\\nauthor = {Aitken, Andrew and Ledig, Christian and Theis, Lucas and Caballero, Jose and Wang, Zehan and Shi, Wenzhe},\\neprint = {1707.02937},\\nmonth = {jul},\\ntitle = {{Checkerboard artifact free sub-pixel convolution A note on sub-pixel convolution, resize convolution and convolution resize}},\\nopturl = {https://arxiv.org/pdf/1707.02937.pdf},\\nyear = {2017}\\n}',\n",
       " 'Friston2010': \"@article{Friston2010,\\nabstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception.},\\nauthor = {Friston, Karl J. and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J.},\\noptdoi = {10.1007/s00422-010-0364-z},\\noptisbn = {1432-0770 (Electronic)$\\\\backslash$n0340-1200 (Linking)},\\noptissn = {03401200},\\njournal = {Biol. Cybern.},\\nkeywords = {Bayesian,Computational,Control,Hierarchical,Motor,Priors},\\npmid = {20148260},\\ntitle = {{Action and behavior: A free-energy formulation}},\\nyear = {2010}\\n}\",\n",
       " 'Rezende2015': '@article{Rezende2015,\\nabstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},\\narchivePrefix = {arXiv},\\narxivId = {1505.05770},\\nauthor = {Rezende, Danilo Jimenez and Mohamed, Shakir},\\neprint = {1505.05770},\\noptisbn = {1505.05770},\\noptissn = {1938-7228},\\nmonth = {may},\\ntitle = {{Variational Inference with Normalizing Flows}},\\nopturl = {http://arxiv.org/abs/1505.05770},\\nyear = {2015}\\n}',\n",
       " 'Hinton2015rmsprop': '@misc{Hinton2015rmsprop,\\nauthor = {Geoffrey, Hinton and Srivastava, Nitish and Swersky, Kevin},\\ntitle = {{Overview of mini-batch gradient descent}},\\nopturl = {http://www.cs.toronto.edu/{\\\\%}5C{~}tijmen/csc321/slides/lecture{\\\\%}5C{\\\\_}slides{\\\\%}5C{\\\\_}lec6.pdf},\\nyear = {2012}\\n}',\n",
       " 'Figurnov2016': '@article{Figurnov2016,\\nabstract = {This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions.},\\narchivePrefix = {arXiv},\\narxivId = {1612.02297},\\nauthor = {Figurnov, Michael and Collins, Maxwell and Zhu, Yukun and Zhang, Li and Huang, Jonathan and Vetrov, Dmitry and Salakhutdinov, Ruslan},\\noptdoi = {10.1109/CVPR.2017.194},\\neprint = {1612.02297},\\njournal = {Arxiv},\\nmonth = {dec},\\ntitle = {{Spatially Adaptive Computation Time for Residual Networks}},\\nopturl = {http://arxiv.org/abs/1612.02297},\\nyear = {2016}\\n}',\n",
       " 'Achille2016': '@article{Achille2016,\\nabstract = {The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that information dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.},\\narchivePrefix = {arXiv},\\narxivId = {1611.01353},\\nauthor = {Achille, Alessandro and Soatto, Stefano},\\neprint = {1611.01353},\\njournal = {arXiv},\\nkeywords = {Autoencoder,Deep learning,Dropout,Variational dropout},\\nmonth = {nov},\\npages = {1--11},\\ntitle = {{Information Dropout: Learning Optimal Representations Through Noisy Computation}},\\nopturl = {http://arxiv.org/abs/1611.01353},\\nyear = {2016}\\n}',\n",
       " 'Hinton1994': '@article{Hinton1994,\\nauthor = {Hinton, GE and Zemel, RS},\\njournal = {Adv. neural Inf. Process.},\\ntitle = {{Autoencoders, minimum description length and Helmholtz free energy}},\\nopturl = {http://papers.nips.cc/paper/798-autoencoders-minimum-description-length-and-helmholtz-free-energy.pdf},\\nyear = {1994}\\n}',\n",
       " 'Werbos1990': '@article{Werbos1990,\\nabstract = {Basic backpropagation, which is a simple method now being widely$\\\\backslash$nused in areas like pattern recognition and fault diagnosis, is reviewed.$\\\\backslash$nThe basic equations for backpropagation through time, and applications$\\\\backslash$nto areas like pattern recognition involving dynamic systems, systems$\\\\backslash$nidentification, and control are discussed. Further extensions of this$\\\\backslash$nmethod, to deal with systems other than neural networks, systems$\\\\backslash$ninvolving simultaneous equations, or true recurrent networks, and other$\\\\backslash$npractical issues arising with the method are described. Pseudocode is$\\\\backslash$nprovided to clarify the algorithms. The chain rule for ordered$\\\\backslash$nderivatives-the theorem which underlies backpropagation-is briefly$\\\\backslash$ndiscussed. The focus is on designing a simpler version of$\\\\backslash$nbackpropagation which can be translated into computer code and applied$\\\\backslash$ndirectly by neutral network users},\\nauthor = {Werbos, Paul J.},\\noptdoi = {10.1109/5.58337},\\noptisbn = {0018-9219},\\noptissn = {15582256},\\njournal = {Proc. IEEE},\\nnumber = {10},\\npages = {1550--1560},\\ntitle = {{Backpropagation Through Time: What It Does and How to Do It}},\\nvolume = {78},\\nyear = {1990}\\n}',\n",
       " 'Zeiler2013': '@article{Zeiler2013,\\nabstract = {We introduce a simple and effective method for regularizing large convolutional neural networks. We replace the conventional deterministic pooling operations with a stochastic procedure, randomly picking the activation within each pooling region according to a multinomial distribution, given by the activities within the pooling region. The approach is hyper-parameter free and can be combined with other regularization approaches, such as dropout and data augmentation. We achieve state-of-the-art performance on four image datasets, relative to other approaches that do not utilize data augmentation.},\\narchivePrefix = {arXiv},\\narxivId = {1301.3557},\\nauthor = {Zeiler, Matthew D. and Fergus, Rob},\\neprint = {1301.3557},\\njournal = {Int. Conf. Represent. Learn.},\\npages = {1--9},\\ntitle = {{Stochastic Pooling for Regularization of Deep Convolutional Neural Networks}},\\nopturl = {http://arxiv.org/abs/1301.3557},\\nyear = {2013}\\n}',\n",
       " 'Goroshin2015a': '@misc{Goroshin2015a,\\nauthor = {Goroshin, Ross and Bruna, Joan and Tompson, Jonathan and Eigen, David and LeCun, Yann},\\npages = {4086--4093},\\ntitle = {{Unsupervised Learning of Spatiotemporally Coherent Metrics}},\\nopturl = {http://www.cv-foundation.org/openaccess/content{\\\\_}iccv{\\\\_}2015/html/Goroshin{\\\\_}Unsupervised{\\\\_}Learning{\\\\_}of{\\\\_}ICCV{\\\\_}2015{\\\\_}paper.html},\\nyear = {2015}\\n}',\n",
       " 'Rezende2014': '@inproceedings{Rezende2014,\\nabstract = {Abstract We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition ... $\\\\backslash$n},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1401.4082v3},\\nauthor = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},\\nbooktitle = {ICML},\\noptdoi = {10.1051/0004-6361/201527329},\\neprint = {arXiv:1401.4082v3},\\noptisbn = {9781634393973},\\noptissn = {10495258},\\nmonth = {jan},\\npages = {1278--1286},\\npmid = {23459267},\\ntitle = {{Stochastic backpropagation and approximate inference in deep generative models}},\\nopturl = {http://jmlr.org/proceedings/papers/v32/rezende14.html{\\\\%}5Cnpapers3://publication/uuid/F2747569-7719-4EAC-A5A7-9ECA9D6A8FE6},\\nvolume = {32},\\nyear = {2014}\\n}',\n",
       " 'Spring2016': '@article{Spring2016,\\nabstract = {Current deep learning architectures are growing larger in order to learn from enormous datasets.These architectures require giant matrix multiplication operations to train millions or billions of parameters during forward and back propagation steps. These operations are very expensive from a computational and energy standpoint. We present a novel technique to reduce the amount of computation needed to train and test deep net-works drastically. Our approach combines recent ideas from adaptive dropouts and randomized hashing for maximum inner product search to select only the nodes with the highest activation efficiently. Our new algorithm for training deep networks reduces the overall computational cost,of both feed-forward pass and backpropagation,by operating on significantly fewer nodes. As a consequence, our algorithm only requires 5{\\\\%} of computations (multiplications) compared to traditional algorithms, without any loss in the accuracy. Furthermore, due to very sparse gradient updates, our algorithm is ideally suited for asynchronous training leading to near linear speedup with increasing parallelism. We demonstrate the scalability and sustainability (energy efficiency) of our proposed algorithm via rigorous experimental evaluations.},\\narchivePrefix = {arXiv},\\narxivId = {1602.08194},\\nauthor = {Spring, Ryan and Shrivastava, Anshumali},\\neprint = {1602.08194},\\njournal = {arXiv:1602.08194},\\npages = {9},\\ntitle = {{Scalable and Sustainable Deep Learning via Randomized Hashing}},\\nopturl = {http://arxiv.org/abs/1602.08194},\\nyear = {2016}\\n}',\n",
       " 'Zhou2017': '@misc{Zhou2017,\\nabstract = {We present an unsupervised learning framework for the task of monocular depth and camera motion estimation from unstructured video sequences. We achieve this by simultaneously training depth and camera pose estimation networks using the task of view synthesis as the supervisory signal. The networks are thus coupled via the view synthesis objective during training, but can be applied independently at test time. Empirical evaluation on the KITTI dataset demonstrates the effectiveness of our approach: 1) monocular depth performing comparably with supervised methods that use either ground-truth pose or depth for training, and 2) pose estimation performing favorably with established SLAM systems under comparable input settings.},\\narchivePrefix = {arXiv},\\narxivId = {1704.07813},\\nauthor = {Zhou, Tinghui and Brown, Matthew and Snavely, Noah and Lowe, David G.},\\nbooktitle = {Cvpr 2017},\\noptdoi = {10.1109/CVPR.2017.700},\\neprint = {1704.07813},\\ntitle = {{Unsupervised Learning of Depth and Ego-Motion from Video}},\\nopturl = {http://arxiv.org/abs/1704.07813},\\nyear = {2017}\\n}',\n",
       " 'Zhang2017': '@article{Zhang2017,\\nabstract = {Convolutional neural network (CNN) models have achieved tremendous success in many visual detection and recognition tasks. Unfortunately, visual tracking, a fundamental computer vision problem, is not handled well using the existing CNN models, because most object trackers implemented with CNN do not effectively leverage temporal and contextual information among consecutive frames. Recurrent neural network (RNN) models, on the other hand, are often used to process text and voice data due to their ability to learn intrinsic representations of sequential and temporal data. Here, we propose a novel neural network tracking model that is capable of integrating information over time and tracking a selected target in video. It comprises three components: a CNN extracting best tracking features in each video frame, an RNN constructing video memory state, and a reinforcement learning (RL) agent making target location decisions. The tracking problem is formulated as a decision-making process, and our model can be trained with RL algorithms to learn good tracking policies that pay attention to continuous, inter-frame correlation and maximize tracking performance in the long run. We compare our model with an existing neural-network based tracking method and show that the proposed tracking approach works well in various scenarios by performing rigorous validation experiments on artificial video sequences with ground truth. To the best of our knowledge, our tracker is the first neural-network tracker that combines convolutional and recurrent networks with RL algorithms.},\\narchivePrefix = {arXiv},\\narxivId = {1701.08936},\\nauthor = {Zhang, Da and Maei, Hamid and Wang, Xin and Wang, Yuan-Fang},\\neprint = {1701.08936},\\ntitle = {{Deep Reinforcement Learning for Visual Object Tracking in Videos}},\\nopturl = {http://arxiv.org/abs/1701.08936},\\nyear = {2017}\\n}',\n",
       " 'Schulman2016': '@article{Schulman2016,\\nabstract = {This paper is concerned with developing policy gradient methods that gracefully scale up to challenging problems with high-dimensional state and action spaces. Towards this end, we develop a scheme that uses value functions to substantially reduce the variance of policy gradient estimates, while introducing a tolerable amount of bias. This scheme, which we call generalized advantage estimation (GAE), involves using a discounted sum of temporal differ-ence residuals as an estimate of the advantage function, and can be interpreted as a type of automated cost shaping. It is simple to implement and can be used with a variety of policy gradient methods and value function approximators. Along with this variance-reduction scheme, we use trust region algorithms to optimize the policy and value function, both represented as neural networks. We present experimental results on a number of highly challenging 3D loco-motion tasks, where our approach learns complex gaits for bipedal and quadrupedal simulated robots. We also learn controllers for the biped getting up off the ground. In contrast to prior work that uses hand-crafted low-dimensional policy representations, our neural network policies map directly from raw kinematics to joint torques.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1506.02438v1},\\nauthor = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},\\neprint = {arXiv:1506.02438v1},\\njournal = {arXiv},\\nmonth = {jun},\\npages = {1--9},\\ntitle = {{High-Dimensional Continuous Control Using Generalized Advantage Estimation}},\\nopturl = {http://arxiv.org/abs/1506.02438},\\nyear = {2016}\\n}',\n",
       " 'Mnih2015': '@article{Mnih2015,\\nauthor = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},\\noptdoi = {10.1038/nature14236},\\noptissn = {0028-0836},\\njournal = {Nature},\\nmonth = {feb},\\nnumber = {7540},\\npages = {529--533},\\ntitle = {{Human-level control through deep reinforcement learning}},\\nopturl = {http://www.nature.com/optdoifinder/10.1038/nature14236},\\nvolume = {518},\\nyear = {2015}\\n}',\n",
       " 'Henaff2016': \"@article{Henaff2016,\\nabstract = {We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.},\\narchivePrefix = {arXiv},\\narxivId = {1612.03969},\\nauthor = {Henaff, Mikael and Weston, Jason and Szlam, Arthur and Bordes, Antoine and LeCun, Yann},\\noptdoi = {10.1146/annurev.energy.28.050302.105509},\\neprint = {1612.03969},\\noptisbn = {1930865988},\\noptissn = {1543-5938},\\njournal = {Annu. Rev. Environ. Resour.},\\nmonth = {dec},\\nnumber = {2003},\\npages = {59--99},\\ntitle = {{Tracking the World State with Recurrent Entity Networks}},\\nopturl = {file:///Users/josemontero/Documents/CAPES{\\\\_}2014/Descartes/descartes{\\\\_}DropBox/Dropbox/Papers/2003{\\\\_}Hilborn et al.{\\\\_}S Tate of the W Orld ? S F Isheries.pdf{\\\\%}5Cnhttp://arxiv.org/abs/1612.03969},\\nvolume = {28},\\nyear = {2016}\\n}\",\n",
       " 'Held2016': \"@inproceedings{Held2016,\\nabstract = {Machine learning techniques are often used in computer vision due to their ability to leverage large amounts of training data to improve performance. Unfortunately, most generic object trackers are still trained from scratch online and do not benefit from the large number of videos that are readily available for offline training. We propose a method for using neural networks to track generic objects in a way that allows them to improve performance by training on labeled videos. Previous attempts to use neural networks for tracking are very slow to run and not practical for real-time applications. In contrast, our tracker uses a simple feed-forward network with no online training required, allowing our tracker to run at 100 fps during test time. Our tracker trains from both labeled video as well as a large collection of images, which helps prevent overfitting. The tracker learns generic object motion and can be used to track novel objects that do not appear in the training set. We test our network on a standard tracking benchmark to demonstrate our tracker's state-of-the-art performance. Our network learns to track generic objects in real-time as they move throughout the world.},\\narchivePrefix = {arXiv},\\narxivId = {1604.01802},\\nauthor = {Held, David and Thrun, Sebastian and Savarese, Silvio},\\nbooktitle = {ECCV Work.},\\noptdoi = {10.1007/978-3-319-46448-0_45},\\neprint = {1604.01802},\\noptisbn = {9783319464473},\\noptissn = {16113349},\\nkeywords = {Deep learning,Machine learning,Neural networks,Tracking},\\norganization = {Springer},\\npmid = {4520227},\\ntitle = {{Learning to track at 100 FPS with deep regression networks}},\\nyear = {2016}\\n}\",\n",
       " 'Walch2016': \"@article{Walch2016,\\nabstract = {In this work we propose a new CNN+LSTM architecture for camera pose regression for indoor and outdoor scenes. CNNs allow us to learn suitable feature representations for localization that are robust against motion blur and illumination changes. We make use of LSTM units on the CNN output, which play the role of a structured dimensionality reduction on the feature vector, leading to drastic improvements in localization performance. We provide extensive quantitative comparison of CNN-based vs SIFT-based localization methods, showing the weaknesses and strengths of each. Furthermore, we present a new large-scale indoor sequence with accurate ground truth from a laser scanner. Experimental results on both indoor and outdoor public datasets show our method outperforms existing deep architectures, and can localize images in hard conditions, e.g., in the presence of mostly textureless surfaces, where classic SIFT-based methods fail.},\\narchivePrefix = {arXiv},\\narxivId = {1611.07890},\\nauthor = {Walch, Florian and Hazirbas, Caner and Leal-Taix{\\\\'{e}}, Laura and Sattler, Torsten and Hilsenbeck, Sebastian and Cremers, Daniel},\\neprint = {1611.07890},\\njournal = {CoRR},\\ntitle = {{Image-based localization using LSTMs for structured feature correlation}},\\nopturl = {http://arxiv.org/abs/1611.07890},\\nvolume = {abs/1611.0},\\nyear = {2016}\\n}\",\n",
       " 'Wenzhe2016': '@inproceedings{Wenzhe2016,\\nabstract = {Recently, several models based on deep neural networks have achieved great success in terms of both reconstruction accuracy and computational performance for single image super-resolution. In these methods, the low resolution (LR) input image is upscaled to the high resolution (HR) space using a single filter, commonly bicubic interpolation, before reconstruction. This means that the super-resolution (SR) operation is performed in HR space. We demonstrate that this is sub-optimal and adds computational complexity. In this paper, we present the first convolutional neural network (CNN) capable of real-time SR of 1080p videos on a single K2 GPU. To achieve this, we propose a novel CNN architec-ture where the feature maps are extracted in the LR space. In addition, we introduce an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale the final LR feature maps into the HR output. By optdoing so, we effectively replace the handcrafted bicubic filter in the SR pipeline with more complex upscaling filters specifically trained for each feature map, whilst also reducing the computational complexity of the overall SR operation. We evaluate the proposed approach using images and videos from publicly available datasets and show that it performs significantly better (+0.15dB on Images and +0.39dB on Videos) and is an order of magnitude faster than previous CNN-based methods.},\\narchivePrefix = {arXiv},\\narxivId = {1609.05158},\\nauthor = {Wenzhe, Shi and Caballero, Jose and Huszar, Ferenc and Totz, Johannes and Aitken, Andrew P. and Bishop, Rob and Rueckert, Daniel and Wang, Zehan},\\nbooktitle = {CVPR},\\noptdoi = {10.1109/CVPR.2016.207},\\neprint = {1609.05158},\\noptisbn = {978-1-4673-8851-1},\\nmonth = {sep},\\npages = {1874--1883},\\ntitle = {{Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network}},\\nopturl = {http://arxiv.org/abs/1609.05158},\\nyear = {2016}\\n}',\n",
       " 'Gu2016': '@article{Gu2016,\\nabstract = {Model-free reinforcement learning has been successfully applied to a range of challenging problems, and has recently been extended to handle large neural network policies and value functions. However, the sample complexity of model-free algorithms, particularly when using high-dimensional function approximators, tends to limit their applicability to physical systems. In this paper, we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks. We propose two complementary techniques for improving the efficiency of such algorithms. First, we derive a continuous variant of the Q-learning algorithm, which we call normalized adantage functions (NAF), as an alternative to the more commonly used policy gradient and actor-critic methods. NAF representation allows us to apply Q-learning with experience replay to continuous tasks, and substantially improves performance on a set of simulated robotic control tasks. To further improve the efficiency of our approach, we explore the use of learned models for accelerating model-free reinforcement learning. We show that iteratively refitted local linear models are especially effective for this, and demonstrate substantially faster learning on domains where such models are applicable.},\\narchivePrefix = {arXiv},\\narxivId = {1603.00748},\\nauthor = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},\\neprint = {1603.00748},\\nmonth = {mar},\\ntitle = {{Continuous Deep Q-Learning with Model-based Acceleration}},\\nopturl = {http://arxiv.org/abs/1603.00748},\\nyear = {2016}\\n}',\n",
       " 'Lake2016': '@article{Lake2016,\\nabstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving perfor- mance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recog- nition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},\\narchivePrefix = {arXiv},\\narxivId = {1604.00289},\\nauthor = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},\\noptdoi = {1511.09249v1},\\neprint = {1604.00289},\\noptisbn = {9781577357384},\\noptissn = {14691825},\\njournal = {arXiv:1604.00289v1[cs.AI]},\\nmonth = {apr},\\nnumber = {2012},\\npages = {1--54},\\npmid = {1000303116},\\ntitle = {{Building Machines that learn and think like people}},\\nopturl = {http://arxiv.org/abs/1604.00289 https://arxiv.org/pdf/1604.00289v1.pdf},\\nyear = {2016}\\n}',\n",
       " 'Gemici2017': \"@article{Gemici2017,\\nabstract = {We consider the general problem of modeling temporal data with long-range dependencies, wherein new observations are fully or partially predictable based on temporally-distant, past observations. A sufficiently powerful temporal model should separate predictable elements of the sequence from unpredictable elements, express uncertainty about those unpredictable elements, and rapidly identify novel elements that may help to predict the future. To create such models, we introduce Generative Temporal Models augmented with external memory systems. They are developed within the variational inference framework, which provides both a practical training methodology and methods to gain insight into the models' operation. We show, on a range of problems with sparse, long-term temporal dependencies, that these models store information from early in a sequence, and reuse this stored information efficiently. This allows them to perform substantially better than existing models based on well-known recurrent neural networks, like LSTMs.},\\narchivePrefix = {arXiv},\\narxivId = {1702.04649},\\nauthor = {Gemici, Mevlana and Hung, Chia-Chun and Santoro, Adam and Wayne, Greg and Mohamed, Shakir and Rezende, Danilo J. and Amos, David and Lillicrap, Timothy},\\neprint = {1702.04649},\\njournal = {arXiv Prepr.},\\npages = {1--25},\\ntitle = {{Generative Temporal Models with Memory}},\\nopturl = {http://arxiv.org/abs/1702.04649},\\nyear = {2017}\\n}\",\n",
       " 'Krueger2016': \"@inproceedings{Krueger2016,\\nabstract = {We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find that zoneout gives significant performance improvements across tasks. We achieve competitive results with relatively simple models in character- and word-level language modelling on the Penn Treebank and Text8 datasets, and combining with recurrent batch normalization yields state-of-the-art results on permuted sequential MNIST.},\\narchivePrefix = {arXiv},\\narxivId = {1606.01305},\\nauthor = {Krueger, David and Maharaj, Tegan and Kram{\\\\'{a}}r, J{\\\\'{a}}nos and Pezeshki, Mohammad and Ballas, Nicolas and Ke, Nan Rosemary and Goyal, Anirudh and Bengio, Yoshua and Courville, Aaron and Pal, Chris},\\nbooktitle = {ICLR},\\neprint = {1606.01305},\\ntitle = {{Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations}},\\nopturl = {http://arxiv.org/abs/1606.01305},\\nyear = {2017}\\n}\",\n",
       " 'Friston2009': '@article{Friston2009,\\nabstract = {This paper questions the need for reinforcement learning or control theory when optimising behaviour. We show that it is fairly simple to teach an agent complicated and adaptive behaviours using a free-energy formulation of perception. In this formulation, agents adjust their internal states and sampling of the environment to minimize their free-energy. Such agents learn causal structure in the environment and sample it in an adaptive and self-supervised fashion. This results in behavioural policies that reproduce those optimised by reinforcement learning and dynamic programming. Critically, we do not need to invoke the notion of reward, value or utility. We illustrate these points by solving a benchmark problem in dynamic programming; namely the mountain-car problem, using active perception or inference under the free-energy principle. The ensuing proof-of-concept may be important because the free-energy formulation furnishes a unified account of both action and perception and may speak to a reappraisal of the role of dopamine in the brain.},\\nauthor = {Friston, Karl J. and Daunizeau, Jean and Kiebel, Stefan J.},\\noptdoi = {10.1371/journal.pone.0006421},\\neditor = {Sporns, Olaf},\\noptisbn = {1932-6203 (Electronic) 1932-6203 (Linking)},\\noptissn = {19326203},\\njournal = {PLoS One},\\nmonth = {jul},\\nnumber = {7},\\npages = {e6421},\\npmid = {19641614},\\npublisher = {Dover},\\ntitle = {{Reinforcement learning or active inference?}},\\nopturl = {http://dx.plos.org/10.1371/journal.pone.0006421},\\nvolume = {4},\\nyear = {2009}\\n}',\n",
       " 'Wang2016': \"@article{Wang2016,\\nabstract = {Neural networks have shown to be a practical way of building a very complex mapping between a pre-specified input space and output space. For example, a convolutional neural network (CNN) mapping an image into one of a thousand object labels is approaching human performance in this particular task. However the mapping (neural network) does not automatically lend itself to other forms of queries, for example, to detect/reconstruct object instances, to enforce top-down signal on ambiguous inputs, or to recover object instances from occlusion. One way to address these queries is a backward pass through the network that fuses top-down and bottom-up information. In this paper, we show a way of building such a backward pass by defining a generative model of the neural network's activations. Approximate inference of the model would naturally take the form of a backward pass through the CNN layers, and it addresses the aforementioned queries in a unified framework.},\\narchivePrefix = {arXiv},\\narxivId = {1611.02767},\\nauthor = {Wang, Huayan and Chen, Anna and Liu, Yi and George, Dileep and Phoenix, D. Scott},\\neprint = {1611.02767},\\nmonth = {nov},\\ntitle = {{A backward pass through a CNN using a generative model of its activations}},\\nopturl = {http://arxiv.org/abs/1611.02767},\\nyear = {2016}\\n}\",\n",
       " 'Kaiser2016': '@misc{Kaiser2016,\\nabstract = {Several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in re-cent years. Attention has improved image classification, image captioning, speech recognition, generative models, and learning algorithmic tasks, but it had probably the largest impact on neural machine translation. Recently, similar improvements have been obtained using alternative mechanisms that do not focus on a single part of a memory but operate on all of it in parallel, in a uniform way. Such mechanism, which we call active memory, improved over attention in algorithmic tasks, image processing, and in generative modelling. So far, however, active memory has not improved over attention for most natural language processing tasks, in particular for machine translation. We analyze this shortcoming in this paper and propose an extended model of active memory that matches existing attention models on neural machine translation and generalizes better to longer sentences. We investigate this model and explain why previous active memory models did not succeed. Finally, we discuss when active memory brings most benefits and where attention can be a better choice.},\\narchivePrefix = {arXiv},\\narxivId = {1610.08613},\\nauthor = {Kaiser, {\\\\L}ukasz and Bengio, Samy},\\nbooktitle = {Nips},\\neprint = {1610.08613},\\noptissn = {10495258},\\nkeywords = {()},\\nnumber = {Nips},\\npages = {1--8},\\ntitle = {{Can Active Memory Replace Attention ?}},\\nopturl = {https://research.google.com/pubs/pub45663.html},\\nyear = {2016}\\n}',\n",
       " 'Bewley2016alextrac': '@inproceedings{Bewley2016alextrac,\\nauthor = {Bewley, Alex and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},\\nbooktitle = {Int. Conf. Robot. Autom.},\\noptisbn = {9781467380256},\\npages = {2212--2218},\\npublisher = {IEEE},\\ntitle = {{ALExTRAC : Affinity Learning by Exploring Temporal Reinforcement within Association Chains}},\\nyear = {2016}\\n}',\n",
       " 'Kingma2014': '@inproceedings{Kingma2014,\\nabstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},\\narchivePrefix = {arXiv},\\narxivId = {1312.6114},\\nauthor = {Kingma, Diederik P and Welling, Max},\\nbooktitle = {ICLR},\\noptdoi = {10.1051/0004-6361/201527329},\\neprint = {1312.6114},\\noptisbn = {1312.6114v10},\\noptissn = {1312.6114v10},\\nmonth = {dec},\\npmid = {23459267},\\ntitle = {{Auto-Encoding Variational Bayes}},\\nopturl = {http://arxiv.org/abs/1312.6114},\\nyear = {2014}\\n}',\n",
       " 'Laukien2016': '@article{Laukien2016,\\nabstract = {Efforts at understanding the computational processes in the brain have met with limited success, despite their importance and potential uses in building intelligent machines. We propose a simple new model which draws on recent findings in Neuroscience and the Applied Mathematics of interacting Dynamical Systems. The Feynman Machine is a Universal Computer for Dynamical Systems, analogous to the Turing Machine for symbolic computing, but with several important differences. We demonstrate that networks and hierarchies of simple interacting Dynamical Systems, each adaptively learning to forecast its evolution, are capable of automatically building sensorimotor models of the external and internal world. We identify such networks in mammalian neocortex, and show how existing theories of cortical computation combine with our model to explain the power and flexibility of mammalian intelligence. These findings lead directly to new architectures for machine intelligence. A suite of software implementations has been built based on these principles, and applied to a number of spatiotemporal learning tasks.},\\narchivePrefix = {arXiv},\\narxivId = {1609.03971},\\nauthor = {Laukien, Eric and Crowder, Richard and Byrne, Fergal},\\neprint = {1609.03971},\\nmonth = {sep},\\npages = {1--28},\\ntitle = {{Feynman Machine: The Universal Dynamical Systems Computer}},\\nopturl = {http://arxiv.org/abs/1609.03971},\\nyear = {2016}\\n}',\n",
       " 'Wu2016': '@article{Wu2016,\\nabstract = {Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT\\'s use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google\\'s Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT\\'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60{\\\\%} compared to Google\\'s phrase-based production system.},\\narchivePrefix = {arXiv},\\narxivId = {1609.08144v2},\\nauthor = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and Klingner, Jeff and Shah, Apurva and Johnson, Melvin and Liu, Xiaobing and Kaiser, {\\\\L}ukasz and Gouws, Stephan and Kato, Yoshikiyo and Kudo, Taku and Kazawa, Hideto and Stevens, Keith and Kurian, George and Patil, Nishant and Wang, Wei and Young, Cliff and Smith, Jason and Riesa, Jason and Rudnick, Alex and Vinyals, Oriol and Corrado, Greg and Hughes, Macduff and Dean, Jeffrey},\\neprint = {1609.08144v2},\\njournal = {arXiv},\\nkeywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Learning},\\nmonth = {sep},\\npages = {1--23},\\ntitle = {{Google\\'s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}},\\nopturl = {http://arxiv.org/abs/1609.08144},\\nyear = {2016}\\n}',\n",
       " 'Silver2014': '@misc{Silver2014,\\nabstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic pol- icy gradient has a particularly appealing form: it is the expected gradient of the action-value func- tion. This simple form means that the deter- ministic policy gradient can be estimated much more efficiently than the usual stochastic pol- icy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counter- parts in high-dimensional action spaces.},\\nauthor = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},\\nbooktitle = {Proc. 31st Int. Conf. Mach. Learn.},\\noptisbn = {9781634393973},\\npages = {387--395},\\npublisher = {JMLR.org},\\ntitle = {{Deterministic Policy Gradient Algorithms}},\\nopturl = {http://dl.acm.org/citation.cfm?id=3044850},\\nyear = {2014}\\n}',\n",
       " 'Achille2017': '@article{Achille2017,\\nabstract = {Using classical notions of statistical decision and information theory, we show that invariance in a deep neural network is equivalent to minimality of the representation it computes, and can be achieved by stacking layers and injecting noise in the computation, under realistic and empirically validated assumptions. We use an Information Decomposition of the empirical loss to show that overfitting can be reduced by limiting the information content stored in the weights. We then present a sharp inequality that relates the information content in the weights -- which are a representation of the training set and inferred by generic optimization agnostic of invariance and disentanglement -- and the minimality and total correlation of the activation functions, which are a representation of the test datum. This allows us to tackle recent puzzles concerning the generalization properties of deep networks and their relation to the geometry of the optimization residual.},\\narchivePrefix = {arXiv},\\narxivId = {1706.01350},\\nauthor = {Achille, Alessandro and Soatto, Stefano},\\neprint = {1706.01350},\\nmonth = {jun},\\ntitle = {{On the Emergence of Invariance and Disentangling in Deep Representations}},\\nopturl = {http://arxiv.org/abs/1706.01350},\\nyear = {2017}\\n}',\n",
       " 'Scellier2016': '@article{Scellier2016,\\nabstract = {This work follows Bengio and Fischer (2015) in which theoretical foundations were laid to show how iterative in-ference can backpropagate error signals. Neurons move their activations towards configurations corresponding to lower energy and smaller prediction error: a new observation creates a perturbation at visible neurons that propagates into hid-den layers, with these propagated perturbations corresponding to the back-propagated gradient. This avoids the need for a lengthy relaxation in the positive phase of training (when both inputs and targets are observed), as was believed with previous work on fixed-point recurrent networks. We show experimentally that energy-based neural networks with sev-eral hidden layers can be trained at discriminative tasks by using iterative inference and an STDP-like learning rule. The main result of this paper is that we can train neural networks with 1, 2 and 3 hidden layers on the permutation-invariant MNIST task and get the training error down to 0.00{\\\\%}. The results presented here make it more biologically plausible that a mechanism similar to back-propagation may take place in brains in order to achieve credit assignment in deep networks. The paper also discusses some of the remaining open problems to achieve a biologically plausible implementation of backprop in brains.},\\narchivePrefix = {arXiv},\\narxivId = {1602.05179},\\nauthor = {Scellier, Benjamin and Bengio, Yoshua},\\noptdoi = {10.3389/fncom.2017.00024},\\neprint = {1602.05179},\\noptissn = {1662-5188},\\njournal = {arXiv},\\nkeywords = {Backpropagation,Equilibrium Propagation},\\nmonth = {feb},\\nnumber = {1987},\\npages = {1--13},\\npmid = {28522969},\\ntitle = {{Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation}},\\nopturl = {http://arxiv.org/abs/1602.05179},\\nyear = {2016}\\n}',\n",
       " 'Covington2016': \"@article{Covington2016,\\nabstract = {YouTube represents one of the largest scale and most sophis-ticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and fo-cus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a sepa-rate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintain-ing a massive recommendation system with enormous user-facing impact.},\\nauthor = {Covington, Paul and Adams, Jay and Sargin, Emre},\\noptdoi = {10.1145/2959100.2959190},\\noptisbn = {9781450340359},\\njournal = {Proc. 10th ACM Conf. Recomm. Syst. - RecSys '16},\\nkeywords = {deep learning,recommender system,scalability},\\npages = {191--198},\\ntitle = {{Deep Neural Networks for YouTube Recommendations}},\\nopturl = {http://dl.acm.org/citation.cfm?optdoid=2959100.2959190},\\nyear = {2016}\\n}\",\n",
       " 'Itti2009': \"@article{Itti2009,\\nabstract = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72{\\\\%} of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84{\\\\%} when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction. {\\\\textcopyright} 2008 Elsevier Ltd. All rights reserved.},\\narchivePrefix = {arXiv},\\narxivId = {NIHMS150003},\\nauthor = {Itti, Laurent and Baldi, Pierre},\\noptdoi = {10.1016/j.visres.2008.09.007},\\neprint = {NIHMS150003},\\noptisbn = {1878-5646 (Electronic)$\\\\backslash$r1878-5646 (Linking)},\\noptissn = {00426989},\\njournal = {Vision Res.},\\nkeywords = {Attention,Bayes theorem,Eye movements,Free viewing,Information theory,Natural vision,Novelty,Saliency,Surprise},\\nmonth = {jun},\\nnumber = {10},\\npages = {1295--1306},\\npmid = {18834898},\\ntitle = {{Bayesian surprise attracts human attention}},\\nopturl = {http://linkinghub.elsevier.com/retrieve/pii/S0042698908004380},\\nvolume = {49},\\nyear = {2009}\\n}\",\n",
       " 'Gregor2016': '@article{Gregor2016,\\nabstract = {In this paper we introduce a new unsupervised reinforcement learning method for discovering the set of intrinsic options available to an agent. This set is learned by maximizing the number of different states an agent can reliably reach, as measured by the mutual information between the set of options and option termination states. To this end, we instantiate two policy gradient based algorithms, one that creates an explicit embedding space of options and one that represents options implicitly. The algorithms also provide an explicit measure of empowerment in a given state that can be used by an empowerment maximizing agent. The algorithm scales well with function approximation and we demonstrate the applicability of the algorithm on a range of tasks.},\\narchivePrefix = {arXiv},\\narxivId = {1611.07507},\\nauthor = {Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},\\neprint = {1611.07507},\\njournal = {arXiv:1611.07507v1 [cs.LG]},\\nmonth = {nov},\\npages = {1--15},\\ntitle = {{Variational Intrinsic Control}},\\nopturl = {http://arxiv.org/abs/1611.07507},\\nyear = {2016}\\n}',\n",
       " 'Pan2010': '@misc{Pan2010,\\nabstract = {A survey on transfer learning. IEEE Trans. Knowl. Data Eng},\\narchivePrefix = {arXiv},\\narxivId = {PAI},\\nauthor = {Pan, Sinno Jialin and Yang, Qiang},\\nbooktitle = {IEEE Trans. Knowl. Data Eng.},\\noptdoi = {10.1109/TKDE.2009.191},\\neprint = {PAI},\\noptisbn = {1041-4347 VO - 22},\\noptissn = {10414347},\\nkeywords = {Transfer learning,data mining.,machine learning,survey},\\nmonth = {oct},\\nnumber = {10},\\npages = {1345--1359},\\ntitle = {{A survey on transfer learning}},\\nopturl = {http://ieeexplore.ieee.org/document/5288526/},\\nvolume = {22},\\nyear = {2010}\\n}',\n",
       " 'Kosiorek2017': '@inproceedings{Kosiorek2017,\\nabstract = {Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate \"where\" and \"what\" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset.},\\narchivePrefix = {arXiv},\\narxivId = {1706.09262},\\nauthor = {Kosiorek, Adam R. and Bewley, Alex and Posner, Ingmar},\\nbooktitle = {NIPS},\\neprint = {1706.09262},\\nmonth = {jun},\\ntitle = {{Hierarchical Attentive Recurrent Tracking}},\\nopturl = {http://arxiv.org/abs/1706.09262},\\nyear = {2017}\\n}',\n",
       " 'Agrawal2016': '@article{Agrawal2016,\\nabstract = {Variational autoencoders (VAEs), that are built upon deep neural networks have emerged as popular generative models in computer vision. Most of the work towards improving variational autoencoders has focused mainly on making the approximations to the posterior flexible and accurate, leading to tremendous progress. However, there have been limited efforts to replace pixel-wise reconstruction, which have known shortcomings. In this work, we use real-valued non-volume preserving transformations (real NVP) to exactly compute the conditional likelihood of the data given the latent distribution. We show that a simple VAE with this form of reconstruction is competitive with complicated VAE structures, on image modeling tasks. As part of our model, we develop powerful conditional coupling layers that enable real NVP to learn with fewer intermediate layers.},\\narchivePrefix = {arXiv},\\narxivId = {1611.05209},\\nauthor = {Agrawal, Siddharth and Dukkipati, Ambedkar},\\neprint = {1611.05209},\\nmonth = {nov},\\ntitle = {{Deep Variational Inference Without Pixel-Wise Reconstruction}},\\nopturl = {http://arxiv.org/abs/1611.05209},\\nyear = {2016}\\n}',\n",
       " 'Karl2017': '@inproceedings{Karl2017,\\nabstract = {We introduce Deep Variational Bayes Filters (DVBF), a new methhttps://arxiv.org/pdf/1605.06432.pdfod for unsupervised learning of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions by means of variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.},\\narchivePrefix = {arXiv},\\narxivId = {1605.06432},\\nauthor = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},\\nbooktitle = {ICLR},\\neprint = {1605.06432},\\nfile = {:Users/adam/Documents/Mendeley/Karl et al. - 2017 - Deep Variational Bayes Filters Unsupervised Learning of State Space Models from Raw Data.pdf:pdf},\\ntitle = {{Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}},\\nopturl = {http://arxiv.org/abs/1605.06432 https://arxiv.org/pdf/1605.06432.pdf},\\nyear = {2017}\\n}',\n",
       " 'Blei2005': \"@techreport{Blei2005,\\nabstract = {This note describes Minka's expectation propagation algorithm. It draws from his thesis and both UAI papers},\\nauthor = {Blei, David},\\nnumber = {0},\\npages = {1--4},\\ntitle = {{Expectation Propagation Explanation}},\\nopturl = {http://www.cs.columbia.edu/{~}blei/papers/Blei2003.pdf},\\nyear = {2005}\\n}\",\n",
       " 'Wang2016a': '@article{Wang2016a,\\nabstract = {In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.},\\narchivePrefix = {arXiv},\\narxivId = {1611.05763},\\nauthor = {Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},\\neprint = {1611.05763},\\njournal = {arXiv},\\nmonth = {nov},\\npages = {1--17},\\ntitle = {{Learning to reinforcement learn}},\\nopturl = {http://arxiv.org/abs/1611.05763},\\nyear = {2016}\\n}',\n",
       " 'Graves2016b': '@article{Graves2016b,\\nabstract = {This paper introduces Adaptive Computation Time (ACT), an algorithm that allows recurrent neural networks to learn how many computational steps to take between receiving an input and emitting an output. ACT requires minimal changes to the network architecture, is deterministic and differentiable, and does not add any noise to the parameter gradients. Experimental results are provided for four synthetic problems: determining the parity of binary vectors, applying binary logic operations, adding integers, and sorting real numbers. Overall, performance is dramatically improved by the use of ACT, which successfully adapts the number of computational steps to the requirements of the problem. We also present character-level language modelling results on the Hutter prize Wikipedia dataset. In this case ACT does not yield large gains in performance; however it does provide intriguing insight into the structure of the data, with more computation allocated to harder-to-predict transitions, such as spaces between words and ends of sentences. This suggests that ACT or other adaptive computation methods could provide a generic method for inferring segment boundaries in sequence data.},\\narchivePrefix = {arXiv},\\narxivId = {1603.08983},\\nauthor = {Graves, Alex},\\noptdoi = {10.475/123},\\neprint = {1603.08983},\\noptisbn = {9781450335423},\\noptissn = {0927-7099},\\njournal = {Arxiv},\\nmonth = {mar},\\npages = {1--19},\\ntitle = {{Adaptive Computation Time for Recurrent Neural Networks}},\\nopturl = {http://arxiv.org/abs/1603.08983},\\nyear = {2016}\\n}',\n",
       " 'Bengio2012': '@article{Bengio2012,\\nabstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},\\narchivePrefix = {arXiv},\\narxivId = {1206.5538},\\nauthor = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},\\noptdoi = {10.1109/TPAMI.2013.50},\\neprint = {1206.5538},\\noptisbn = {0162-8828 VO - 35},\\noptissn = {01628828},\\njournal = {IEEE Trans. Pattern Anal. Mach. Intell.},\\nkeywords = {Boltzmann machine,Deep learning,autoencoder,feature learning,neural nets,representation learning,unsupervised learning},\\nmonth = {jun},\\nnumber = {8},\\npages = {1798--1828},\\npmid = {23459267},\\ntitle = {{Representation learning: A review and new perspectives}},\\nopturl = {http://arxiv.org/abs/1206.5538},\\nvolume = {35},\\nyear = {2013}\\n}',\n",
       " 'Kumaran2016': '@article{Kumaran2016,\\nabstract = {We update complementary learning systems (CLS) theory, which holds that intelligent agents must possess two learning systems, instantiated in mammalians in neocortex and hippocampus. The first gradually acquires structured knowledge representations while the second quickly learns the specifics of individual experiences. We broaden the role of replay of hippocampal memories in the theory, noting that replay allows goal-dependent weighting of experience statistics. We also address recent challenges to the theory and extend it by showing that recurrent activation of hippocampal traces can support some forms of generalization and that neocortical learning can be rapid for information that is consistent with known structure. Finally, we note the relevance of the theory to the design of artificial intelligent agents, highlighting connections between neuroscience and machine learning.},\\nauthor = {Kumaran, Dharshan and Hassabis, Demis and McClelland, James L.},\\noptdoi = {10.1016/j.tics.2016.05.004},\\noptisbn = {1879-307X (Electronic)$\\\\backslash$r1364-6613 (Linking)},\\noptissn = {1879307X},\\njournal = {Trends Cogn. Sci.},\\nkeywords = {Artificial intelligence,Hippocampus,Learning,Memory},\\nmonth = {jul},\\nnumber = {7},\\npages = {512--534},\\npmid = {27315762},\\ntitle = {{What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated}},\\nopturl = {http://www.ncbi.nlm.nih.gov/pubmed/27315762},\\nvolume = {20},\\nyear = {2016}\\n}',\n",
       " 'Schulman2015': '@article{Schulman2015,\\nabstract = {SmB6 has been predicted and verified as a prototype of topological Kondo insulators (TKIs). Here we report longitudinal magnetoresistance and Hall coefficient measurements on co-sputtered nanocrystalline SmB6 films and try to find possible signatures of their topological properties. The magnetoresistance (MR) at 2 K is positive and linear (LPMR) at low field and becomes negative and quadratic at higher field. While the negative part is known from the reduction of the hybridization gap due to Zeeman splitting, the positive dependence is similar to what has been observed in other topological insulators (TI). We conclude that the LPMR is a characteristic feature of TI and is related to the linear dispersion near the Dirac cone. The Hall resistance shows a sign change around 50 K. It peaks and becomes nonlinear at around 10 K then decreases below 10 K. This indicates that carriers with opposite signs emerge below 50 K. Two films with different geometries (thickness and lateral dimension) show contrasting behavior below and above 50K, which proves the surface origin of the low temperature carriers in these films. The temperature dependence of magnetoresistance and the Hall data indicates that the surface states are likely non-trivial.},\\narchivePrefix = {arXiv},\\narxivId = {1502.0547},\\nauthor = {Schulman, John and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},\\noptdoi = {10.1063/1.4927398},\\neprint = {1502.0547},\\noptisbn = {0375-9687},\\noptissn = {2158-3226},\\njournal = {Icml-2015},\\nmonth = {feb},\\npages = {16},\\ntitle = {{Trust Region Policy Optimization}},\\nopturl = {http://arxiv.org/abs/1502.0547},\\nyear = {2015}\\n}',\n",
       " 'Hoffman': '@article{Hoffman,\\nabstract = {We rewrite the variational evidence lower bound objective (ELBO) of variational autoencoders in a way that highlights the role of the encoded data distribution. This perspective suggests that to improve our variational bounds we should improve our priors and not just the encoder and decoder.},\\nauthor = {Hoffman, Matthew D and Johnson, Matthew J and Brain, Google},\\nfile = {:Users/adam/Documents/Mendeley/Hoffman, Johnson, Brain - Unknown - ELBO surgery yet another way to carve up the variational evidence lower bound.pdf:pdf},\\ntitle = {{ELBO surgery: yet another way to carve up the variational evidence lower bound}},\\nopturl = {http://approximateinference.org/accepted/HoffmanJohnson2016.pdf}\\n}',\n",
       " 'Pathak2017': \"@article{Pathak2017,\\nabstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch. Demo video and code available at https://pathak22.github.io/noreward-rl/},\\narchivePrefix = {arXiv},\\narxivId = {1705.05363},\\nauthor = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},\\noptdoi = {10.1109/CVPRW.2017.70},\\neprint = {1705.05363},\\noptissn = {1938-7228},\\nmonth = {may},\\ntitle = {{Curiosity-driven Exploration by Self-supervised Prediction}},\\nopturl = {http://arxiv.org/abs/1705.05363},\\nyear = {2017}\\n}\",\n",
       " 'Haeusser2017': '@inproceedings{Haeusser2017,\\nabstract = {In many real-world scenarios, labeled data for a specific machine learning task is costly to obtain. Semi-supervised training methods make use of abundantly available unlabeled data and a smaller number of labeled examples. We propose a new framework for semi-supervised training of deep neural networks inspired by learning in humans. \"Associations\" are made from embeddings of labeled samples to those of unlabeled ones and back. The optimization schedule encourages correct association cycles that end up at the same class from which the association was started and penalizes wrong associations ending at a different class. The implementation is easy to use and can be added to any existing end-to-end training setup. We demonstrate the capabilities of learning by association on several data sets and show that it can improve performance on classification tasks tremendously by making use of additionally available unlabeled data. In particular, for cases with few labeled data, our training scheme outperforms the current state of the art on SVHN.},\\narchivePrefix = {arXiv},\\narxivId = {1706.00909},\\nauthor = {H{\\\\\"{a}}usser, Philip and Mordvintsev, Alexander and Cremers, Daniel},\\nbooktitle = {CVPR},\\noptdoi = {10.1109/CVPR.2017.74},\\neprint = {1706.00909},\\nmonth = {jun},\\ntitle = {{Learning by Association - A versatile semi-supervised training method for neural networks}},\\nopturl = {http://arxiv.org/abs/1706.00909},\\nyear = {2017}\\n}',\n",
       " 'Zhang2016a': '@article{Zhang2016a,\\nabstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},\\narchivePrefix = {arXiv},\\narxivId = {1611.03530},\\nauthor = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},\\neprint = {1611.03530},\\nmonth = {nov},\\ntitle = {{Understanding deep learning requires rethinking generalization}},\\nopturl = {http://arxiv.org/abs/1611.03530},\\nyear = {2016}\\n}',\n",
       " 'Bishop2006': '@book{Bishop2006,\\nabstract = {Textbook for graduates. The field of pattern recognition has undergone substantial development over the years. This book reflects these developments while providing a grounding in the basic concepts of pattern recognition and machine learning. It is aimed at advanced undergraduates or first year PhD students, as well as researchers and practitioners. Introduction. Example : polynomial curve fitting ; Probability theory ; Model selection ; The curse of dimensionality Decision theory ; Information theory -- Probability distributions. Binary vehicles ; Multinomial variables ; The Gaussian distribution ; The exponential family ; Nonparametric methods -- Linear models for regression. Linear basis function models ; The bias-variance decomposition ; Bayesian linear regression ; Bayesian model comparison ; The evidence approximation ; Limitations of fixed basis functions -- Linear models for classification. Discriminant functions ; Probabilistic generative models ; Probabilistic discrimitive models ; The Laplace approximation ; Bayesian logistic regression -- Neural networks. Feed-forward network functions ; Network training ; Error backpropagation ; The Hessian matrix ; Regularization in neural networks ; Mixture density networks ; Bayesian neural networks -- Kernel methods. Dual representations ; Constructing kernals ; Radial basis function networks ; Gaussian processes -- Sparse Kernel machines. Maximum margin classifiers ; Relevance vector machines -- Graphical models. Bayesian networks ; Conditional independence ; Markov random fields ; Inference in graphical models -- Mixture models and EM. K-means clustering ; Mixtures of Gaussians ; An alternative view of EM ; The EM algorithm in general -- Approximate inference. Variational inference ; Illustration : variational mixture of Gaussians ; Variational linear regression ; Exponential family distributions ; Local variational methods ; Variational logistic regression ; Expectation propagation -- Sampling methods. Basic sampling algorithms ; Markov chain Monte Carlo ; Gibbs sampling ; Slice sampling ; The hybrid Monte Carlo algorithm ; Estimating the partition function -- Continuous latent variables. Principal component analysis ; Probabilistic PCA ; Kernel PCA ; Nonlinear latent variable models -- Sequential data. Markoc models ; Hidden Markov models ; Linear dynamical systems -- Combining models. Bayesian model averaging ; Committees ; Boosting ; Tree-based models ; Conditional mixture models -- Data sets -- Probability distributions -- Properties of matrices -- Calculus of variations -- Lagrange multipliers.},\\nauthor = {Bishop, Christopher M.},\\noptisbn = {9780387310732},\\npages = {738},\\npublisher = {Springer},\\ntitle = {{Pattern recognition and machine learning}},\\nyear = {2006}\\n}',\n",
       " 'Ba2014': '@article{Ba2014,\\nabstract = {We present an attention-based model for recognizing multiple objects in images. The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image. We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training. We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation.},\\narchivePrefix = {arXiv},\\narxivId = {1412.7755},\\nauthor = {Ba, Jimmy and Mnih, Volodymyr and Kavukcuoglu, Koray},\\neprint = {1412.7755},\\noptisbn = {9781424465163},\\njournal = {Iclr},\\nmonth = {dec},\\npages = {1--10},\\ntitle = {{Multiple Object Recognition with Visual Attention}},\\nopturl = {http://arxiv.org/pdf/1412.7755v2.pdf{\\\\%}5Cnhttp://arxiv.org/abs/1412.7755},\\nyear = {2014}\\n}',\n",
       " 'Hochreiter1997': '@article{Hochreiter1997,\\nabstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter\\'s (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},\\narchivePrefix = {arXiv},\\narxivId = {1206.2944},\\nauthor = {Hochreiter, Sepp and Schmidhuber, J{\\\\\"{u}}rgen},\\noptdoi = {10.1162/neco.1997.9.8.1735},\\neprint = {1206.2944},\\noptisbn = {08997667 (optissn)},\\noptissn = {0899-7667},\\njournal = {Neural Comput.},\\nmonth = {nov},\\nnumber = {8},\\npages = {1735--1780},\\npmid = {9377276},\\ntitle = {{Long Short-Term Memory}},\\nopturl = {http://www.mitpressjournals.org/optdoi/10.1162/neco.1997.9.8.1735},\\nvolume = {9},\\nyear = {1997}\\n}',\n",
       " 'Kendall2017': \"@article{Kendall2017,\\nabstract = {Deep learning has shown to be effective for robust and real-time monocular image relocalisation. In particular, PoseNet is a deep convolutional neural network which learns to regress the 6-DOF camera pose from a single image. It learns to localize using high level features and is robust to difficult lighting, motion blur and unknown camera intrinsics, where point based SIFT registration fails. However, it was trained using a naive loss function, with hyper-parameters which require expensive tuning. In this paper, we give the problem a more fundamental theoretical treatment. We explore a number of novel loss functions for learning camera pose which are based on geometry and scene reprojection error. Additionally we show how to automatically learn an optimal weighting to simultaneously regress position and orientation. By leveraging geometry, we demonstrate that our technique significantly improves PoseNet's performance across datasets ranging from indoor rooms to a small city.},\\narchivePrefix = {arXiv},\\narxivId = {1704.00390},\\nauthor = {Kendall, Alex and Cipolla, Roberto},\\neprint = {1704.00390},\\ntitle = {{Geometric loss functions for camera pose regression with deep learning}},\\nopturl = {http://arxiv.org/abs/1704.00390},\\nyear = {2017}\\n}\",\n",
       " 'Stadie2015': '@article{Stadie2015,\\nabstract = {Achieving efficient and scalable exploration in complex domains poses a major challenge in reinforcement learning. While Bayesian and PAC-MDP approaches to the exploration problem offer strong formal guarantees, they are often impractical in higher dimensions due to their reliance on enumerating the state-action space. Hence, exploration in complex domains is often performed with simple epsilon-greedy methods. To achieve more efficient exploration, we develop a method for assigning exploration bonuses based on a concurrently learned model of the system dynamics. By parameterizing our learned model with a neural network, we are able to develop a scalable and efficient approach to exploration bonuses that can be applied to tasks with complex, high-dimensional state spaces. We demonstrate our approach on the task of learning to play Atari games from raw pixel inputs. In this domain, our method offers substantial improvements in exploration efficiency when compared with the standard epsilon greedy approach. As a result of our improved exploration strategy, we are able to achieve state-of-the-art results on several games that pose a major challenge for prior methods.},\\narchivePrefix = {arXiv},\\narxivId = {1507.00814},\\nauthor = {Stadie, Bradly C. and Levine, Sergey and Abbeel, Pieter},\\neprint = {1507.00814},\\njournal = {arXiv},\\nmonth = {jul},\\npages = {1--11},\\ntitle = {{Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models}},\\nopturl = {http://arxiv.org/abs/1507.00814},\\nyear = {2015}\\n}',\n",
       " 'Bertinetto2016': \"@inproceedings{Bertinetto2016,\\nabstract = {The problem of arbitrary object tracking has traditionally been tackled by learning a model of the object's appearance exclusively online, using as sole training data the video itself. Despite the success of these methods, their online-only approach inherently limits the richness of the model they can learn. Recently, several attempts have been made to exploit the expressive power of deep convolutional networks. However, when the object to track is not known beforehand, it is necessary to perform Stochastic Gradient Descent online to adapt the weights of the network, severely compromising the speed of the system. In this paper we equip a basic tracking algorithm with a novel fully-convolutional Siamese network trained end-to-end on the ILSVRC15 video object detection dataset. Our tracker operates at frame-rates beyond real-time and, despite its extreme simplicity, achieves state-of-the-art performance in the VOT2015 benchmark.},\\narchivePrefix = {arXiv},\\narxivId = {1606.09549},\\nauthor = {Bertinetto, Luca and Valmadre, Jack and Henriques, Jo{\\\\~{a}}o F. and Vedaldi, Andrea and Torr, Philip H. S.},\\nbooktitle = {ArXiv},\\noptdoi = {10.1007/978-3-319-46448-0},\\neprint = {1606.09549},\\noptisbn = {978-3-319-46447-3},\\noptissn = {0302-9743},\\nkeywords = {deep-,object-tracking,siamese-network,similarity-learning},\\norganization = {Springer},\\npages = {850--865},\\npmid = {4520227},\\ntitle = {{Fully-Convolutional Siamese Networks for Object Tracking}},\\nopturl = {http://arxiv.org/abs/1606.09549},\\nyear = {2016}\\n}\",\n",
       " 'Kalman1960': '@article{Kalman1960,\\nauthor = {Kalman, R E},\\noptdoi = {10.1115/1.3662552},\\noptisbn = {9783540769897},\\noptissn = {00219223},\\njournal = {Fluids Eng.},\\nnumber = {82 (Series D)},\\npages = {35--45 (1960) (11 pages)},\\npmid = {5311910},\\ntitle = {{New Approach to Linear Filtering and Prediction Problems}},\\nopturl = {http://www.citeulike.org/user/pqnga/article/347166},\\nvolume = {82},\\nyear = {1960}\\n}',\n",
       " 'Chalasani2013': '@article{Chalasani2013,\\nabstract = {The quality of data representation in deep learning methods is directly related to the prior model imposed on the representations; however, generally used fixed priors are not capable of adjusting to the context in the data. To address this issue, we propose deep predictive coding networks, a hierarchical generative model that empirically alters priors on the latent representations in a dynamic and context-sensitive manner. This model captures the temporal dependencies in time-varying signals and uses top-down information to modulate the representation in lower layers. The centerpiece of our model is a novel procedure to infer sparse states of a dynamic model which is used for feature extraction. We also extend this feature extraction block to introduce a pooling function that captures locally invariant representations. When applied on a natural video data, we show that our method is able to learn high-level visual features. We also demonstrate the role of the top-down connections by showing the robustness of the proposed model to structured noise.},\\narchivePrefix = {arXiv},\\narxivId = {1301.3541},\\nauthor = {Chalasani, Rakesh and Principe, Jc},\\neprint = {1301.3541},\\njournal = {arXiv Prepr. arXiv1301.3541},\\nmonth = {jan},\\npages = {13},\\ntitle = {{Deep Predictive Coding Networks}},\\nopturl = {http://arxiv.org/abs/1301.3541},\\nyear = {2013}\\n}',\n",
       " 'Glasmachers2017': '@article{Glasmachers2017,\\nabstract = {End-to-end learning refers to training a possibly complex learning system by applying gradient-based learning to the system as a whole. End-to-end learning system is specifically designed so that all modules are differentiable. In effect, not only a central learning machine, but also all \"peripheral\" modules like representation learning and memory formation are covered by a holistic learning process. The power of end-to-end learning has been demonstrated on many tasks, like playing a whole array of Atari video games with a single architecture. While pushing for solutions to more challenging tasks, network architectures keep growing more and more complex. In this paper we ask the question whether and to what extent end-to-end learning is a future-proof technique in the sense of scaling to complex and diverse data processing architectures. We point out potential inefficiencies, and we argue in particular that end-to-end learning does not make optimal use of the modular design of present neural networks. Our surprisingly simple experiments demonstrate these inefficiencies, up to the complete breakdown of learning.},\\narchivePrefix = {arXiv},\\narxivId = {1704.08305},\\nauthor = {Glasmachers, Tobias},\\neprint = {1704.08305},\\njournal = {arXiv1704.08305 [cs, stat]},\\nmonth = {apr},\\ntitle = {{Limits of End-to-End Learning}},\\nopturl = {http://arxiv.org/abs/1704.08305{\\\\%}0Ahttp://www.arxiv.org/pdf/1704.08305.pdf{\\\\%}0Ahttps://arxiv.org/abs/1704.08305},\\nyear = {2017}\\n}',\n",
       " 'Patraucean2016': '@article{Patraucean2016,\\nabstract = {We describe a new spatio-temporal video autoencoder, based on a classic spatial image autoencoder and a novel nested temporal autoencoder. The temporal encoder is represented by a differentiable visual memory composed of convolutional long short-term memory (LSTM) cells that integrate changes over time. Here we target motion changes and use as temporal decoder a robust optical flow prediction module together with an image sampler serving as built-in feedback loop. The architecture is end-to-end differentiable. At each time step, the system receives as input a video frame, predicts the optical flow based on the current observation and the LSTM memory state as a dense transformation map, and applies it to the current frame to generate the next frame. By minimising the reconstruction error between the predicted next frame and the corresponding ground truth next frame, we train the whole system to extract features useful for motion estimation without any supervision effort. We believe these features can in turn facilitate learning high-level tasks such as path planning, semantic segmentation, or action recognition, reducing the overall supervision effort.},\\narchivePrefix = {arXiv},\\narxivId = {1511.06309},\\nauthor = {Patraucean, Viorica and Handa, Ankur and Cipolla, Roberto},\\neprint = {1511.06309},\\njournal = {Int. Conf. Learn. Represent.},\\nmonth = {nov},\\nnumber = {2015},\\npages = {1--10},\\ntitle = {{Spatio-temporal video autoencoder with differentiable memory}},\\nopturl = {http://arxiv.org/abs/1511.06309},\\nyear = {2016}\\n}',\n",
       " 'Tokui2015': \"@misc{Tokui2015,\\nabstract = {A long strand of empirical research has claimed that dropout cannot be applied between the recurrent connections of a recurrent neural network (RNN). The reasoning has been that the noise hinders the network's ability to model sequences, and instead should be applied to the RNN's inputs and outputs alone. But dropout is a vital tool for regularisation, and without dropout in recurrent layers our models overfit quickly. In this paper we show that a recently developed theoretical framework, casting dropout as approximate Bayesian inference, can give us mathematically grounded tools to apply dropout within the recurrent layers. We apply our new dropout technique in long short-term memory (LSTM) networks and show that the new approach significantly outperforms existing techniques.},\\narchivePrefix = {arXiv},\\narxivId = {1512.05287},\\nauthor = {Tokui, Seiya and Networks, Preferred},\\nbooktitle = {arXiv:1512.05287},\\noptdoi = {10.1201/9781420049176},\\neprint = {1512.05287},\\nfile = {:Users/adam/Documents/Mendeley/Tokui, Networks - 2015 - A Theoretically Grounded Application of Dropout in Recurrent Neural Networks.pdf:pdf},\\noptisbn = {9789537619084},\\noptissn = {0302-9743},\\nkeywords = {adatpive{\\\\_}loss},\\nmendeley-tags = {adatpive{\\\\_}loss},\\npages = {1--9},\\ntitle = {{A Theoretically Grounded Application of Dropout in Recurrent Neural Networks}},\\nopturl = {http://arxiv.org/abs/1512.05287},\\nyear = {2015}\\n}\",\n",
       " 'Fortunato2017': '@article{Fortunato2017,\\nabstract = {In this work we explore a straightforward variational Bayes scheme for Recurrent Neural Networks. Firstly, we show that a simple adaptation of truncated backpropagation through time can yield good quality uncertainty estimates and superior regularisation at only a small extra computational cost during training. Secondly, we demonstrate how a novel kind of posterior approximation yields further improvements to the performance of Bayesian RNNs. We incorporate local gradient information into the approximate posterior to sharpen it around the current batch statistics. This technique is not exclusive to recurrent neural networks and can be applied more widely to train Bayesian neural networks. We also empirically demonstrate how Bayesian RNNs are superior to traditional RNNs on a language modelling benchmark and an image captioning task, as well as showing how each of these methods improve our model over a variety of other schemes for training them. We also introduce a new benchmark for studying uncertainty for language models so future methods can be easily compared.},\\narchivePrefix = {arXiv},\\narxivId = {1704.02798},\\nauthor = {Fortunato, Meire and Blundell, Charles and Vinyals, Oriol},\\neprint = {1704.02798},\\nmonth = {apr},\\ntitle = {{Bayesian Recurrent Neural Networks}},\\nopturl = {http://arxiv.org/abs/1704.02798},\\nyear = {2017}\\n}',\n",
       " 'Li2016': \"@article{Li2016,\\nabstract = {This paper introduces the variational R$\\\\backslash$'enyi bound (VR) that extends traditional variational inference to R$\\\\backslash$'enyi's alpha-divergences. This new family of variational methods unifies a number of existing approaches, and enables a smooth interpolation from the evidence lower-bound to the log marginal likelihood that is controlled by the value of alpha that parametrises the divergence. The reparameterization trick, Monte Carlo approximation and stochastic optimisation methods are deployed to obtain a unified framework for optimisation. We further consider negative alpha values and propose a novel variational inference method as a new special case in the proposed framework. Experiments on Bayesian neural networks and variational auto-encoders demonstrate the wide applicability of the VR bound.},\\narchivePrefix = {arXiv},\\narxivId = {1602.02311},\\nauthor = {Li, Yingzhen and Turner, Richard E},\\neprint = {1602.02311},\\noptissn = {10495258},\\nnumber = {Nips},\\npages = {1--20},\\ntitle = {{R$\\\\backslash$'enyi Divergence Variational Inference}},\\nopturl = {http://arxiv.org/abs/1602.02311},\\nyear = {2016}\\n}\",\n",
       " 'Santoro2016': '@article{Santoro2016,\\nabstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.},\\narchivePrefix = {arXiv},\\narxivId = {1605.06065},\\nauthor = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},\\noptdoi = {10.1002/2014GB005021},\\neprint = {1605.06065},\\noptisbn = {9781617796029},\\noptissn = {19449224},\\npmid = {8190083},\\ntitle = {{One-shot Learning with Memory-Augmented Neural Networks}},\\nopturl = {http://arxiv.org/abs/1605.06065},\\nyear = {2016}\\n}',\n",
       " 'Devries2017': \"@article{Devries2017,\\nabstract = {It is commonly assumed that language refers to high-level visual concepts while leaving low-level visual processing unaffected. This view dominates the current literature in computational models for language-vision tasks, where visual and linguistic input are mostly processed independently before being fused into a single representation. In this paper, we deviate from this classic pipeline and propose to modulate the $\\\\backslash$emph{\\\\{}entire visual processing{\\\\}} by linguistic input. Specifically, we condition the batch normalization parameters of a pretrained residual network (ResNet) on a language embedding. This approach, which we call MOdulated RESnet ($\\\\backslash$MRN), significantly improves strong baselines on two visual question answering tasks. Our ablation study shows that modulating from the early stages of the visual processing is beneficial.},\\narchivePrefix = {arXiv},\\narxivId = {1707.00683},\\nauthor = {de Vries, Harm and Strub, Florian and Mary, J{\\\\'{e}}r{\\\\'{e}}mie and Larochelle, Hugo and Pietquin, Olivier and Courville, Aaron},\\neprint = {1707.00683},\\nmonth = {jul},\\npages = {1--13},\\ntitle = {{Modulating early visual processing by language}},\\nopturl = {http://arxiv.org/abs/1707.00683},\\nyear = {2017}\\n}\",\n",
       " 'Graves2014recurrent': '@inproceedings{Graves2014recurrent,\\nabstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for optdoing so.},\\narchivePrefix = {arXiv},\\narxivId = {1406.6247},\\nauthor = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},\\nbooktitle = {NIPS},\\noptdoi = {ng},\\neprint = {1406.6247},\\noptisbn = {078036404X},\\noptissn = {0157244X},\\ntitle = {{Recurrent Models of Visual Attention}},\\nopturl = {http://arxiv.org/abs/1406.6247},\\nyear = {2014}\\n}',\n",
       " 'Milan2017': '@article{Milan2017,\\nabstract = {There exist a number of problem classes for which obtain-ing the exact solution becomes exponentially expensive with increasing problem size. The quadratic assignment problem (QAP) or the travelling salesman problem (TSP) are just two examples of such NP-hard problems. In practice, approxi-mate algorithms are employed to obtain a suboptimal solu-tion, where one must face a trade-off between computational complexity and solution quality. In this paper, we propose to learn to solve these problem from approximate examples, using recurrent neural networks (RNNs). Surprisingly, such architectures are capable of producing highly accurate solu-tions at minimal computational cost. Moreover, we introduce a simple, yet effective technique for improving the initial (weak) training set by incorporating the objective cost into the training procedure. We demonstrate the functionality of our approach on three exemplar applications: marginal dis-tributions of a joint matching space, feature point matching and the travelling salesman problem. We show encouraging results on synthetic and real data in all three cases.},\\nauthor = {Milan, Anton and Rezatofighi, S Hamid and Garg, Ravi and Dick, Anthony and Reid, Ian},\\nkeywords = {Machine Learning Applications},\\npages = {1453--1459},\\ntitle = {{Data-Driven Approximations to NP-Hard Problems}},\\nopturl = {http://www.milanton.de/files/aaai2017/aaai2017-anton-nphard.pdf},\\nyear = {2017}\\n}',\n",
       " 'Pu2017': \"@article{Pu2017,\\nabstract = {A new method for learning variational autoencoders is developed, based on an application of Stein's operator. The framework represents the encoder as a deep nonlinear function through which samples from a simple distribution are fed. One need not make parametric assumptions about the form of the encoder distribution, and performance is further enhanced by integrating the proposed encoder with importance sampling. Example results are demonstrated across multiple unsupervised and semi-supervised problems, including semi-supervised analysis of the ImageNet data, demonstrating the scalability of the model to large datasets.},\\narchivePrefix = {arXiv},\\narxivId = {1704.05155},\\nauthor = {Pu, Y. and Gan, Z. and Henao, R. and Li, C. and Han, S. and Carin, L.},\\neprint = {1704.05155},\\njournal = {arXiv:1704.05155},\\nmonth = {apr},\\ntitle = {{Stein Variational Autoencoder}},\\nopturl = {http://arxiv.org/abs/1704.05155},\\nyear = {2017}\\n}\",\n",
       " 'Larsen2016': '@article{Larsen2016,\\nabstract = {We present an autoencoder that leverages learned representations to better measure similarities in data space. By combining a variational autoencoder with a generative adversarial network we can use learned feature representations in the GAN discriminator as basis for the VAE reconstruction objective. Thereby, we replace element-wise errors with feature-wise errors to better capture the data distribution while offering invariance towards e.g. translation. We apply our method to images of faces and show that it outperforms VAEs with element-wise similarity measures in terms of visual fidelity. Moreover, we show that the method learns an embedding in which high-level abstract visual features (e.g. wearing glasses) can be modified using simple arithmetic.},\\narchivePrefix = {arXiv},\\narxivId = {1512.09300},\\nauthor = {Larsen, Anders Boesen Lindbo and S{\\\\o}nderby, S{\\\\o}ren Kaae and Larochelle, Hugo and Winther, Ole},\\neprint = {1512.09300},\\noptisbn = {9781510829008},\\njournal = {Proc. 33rd Int. Conf. Mach. Learn.},\\npages = {pp. 1558--1566},\\ntitle = {{Autoencoding beyond pixels using a learned similarity metric}},\\nopturl = {https://arxiv.org/pdf/1512.09300.pdf},\\nyear = {2016}\\n}',\n",
       " 'Lotter2016': '@article{Lotter2016,\\nabstract = {While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (\"PredNet\") architecture that is inspired by the concept of \"predictive coding\" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in optdoing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.},\\narchivePrefix = {arXiv},\\narxivId = {1605.08104},\\nauthor = {Lotter, William and Kreiman, Gabriel and Cox, David},\\neprint = {1605.08104},\\nmonth = {may},\\ntitle = {{Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning}},\\nopturl = {http://arxiv.org/abs/1605.08104},\\nyear = {2016}\\n}',\n",
       " 'Giordano2015': '@article{Giordano2015,\\nabstract = {In Bayesian analysis, the posterior follows from the data and a choice of a prior and a likelihood. One hopes that the posterior is robust to reasonable variation in the choice of prior and likelihood, since this choice is made by the modeler and is necessarily somewhat subjective. Despite the fundamental importance of the problem and a considerable body of literature, the tools of robust Bayes are not commonly used in practice. This is in large part due to the difficulty of calculating robustness measures from MCMC draws. Although methods for computing robustness measures from MCMC draws exist, they lack generality and often require additional coding or computation. In contrast to MCMC, variational Bayes (VB) techniques are readily amenable to robustness analysis. The derivative of a posterior expectation with respect to a prior or data perturbation is a measure of local robustness to the prior or likelihood. Because VB casts posterior inference as an optimization problem, its methodology is built on the ability to calculate derivatives of posterior quantities with respect to model parameters, even in very complex models. In the present work, we develop local prior robustness measures for mean-field variational Bayes(MFVB), a VB technique which imposes a particular factorization assumption on the variational posterior approximation. We start by outlining existing local prior measures of robustness. Next, we use these results to derive closed-form measures of the sensitivity of mean-field variational posterior approximation to prior specification. We demonstrate our method on a meta-analysis of randomized controlled interventions in access to microcredit in developing countries.},\\narchivePrefix = {arXiv},\\narxivId = {1512.02578},\\nauthor = {Giordano, Ryan and Broderick, Tamara and Jordan, Michael},\\neprint = {1512.02578},\\noptisbn = {1512.02578},\\nmonth = {dec},\\npages = {1--16},\\ntitle = {{Robust Inference with Variational Bayes}},\\nopturl = {http://arxiv.org/abs/1512.02578},\\nyear = {2015}\\n}',\n",
       " 'Goroshin2013': \"@inproceedings{Goroshin2013,\\nabstract = {We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE's ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of features can be learned when different activation functions are used. Finally, connections are established with the Contractive and Sparse Auto-Encoders.},\\narchivePrefix = {arXiv},\\narxivId = {1301.3577},\\nauthor = {Goroshin, Rostislav and Lecun, Yann},\\noptdoi = {10.1140/epjc/s10052-013-2439-1},\\neprint = {1301.3577},\\noptissn = {14346052},\\nmonth = {jan},\\nnumber = {5},\\npages = {1--8},\\ntitle = {{Saturating Autoencoders}},\\nopturl = {http://arxiv.org/abs/1301.3577},\\nvolume = {73},\\nyear = {2013}\\n}\",\n",
       " 'Rae2016': '@article{Rae2016,\\nabstract = {Neural networks augmented with external memory have the ability to learn algorithmic solutions to complex tasks. These models appear promising for applications such as language modeling and machine translation. However, they scale poorly in both space and time as the amount of memory grows --- limiting their applicability to real-world domains. Here, we present an end-to-end differentiable memory access scheme, which we call Sparse Access Memory (SAM), that retains the representational power of the original approaches whilst training efficiently with very large memories. We show that SAM achieves asymptotic lower bounds in space and time complexity, and find that an implementation runs {\\\\$}1,\\\\backslash!000\\\\backslashtimes{\\\\$} faster and with {\\\\$}3,\\\\backslash!000\\\\backslashtimes{\\\\$} less physical memory than non-sparse models. SAM learns with comparable data efficiency to existing models on a range of synthetic tasks and one-shot Omniglot character recognition, and can scale to tasks requiring {\\\\$}100,\\\\backslash!000{\\\\$}s of time steps and memories. As well, we show how our approach can be adapted for models that maintain temporal associations between memories, as with the recently introduced Differentiable Neural Computer.},\\narchivePrefix = {arXiv},\\narxivId = {1610.09027},\\nauthor = {Rae, Jack W and Hunt, Jonathan J and Harley, Tim and Danihelka, Ivo and Senior, Andrew and Wayne, Greg and Graves, Alex and Lillicrap, Timothy P},\\neprint = {1610.09027},\\noptissn = {10495258},\\njournal = {Adv. Neural Inf. Process. Syst. 29 (NIPS 2016)},\\nmonth = {oct},\\nnumber = {Nips},\\ntitle = {{Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes}},\\nopturl = {http://arxiv.org/abs/1610.09027},\\nyear = {2016}\\n}',\n",
       " 'Wierstra2015draw': '@article{Wierstra2015draw,\\nabstract = {This paper introduces the Deep Recurrent Atten- tive Writer (DRAW) neural network architecture for image generation. DRAWnetworks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distin- guished from real data with the naked eye. 1.},\\narchivePrefix = {arXiv},\\narxivId = {1502.04623},\\nauthor = {Gregor, K and Danihelka, I and Graves, A and Wierstra, D},\\neprint = {1502.04623},\\noptisbn = {9781510810587},\\njournal = {ICML},\\ntitle = {{DRAW: A Recurrent Neural Network For Image Generation}},\\nopturl = {http://arxiv.org/abs/1502.04623},\\nyear = {2015}\\n}',\n",
       " 'Xu1994': '@article{Xu1994,\\nabstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the cor- responding words in the output sequence. We validate the use of attention with state-of-the- art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO. 1.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1211.5063v2},\\nauthor = {Xu, Kelvin and Kiros, Jimmy Lei Ba Ryan and Courville, Kyunghyun Cho Aaron and Bengio, Ruslan Salakhutdinov Richard S. Zemel Yoshua},\\noptdoi = {10.1109/72.279181},\\neprint = {arXiv:1211.5063v2},\\noptisbn = {1045-9227 VO - 5},\\noptissn = {19410093},\\njournal = {IEEE Trans. Neural Networks},\\nmonth = {feb},\\nnumber = {2},\\npages = {157--166},\\npmid = {18267787},\\ntitle = {{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}},\\nopturl = {http://arxiv.org/abs/1502.03044},\\nvolume = {5},\\nyear = {1994}\\n}',\n",
       " 'Haeusser2017adapt': '@inproceedings{Haeusser2017adapt,\\nabstract = {We propose associative domain adaptation, a novel tech-nique for end-to-end domain adaptation with neural net-works, the task of inferring class labels for an unlabeled tar-get domain based on the statistical properties of a labeled source domain. Our training scheme follows the paradigm that in order to effectively derive class labels for the tar-get domain, a network should produce statistically domain invariant embeddings, while minimizing the classification error on the labeled source domain. We accomplish this by reinforcing associations between source and target data directly in embedding space. Our method can easily be added to any existing classification network with no struc-tural and almost no computational overhead. We demon-strate the effectiveness of our approach on various bench-marks and achieve state-of-the-art results across the board with a generic convolutional neural network architecture not specifically tuned to the respective tasks. Finally, we show that the proposed association loss produces embed-dings that are more effective for domain adaptation com-pared to methods employing maximum mean discrepancy as a similarity measure in embedding space.},\\narchivePrefix = {arXiv},\\narxivId = {1708.00938},\\nauthor = {Haeusser, Philip and Frerix, Thomas and Mordvintsev, Alexander and Cremers, Daniel},\\nbooktitle = {ICCV},\\neprint = {1708.00938},\\nmonth = {aug},\\ntitle = {{Associative Domain Adaptation}},\\nopturl = {http://arxiv.org/abs/1708.00938},\\nyear = {2017}\\n}',\n",
       " 'Andrychowicz2016a': '@article{Andrychowicz2016a,\\nabstract = {In this paper, we propose and investigate a novel memory architecture for neural networks called Hierarchical Attentive Memory (HAM). It is based on a binary tree with leaves corresponding to memory cells. This allows HAM to perform memory access in O(log n) complexity, which is a significant improvement over the standard attention mechanism that requires O(n) operations, where n is the size of the memory. We show that an LSTM network augmented with HAM can learn algorithms for problems like merging, sorting or binary searching from pure input-output examples. In particular, it learns to sort n numbers in time O(n log n) and generalizes well to input sequences much longer than the ones seen during the training. We also show that HAM can be trained to act like classic data structures: a stack, a FIFO queue and a priority queue.},\\narchivePrefix = {arXiv},\\narxivId = {1602.03218},\\nauthor = {Andrychowicz, Marcin and Kurach, Karol},\\noptdoi = {10.23915/DISTILL.00001},\\neprint = {1602.03218},\\noptissn = {2476-0757},\\njournal = {Icml},\\nkeywords = {ICML,attention,machine learning},\\ntitle = {{Learning Efficient Algorithms with Hierarchical Attentive Memory}},\\nopturl = {http://arxiv.org/abs/1602.03218},\\nyear = {2016}\\n}',\n",
       " 'Soelch2016': '@inproceedings{Soelch2016,\\nabstract = {Approximate variational inference has shown to be a powerful tool for modeling unknown, complex probability distributions. Recent advances in the field allow us to learn probabilistic sequence models. We apply a Stochastic Recurrent Network (STORN) to learn robot time series data. Our evaluation demonstrates that we can robustly detect anomalies both off- and on-line.},\\narchivePrefix = {arXiv},\\narxivId = {1602.07109},\\nauthor = {S{\\\\\"{o}}lch, Maximilian and Bayer, Justin and Ludersdorfer, Marvin and van der Smagt, Patrick},\\nbooktitle = {ICML},\\neprint = {1602.07109},\\nmonth = {feb},\\ntitle = {{Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series}},\\nopturl = {http://arxiv.org/abs/1602.07109},\\nyear = {2016}\\n}',\n",
       " 'Han2015': '@article{Han2015,\\nabstract = {Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.},\\narchivePrefix = {arXiv},\\narxivId = {1510.00149},\\nauthor = {Han, Song and Mao, Huizi and Dally, William J.},\\noptdoi = {abs/1510.00149/1510.00149},\\neprint = {1510.00149},\\nmonth = {oct},\\ntitle = {{Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}},\\nopturl = {http://arxiv.org/abs/1510.00149},\\nyear = {2015}\\n}',\n",
       " 'Rusu2016': '@article{Rusu2016,\\nabstract = {Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},\\narchivePrefix = {arXiv},\\narxivId = {1606.04671},\\nauthor = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},\\neprint = {1606.04671},\\njournal = {CoRR. arXiv:1606.04671},\\nmonth = {jun},\\ntitle = {{Progressive Neural Networks}},\\nopturl = {http://arxiv.org/abs/1606.04671},\\nyear = {2016}\\n}',\n",
       " 'Burda2015': \"@article{Burda2015,\\nabstract = {The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.},\\narchivePrefix = {arXiv},\\narxivId = {1509.00519},\\nauthor = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},\\neprint = {1509.00519},\\noptisbn = {1509.00519},\\noptissn = {1312.6114v10},\\nmonth = {sep},\\ntitle = {{Importance Weighted Autoencoders}},\\nopturl = {http://arxiv.org/abs/1509.00519},\\nyear = {2015}\\n}\",\n",
       " 'Mcintosh2009': \"@article{Mcintosh2009,\\nabstract = {This Special Issue of Neuropsychologia is a celebration and eval- uation of the work of David Milner, who retired formally from his Chair at the University of Durham at the end of 2008. In the course of a distinguished career, David's work has informed many topics within cognitive neuroscience. However, his influ- ence has thus far been felt most strongly via his collaboration with Mel Goodale on their perception-action model of primate vision (Goodale {\\\\&} Milner, 1992; Milner {\\\\&} Goodale, 1995; Milner {\\\\&} Goodale, 2006). The model proposes a functional interpretation for the two cortical visual streams, with the (occipito-temporal) ventral stream processing visual information for perceptual pur- poses, and the (occipito-parietal) dorsal stream providing visual guidance for movement. In the past two decades, the model has had a revolutionary effect within visual neuroscience, elevated the study of motor control to previously unthinkable prominence and inspired thousands of empirical studies. Moreover, its influ- ence has reached beyond the boundaries of neuroscience, fuelling philosophical debates and even capturing the popular imagination (Goodale {\\\\&} Milner, 2004; Ramachandran {\\\\&} Blakeslee, 1998). The perception-action model thus provides an appropriate focus for this Special Issue},\\nauthor = {McIntosh, Robert D. and Schenk, Thomas},\\noptdoi = {10.1016/j.neuropsychologia.2009.02.009},\\noptisbn = {1873-3514},\\noptissn = {00283932},\\njournal = {Neuropsychologia},\\nnumber = {6},\\npages = {1391--1396},\\npmid = {19428404},\\ntitle = {{Two visual streams for perception and action: Current trends}},\\nopturl = {http://www.sciencedirect.com/science/article/pii/S0028393209000803},\\nvolume = {47},\\nyear = {2009}\\n}\",\n",
       " 'Moravec1988': '@book{Moravec1988,\\nabstract = {Average Customer Rating: 4.5 Rating: 3 Thought-provoking, but un-even In this nearly twenty year old book, the author contends that advancing technology and the force of economic competition will lead inevitably (and in a span of mere decades) to a world in which machine intelligence vastly exceeds human intelligence. In chapters 3 through 6 the author gives a fascinating look at some of the possible features of that transhuman, post-biological world. Those chapters are as interesting and thought-provoking as any that have appeared in more contemporary treatments. Where the book does show it age, however, is in the first three chapters. There the author reviews the history of computer technology, and then succumbs to the shop-worn refrain of many classical AI researchers - \"If only we had a computer that is 100 (or 1000 or 10000) times as powerful as today\\'s machine, then we could program a human-equivalent intelligence\". He even predicts on page 23 that \"a general-purpose robot usable in the home\" will be available within ten years. Well, today we have the computer power he was hoping for and still no general-purpose robot. Bottom line: if you want a fascinating look at what a world with superintelligent machines might be like, then buy this book and start reading at chapter 4. If you are interested in how we might actually achieve such a world then consider buying a copy of \"On Intelligence\" by Jeff Hawkins. Rating: 5 Visionary This book does a great job of exploring the future of robots, artificial intelligence, the human mind, and human identity. A few parts of it seem dated, but most of what the book describes seems likely to happen this century and to surprise the large fraction of the population which still hasn\\'t given any thought to the possibilities this book describes. Rating: 4 Good but a little too far out Moravec writes a good book but I think his ideas are a tad to far out there. He doesn\\'t take into account the possiblility of people not wanting to have their minds transfered to machines. He appears to assume that it is inevitable. I personally agree with his goals but I suspect that the majority of the population would be strongly opposed. Rating: 4 Buy it for the prologue alone! I picked up this book, expecting to learn a little bit about where we\\'re headed with our computers, and the consequences therein. I learned all that-but I got even more than I bargained for. I have to say, the prologue in and of itself blew me away. I had never quite thought of humans as the first step in a bigger evolution. I read this book six months ago, and I haven\\'t been able to get the implications of it out of my head since. If you\\'re looking for the big answers-like \"Why are we here?\" and \"What\\'s the point?\"-you may be like me and find more in here than in more traditional spiritual texts. Rating: 5 A definitive Work for the strong AI perspective This is a hard Hitting Strong AI book. It\\'s the the land mark book the drew the line in the sand. If you wont to know what the strong AI position is this is the only book you have to read. You wont feel special after reading this book... So much for being on the top of the evolutionary ladder},\\nauthor = {Moravec, Hans},\\nbooktitle = {Mind Child. Futur. Robot Hum. Intell.},\\noptisbn = {0674576187},\\npages = {214 p.},\\npmid = {4329102},\\npublisher = {Harvard University Press},\\ntitle = {{Mind Children: The Future of Robot and Human Intelligence}},\\nopturl = {http://dl.acm.org/citation.cfm?id=48030 http://www.amazon.com/Mind-Children-Future-Robot-Intelligence/dp/0674576187},\\nvolume = {February 1},\\nyear = {1988}\\n}',\n",
       " 'Zhan2016': \"@article{Zhan2016,\\nabstract = {Policy advice is a transfer learning method where a student agent is able to learn faster via advice from a teacher. However, both this and other reinforcement learning transfer methods have little theoretical analysis. This paper formally defines a setting where multiple teacher agents can provide advice to a student and introduces an algorithm to leverage both autonomous exploration and teacher's advice. Our regret bounds justify the intuition that good teachers help while bad teachers hurt. Using our formalization, we are also able to quantify, for the first time, when negative transfer can occur within such a reinforcement learning setting.},\\narchivePrefix = {arXiv},\\narxivId = {1604.03986},\\nauthor = {Zhan, Yusen and Ammar, Haitham Bou and Taylor, Matthew E.},\\noptdoi = {10.1038/nature14236},\\neprint = {1604.03986},\\noptisbn = {1476-4687 (Electronic) 0028-0836 (Linking)},\\noptissn = {10450823},\\njournal = {IJCAI Int. Jt. Conf. Artif. Intell.},\\nmonth = {feb},\\nnumber = {7540},\\npages = {2315--2321},\\npmid = {25719670},\\ntitle = {{Theoretically-grounded policy advice from multiple teachers in reinforcement learning settings with applications to negative transfer}},\\nopturl = {http://www.ncbi.nlm.nih.gov/pubmed/25719670},\\nvolume = {2016-Janua},\\nyear = {2016}\\n}\",\n",
       " 'Xie2016': '@article{Xie2016,\\nabstract = {We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call \"cardinality\" (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, codenamed ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart.},\\narchivePrefix = {arXiv},\\narxivId = {1611.05431},\\nauthor = {Xie, Saining and Girshick, Ross and Doll{\\\\\\'{a}}r, Piotr and Tu, Zhuowen and He, Kaiming},\\noptdoi = {10.1109/CVPR.2017.634},\\neprint = {1611.05431},\\njournal = {arXiv:1611.05431 [cs.CV]},\\nmonth = {nov},\\ntitle = {{Aggregated Residual Transformations for Deep Neural Networks}},\\nopturl = {http://arxiv.org/abs/1611.05431},\\nyear = {2016}\\n}',\n",
       " 'Sutton1999': '@article{Sutton1999,\\nabstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and deter-mining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, indepen-dent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams\\'s REINFORCE method and actorâ€“critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy. Large applications of reinforcement learning (RL) require the use of generalizing func-tion approximators such neural networks, decision-trees, or instance-based methods. The dominant approach for the last decade has been the value-function approach, in which all function approximation effort goes into estimating a value function, with the action-selection policy represented implicitly as the \" greedy \" policy with respect to the estimated values (e.g., as the policy that selects in each state the action with highest estimated value). The value-function approach has worked well in many appli-cations, but has several limitations. First, it is oriented toward finding deterministic policies, whereas the optimal policy is often stochastic, selecting different actions with specific probabilities (e.g., see Singh, Jaakkola, and Jordan, 1994). Second, an arbi-trarily small change in the estimated value of an action can cause it to be, or not be, selected. Such discontinuous changes have been identified as a key obstacle to estab-lishing convergence assurances for algorithms following the value-function approach (Bertsekas and Tsitsiklis, 1996). For example, Q-learning, Sarsa, and dynamic pro-gramming methods have all been shown unable to converge to any policy for simple MDPs and simple function approximators (Gordon, 1995, 1996; Baird, 1995; Tsit-siklis and van Roy, 1996; Bertsekas and Tsitsiklis, 1996). This can occur even if the best approximation is found at each step before changing the policy, and whether the notion of \" best \" is in the mean-squared-error sense or the slightly different senses of residual-gradient, temporal-difference, and dynamic-programming methods.},\\nauthor = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},\\noptdoi = {10.1.1.37.9714},\\noptisbn = {0-262-19450-3},\\noptissn = {0047-2875},\\njournal = {Adv. Neural Inf. Process. Syst. 12, {\\\\{}[NIPS{\\\\}} Conf. Denver, Color. USA, Novemb. 29 - December 4, 1999]},\\npages = {1057--1063},\\npublisher = {MIT Press},\\ntitle = {{Policy Gradient Methods for Reinforcement Learning with Function Approximation}},\\nopturl = {https://homes.cs.washington.edu/{~}todorov/courses/amath579/reading/PolicyGradient.pdf http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation},\\nvolume = {07932},\\nyear = {1999}\\n}',\n",
       " 'Ranganath2016': '@article{Ranganath2016,\\nabstract = {Variational inference is an umbrella term for algorithms which cast Bayesian inference as optimization. Classically, variational inference uses the Kullback-Leibler divergence to define the optimization. Though this divergence has been widely used, the resultant posterior approximation can suffer from undesirable statistical properties. To address this, we reexamine variational inference from its roots as an optimization problem. We use operators, or functions of functions, to design variational objectives. As one example, we design a variational objective with a Langevin-Stein operator. We develop a black box algorithm, operator variational inference (OPVI), for optimizing any operator objective. Importantly, operators enable us to make explicit the statistical and computational tradeoffs for variational inference. We can characterize different properties of variational objectives, such as objectives that admit data subsampling---allowing inference to scale to massive data---as well as objectives that admit variational programs---a rich class of posterior approximations that does not require a tractable density. We illustrate the benefits of OPVI on a mixture model and a generative model of images.},\\narchivePrefix = {arXiv},\\narxivId = {1610.09033},\\nauthor = {Ranganath, Rajesh and Altosaar, Jaan and Tran, Dustin and Blei, David M.},\\neprint = {1610.09033},\\njournal = {Unpublished},\\nmonth = {oct},\\nnumber = {Nips},\\npages = {1--6},\\ntitle = {{Operator Variational Inference}},\\nopturl = {http://arxiv.org/abs/1610.09033},\\nyear = {2016}\\n}',\n",
       " 'Bongers2016': '@article{Bongers2016,\\nabstract = {Structural causal models (SCMs), also known as non-parametric struc-tural equation models (NP-SEMs), are widely used for causal modeling purposes. In this paper, we give a rigorous treatment of structural causal models, dealing with measure-theoretic complications that arise in the presence of cyclic relations. The central question studied in this paper is: given a (possibly cyclic) SCM defined on a large system (consisting of observable endogenous and latent exogenous variables), can we \" project it down \" to an SCM that describes a subsystem (consisting of a subset of the observed endogenous variables and possibly different latent exogenous variables) in order to obtain a more parsimonious but equivalent repre-sentation of the subsystem? We define a marginalization operation that effectively removes a subset of the endogenous variables from the model, and a class of mappings, exogenous reparameterizations, that can be used to reduce the space of exogenous variables. We show that both operations preserve the causal semantics of the model and that under mild conditions they can lead to a significant reduction of the model complexity, at least in terms of the number of variables in the model. We argue that for the task of estimating an SCM from data, the existence of \" smooth \" reduc-tions would be desirable. We provide several conditions under which the existence of such reductions can be shown, but also provide a counterex-ample that shows that such reductions do not exist in general. The latter result implies that existing approaches to estimate linear or Markovian SCMs from data cannot be extended to general SCMs.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1611.06221v1},\\nauthor = {Bongers, Stephan and Peters, Jonas and Sch{\\\\\"{o}}lkopf, Bernhard and Mooij, Joris M},\\neprint = {arXiv:1611.06221v1},\\njournal = {arXiv},\\nkeywords = {()},\\nmonth = {nov},\\npages = {1--44},\\ntitle = {{Structural Causal Models: Cycles, Marginalizations, Exogenous Reparametrizations and Reductions}},\\nopturl = {http://arxiv.org/abs/1611.06221},\\nyear = {2016}\\n}',\n",
       " 'Soediono1989': '@article{Soediono1989,\\nabstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and proteinâˆ’protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\\\\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD â‰¤ 2.0 {\\\\AA} for the interface backbone atoms) increased from 21{\\\\%} with default Glide SP settings to 58{\\\\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\\\\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\\\\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Soediono, Budi},\\noptdoi = {10.1017/CBO9781107415324.004},\\neprint = {arXiv:1011.1669v3},\\nfile = {:Users/adam/Documents/Mendeley/Soediono - 1989 - The Handbook of Brain Theory and Neural Networks.pdf:pdf},\\noptisbn = {9788578110796},\\noptissn = {1098-6596},\\njournal = {J. Chem. Inf. Model.},\\nkeywords = {icle},\\npages = {160},\\npmid = {25246403},\\ntitle = {{The Handbook of Brain Theory and Neural Networks}},\\nvolume = {53},\\nyear = {1989}\\n}',\n",
       " 'Naesseth2016': '@article{Naesseth2016,\\nabstract = {Variational inference using the reparameterization trick has enabled large-scale approximate Bayesian inference in complex probabilistic models, leveraging stochastic optimization to sidestep intractable expectations. The reparameterization trick is applicable when we can simulate a random variable by applying a (differentiable) deterministic function on an auxiliary random variable whose distribution is fixed. For many distributions of interest (such as the gamma or Dirichlet), simulation of random variables relies on rejection sampling. The discontinuity introduced by the accept--reject step means that standard reparameterization tricks are not applicable. We propose a new method that lets us leverage reparameterization gradients even when variables are outputs of a rejection sampling algorithm. Our approach enables reparameterization on a larger class of variational distributions. In several studies of real and synthetic data, we show that the variance of the estimator of the gradient is significantly lower than other state-of-the-art methods. This leads to faster convergence of stochastic optimization variational inference.},\\narchivePrefix = {arXiv},\\narxivId = {1610.05683},\\nauthor = {Naesseth, Christian A. and Ruiz, Francisco J. R. and Linderman, Scott W. and Blei, David M.},\\noptdoi = {10.16373/j.cnki.ahr.150049},\\neprint = {1610.05683},\\noptisbn = {0894-0282},\\noptissn = {00237205},\\nmonth = {oct},\\npmid = {22352717},\\ntitle = {{Rejection Sampling Variational Inference}},\\nopturl = {http://arxiv.org/abs/1610.05683},\\nyear = {2016}\\n}',\n",
       " 'Rolls2014': '@article{Rolls2014,\\nabstract = {Searching for and recognizing objects in complex natural scenes is implemented by multiple saccades until the eyes reach within the reduced receptive field sizes of inferior temporal cortex (IT) neurons. We analyze and model how the dorsal and ventral visual streams both contribute to this. Saliency detection in the dorsal visual system including area LIP is modeled by graph-based visual saliency, and allows the eyes to fixate potential objects within several degrees. Visual information at the fixated location subtending approximately 9Â° corresponding to the receptive fields of IT neurons is then passed through a four layer hierarchical model of the ventral cortical visual system, VisNet. We show that VisNet can be trained using a synaptic modification rule with a short-term memory trace of recent neuronal activity to capture both the required view and translation invariances to allow in the model approximately 90{\\\\%} correct object recognition for 4 objects shown in any view across a range of 135Â° anywhere in a scene. The model was able to generalize correctly within the four trained views and the 25 trained translations. This approach analyses the principles by which complementary computations in the dorsal and ventral visual cortical streams enable objects to be located and recognized in complex natural scenes.},\\nauthor = {Rolls, Edmund T. and Webb, Tristan J.},\\noptdoi = {10.3389/fncom.2014.00085},\\nfile = {:Users/adam/Documents/Mendeley/Rolls, Webb - 2014 - Finding and recognizing objects in natural scenes complementary computations in the dorsal and ventral visual syste.pdf:pdf},\\noptisbn = {1662-5188},\\noptissn = {1662-5188},\\njournal = {Front. Comput. Neurosci.},\\nkeywords = {Inferior temporal visual cortex,Invariance,Object recognition,Saliency,Trace learning rule,VisNet},\\nnumber = {AUG},\\npages = {85},\\npmid = {25161619},\\npublisher = {Frontiers},\\ntitle = {{Finding and recognizing objects in natural scenes: complementary computations in the dorsal and ventral visual systems.}},\\nopturl = {http://journal.frontiersin.org/article/10.3389/fncom.2014.00085/abstract http://www.scopus.com/inward/record.opturl?eid=2-s2.0-84905973828{\\\\&}partnerID=tZOtx3y1},\\nvolume = {8},\\nyear = {2014}\\n}',\n",
       " 'Olshausen2016foveal': \"@article{Olshausen2016foveal,\\nabstract = {We describe a neural attention model with a learnable retinal sampling lattice. The model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations. We explore the tiling properties that emerge in the model's retinal sampling lattice after training. Specifically, we show that this lattice resembles the eccentricity dependent sampling lattice of the primate retina, with a high resolution region in the fovea surrounded by a low resolution periphery. Furthermore, we find conditions where these emergent properties are amplified or eliminated providing clues to their function.},\\narchivePrefix = {arXiv},\\narxivId = {1611.09430},\\nauthor = {Cheung, Brian and Weiss, Eric and Olshausen, Bruno},\\neprint = {1611.09430},\\njournal = {ICLR},\\ntitle = {{Emergence of foveal image sampling from learning to attend in visual scenes}},\\nopturl = {http://arxiv.org/abs/1611.09430},\\nyear = {2017}\\n}\",\n",
       " 'Dayan2001': \"@book{Dayan2001,\\nabstract = {Annotation Theoretical neuroscience provides a quantitative basis for describing what nervous systems do, determining how they function, and uncovering the general principles by which they operate. This text introduces the basic mathematical and computational methods of theoretical neuroscience and presents applications in a variety of areas including vision, sensory-motor integration, development, learning, and memory. The book is divided into three parts. Part I discusses the relationship between sensory stimuli and neural responses, focusing on the representation of information by the spiking activity of neurons. Part II discusses the modeling of neurons and neural circuits on the basis of cellular and synaptic biophysics. Part III analyzes the role of plasticity in development and learning. An appendix covers the mathematical methods used, and exercises are available on the book's Web site. Neural encoding I: firing rates and spike statistics -- Neural encoding II: reverse correlation and visual receptive fields -- Neural decoding -- Information theory -- Model neurons I: neuroelectronics -- Model neurons II: conductances and morphology -- Network models -- Plasticity and learning -- Classical conditioning and reinforcement learning -- Representational learning -- Mathematical appendix.},\\nauthor = {Dayan, Peter. and Abbott, L. F.},\\noptisbn = {9780262041997},\\npages = {460},\\npublisher = {Massachusetts Institute of Technology Press},\\ntitle = {{Theoretical neuroscience : computational and mathematical modeling of neural systems}},\\nyear = {2001}\\n}\",\n",
       " 'Kingma2016': '@article{Kingma2016,\\nabstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow (IAF), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that IAF significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with IAF, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},\\narchivePrefix = {arXiv},\\narxivId = {1606.04934},\\nauthor = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},\\neprint = {1606.04934},\\nmonth = {jun},\\ntitle = {{Improving Variational Inference with Inverse Autoregressive Flow}},\\nopturl = {http://arxiv.org/abs/1606.04934},\\nyear = {2016}\\n}',\n",
       " 'Langkvist2014': '@article{Langkvist2014,\\nauthor = {L{\\\\\"{a}}ngkvist, Martin and Karlsson, Lars and Loutfi, Amy},\\noptdoi = {10.1016/j.patrec.2014.01.008},\\noptissn = {01678655},\\njournal = {Pattern Recognit. Lett.},\\nmonth = {jun},\\npages = {11--24},\\ntitle = {{A review of unsupervised feature learning and deep learning for time-series modeling}},\\nopturl = {http://linkinghub.elsevier.com/retrieve/pii/S0167865514000221},\\nvolume = {42},\\nyear = {2014}\\n}',\n",
       " 'Graves2017': '@article{Graves2017,\\nabstract = {We introduce a method for automatically selecting the path, or syllabus, that a neural network follows through a curriculum so as to maximise learning efficiency. A measure of the amount that the network learns from each data sample is provided as a reward signal to a nonstationary multi-armed bandit algorithm, which then determines a stochastic syllabus. We consider a range of signals derived from two distinct indicators of learning progress: rate of increase in prediction accuracy, and rate of increase in network complexity. Experimental results for LSTM networks on three curricula demonstrate that our approach can significantly accelerate learning, in some cases halving the time required to attain a satisfactory performance level.},\\narchivePrefix = {arXiv},\\narxivId = {1704.03003},\\nauthor = {Graves, Alex and Bellemare, Marc G. and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},\\neprint = {1704.03003},\\njournal = {Icml 2017},\\nmonth = {apr},\\ntitle = {{Automated Curriculum Learning for Neural Networks}},\\nopturl = {http://arxiv.org/abs/1704.03003},\\nyear = {2017}\\n}',\n",
       " 'Ba2016a': '@article{Ba2016a,\\nabstract = {Until recently, research on artificial neural networks was largely restricted to systems with only two types of variable: Neural activities that represent the current or recent input and weights that learn to capture regularities among inputs, outputs and payoffs. There is no good reason for this restriction. Synapses have dynamics at many different time-scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights. These \"fast weights\" can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proved very helpful in sequence-to-sequence models. By using fast weights we can avoid the need to store copies of neural activity patterns.},\\narchivePrefix = {arXiv},\\narxivId = {1610.06258},\\nauthor = {Ba, Jimmy and Hinton, Geoffrey and Mnih, Volodymyr and Leibo, Joel Z. and Ionescu, Catalin},\\neprint = {1610.06258},\\noptissn = {10495258},\\njournal = {Adv. Neural Inf. Process. Syst.},\\npages = {1--10},\\ntitle = {{Using Fast Weights to Attend to the Recent Past}},\\nopturl = {http://arxiv.org/abs/1610.06258},\\nyear = {2016}\\n}',\n",
       " 'Method': '@misc{Method,\\nauthor = {Method, Cross-entropy},\\npages = {463--480},\\ntitle = {{Cross-Entropy Method}},\\nopturl = {https://en.wikipedia.org/wiki/Cross-entropy{\\\\_}method},\\nopturldate = {2017-07-13}\\n}',\n",
       " 'Gordon2017': \"@inproceedings{Gordon2017,\\nabstract = {Robust object tracking requires knowledge and understanding of the object being tracked: its appearance, its motion, and how it changes over time. A tracker must be able to modify its underlying model and adapt to new observations. We present Re3, a real-time deep object tracker capable of incorporating long-term temporal information into its model. In line with other recent deep learning techniques, we do not train an online tracker. Instead, we use a recurrent neural network to represent the appearance and motion of the object. We train the network offline to learn how an object's appearance and motion may change, letting it track with a single forward pass at test time. This lightweight model is capable of tracking objects at 150 FPS, while attaining competitive results on challenging benchmarks. We also show that our method handles temporary occlusion better than other comparable trackers using experiments that directly measure performance on sequences with occlusion.},\\narchivePrefix = {arXiv},\\narxivId = {1705.06368},\\nauthor = {Gordon, Daniel and Farhadi, Ali and Fox, Dieter},\\nbooktitle = {arXiv:1705.06368},\\neprint = {1705.06368},\\ntitle = {{Re3 : Real-Time Recurrent Regression Networks for Object Tracking}},\\nopturl = {http://arxiv.org/abs/1705.06368},\\nyear = {2017}\\n}\",\n",
       " 'Watter2015': '@inproceedings{Watter2015,\\nabstract = {We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.},\\narchivePrefix = {arXiv},\\narxivId = {1506.07365},\\nauthor = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},\\nbooktitle = {NIPS},\\neprint = {1506.07365},\\noptissn = {10495258},\\nmonth = {jun},\\ntitle = {{Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images}},\\nopturl = {http://arxiv.org/abs/1506.07365},\\nyear = {2015}\\n}',\n",
       " 'Friston2009guide': \"@article{Friston2009guide,\\nabstract = {This article reviews a free-energy formulation that advances Helmholtz's agenda to find principles of brain function based on conservation laws and neuronal energy. It rests on advances in statistical physics, theoretical biology and machine learning to explain a remarkable range of facts about brain structure and function. We could have just scratched the surface of what this formulation offers; for example, it is becoming clear that the Bayesian brain is just one facet of the free-energy principle and that perception is an inevitable consequence of active exchange with the environment. Furthermore, one can see easily how constructs like memory, attention, value, reinforcement and salience might disclose their simple relationships within this framework. {\\\\textcopyright} 2009 Elsevier Ltd. All rights reserved.},\\nauthor = {Friston, Karl},\\noptdoi = {10.1016/j.tics.2009.04.005},\\noptisbn = {1364-6613 (Print)},\\noptissn = {13646613},\\njournal = {Trends Cogn. Sci.},\\nnumber = {7},\\npages = {293--301},\\npmid = {19559644},\\ntitle = {{The free-energy principle: a rough guide to the brain?}},\\nopturl = {http://www.fil.ion.ucl.ac.uk/{~}karl/The free-energy principle - a rough guide to the brain.pdf},\\nvolume = {13},\\nyear = {2009}\\n}\",\n",
       " 'Kirkpatrick2017': '@article{Kirkpatrick2017,\\nabstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},\\narchivePrefix = {arXiv},\\narxivId = {1612.00796},\\nauthor = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},\\noptdoi = {10.1073/pnas.1611835114},\\neprint = {1612.00796},\\noptisbn = {1215421109},\\noptissn = {0027-8424},\\njournal = {Pnas},\\nnumber = {13},\\npages = {3521--3526},\\npmid = {28292907},\\ntitle = {{Overcoming catastrophic forgetting in neural networks}},\\nopturl = {http://arxiv.org/abs/1612.00796},\\nvolume = {114},\\nyear = {2017}\\n}',\n",
       " 'Bakker2000': '@article{Bakker2000,\\nabstract = {An algorithm is introduced that trains a neural network to identify chaotic dynamics from a single measured time series. During training, the algorithm learns to shortterm predict the time series. At the same time a criterion, developed by Diks, van Zwet, Takens, and de Goede (1996) is monitored that tests the hypothesis that the reconstructed attractors of modelgenerated and measured data are the same. Training is stopped when the prediction error is low and the model passes this test. Two other features of the algorithm are (1) the way the state of the system, consisting of delays from the time series, has its dimension reduced by weighted principal component analysis data reduction, and (2) the useradjustable prediction horizon obtained by \" error propagation \" â€”partially propagating prediction errors to the next time step. The algorithm is applied to data from an experimentaldriven chaotic pendulum, of which two of the three state variables are known. This is a comprehensive example that shows how well the Diks test can distinguish between slightly different attractors. Second, the algorithm is applied to the same problem, but now one of the two known state variables is ignored. Finally, we present a model for the laser data from the Santa Fe timeseries competition (set A). It is the model for these data that is not only useful for shortterm predictions but also generates time series with similar chaotic characteristics as the measured data.},\\nauthor = {Bakker, Rembrandt and Schouten, Jaap C and Giles, C Lee and Takens, Floris and {Van Den Bleek}, Cor M and Bakker, R and Schouten, J C and Giles, C L and Takens, F and {Van Den Bleek}, C M},\\noptdoi = {10.1162/089976600300014971},\\noptisbn = {0899-7667 (Print)$\\\\backslash$r0899-7667 (Linking)},\\noptissn = {0899-7667},\\njournal = {Neural Comput. Massachusetts Inst. Technol.},\\nmonth = {oct},\\nnumber = {10},\\npages = {23552383},\\npmid = {11032038},\\npublisher = { MIT Press  238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info',\n",
       " 'Rezatofighi2016': '@article{Rezatofighi2016,\\nabstract = {This paper addresses the task of set prediction using deep learning. This is important because the output of many computer vision tasks, including image tagging and object detection, are naturally expressed as sets of entities rather than vectors. As opposed to a vector, the size of a set is not fixed in advance, and it is invariant to the ordering of entities within it. We define a likelihood for a set distribution and learn its parameters using a deep neural network. We also derive a loss for predicting a discrete distribution corresponding to set cardinality. Set prediction is demonstrated on the problems of multi-class image classification and pedestrian detection. Our approach yields state-of-the-art results in both cases on standard datasets.},\\narchivePrefix = {arXiv},\\narxivId = {1611.08998},\\nauthor = {Rezatofighi, Seyed Hamid and G, Vijay Kumar B and Milan, Anton and Abbasnejad, Ehsan and Dick, Anthony and Reid, Ian},\\neprint = {1611.08998},\\njournal = {arXiv},\\ntitle = {{DeepSetNet: Predicting Sets with Deep Neural Networks}},\\nopturl = {http://arxiv.org/abs/1611.08998},\\nyear = {2016}\\n}',\n",
       " 'Jung2011': '@article{Jung2011,\\nabstract = {This article develops generalizations of empowerment to continuous states. Empowerment is a recently introduced information-theoretic quantity motivated by hypotheses about the efficiency of the sensorimotor loop in biological organisms, but also from considerations stemming from curiosity-driven learning. Empowerment measures, for agent-environment systems with stochastic transitions, how much influence an agent has on its environment, but only that influence that can be sensed by the agent sensors. It is an information-theoretic generalization of joint controllability (influence on environment) and observability (measurement by sensors) of the environment by the agent, both controllability and observability being usually defined in control theory as the dimensionality of the control/observation spaces. Earlier work has shown that empowerment has various interesting and relevant properties, for example, it allows us to identify salient states using only the dynamics, and it can act as intrinsic reward without requiring an external reward. However, in this previous work empowerment was limited to the case of small-scale and discrete domains and furthermore state transition probabilities were assumed to be known. The goal of this article is to extend empowerment to the significantly more important and relevant case of continuous vector-valued state spaces and initially unknown state transition probabilities. The continuous state space is addressed by Monte Carlo approximation; the unknown transitions are addressed by model learning and prediction for which we apply Gaussian processes regression with iterated forecasting. In a number of well-known continuous control tasks we examine the dynamics induced by empowerment and include an application to exploration and online model learning.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1201.6583v1},\\nauthor = {Jung, T. and Polani, D. and Stone, P.},\\noptdoi = {10.1177/1059712310392389},\\neprint = {arXiv:1201.6583v1},\\noptisbn = {1059-7123},\\noptissn = {1059-7123},\\njournal = {Adapt. Behav.},\\nkeywords = {dynamical systems,information theory,learning,self-motivated behavior},\\nmonth = {jan},\\nnumber = {1},\\npages = {16--39},\\ntitle = {{Empowerment for continuous agent--environment systems}},\\nopturl = {http://arxiv.org/abs/1201.6583},\\nvolume = {19},\\nyear = {2011}\\n}',\n",
       " 'Neil2016': '@article{Neil2016,\\nabstract = {Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. Current RNN models are ill suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors which generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range which require updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes.},\\narchivePrefix = {arXiv},\\narxivId = {1610.09513},\\nauthor = {Neil, Daniel and Pfeiffer, Michael and Liu, Shih-Chii},\\neprint = {1610.09513},\\njournal = {Nips},\\nmonth = {oct},\\npages = {3882--3890},\\ntitle = {{Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences}},\\nopturl = {https://papers.nips.cc/paper/6310-phased-lstm-accelerating-recurrent-network-training-for-long-or-event-based-sequences},\\nyear = {2016}\\n}',\n",
       " 'Stollenga2014': '@inproceedings{Stollenga2014,\\nabstract = {Traditional convolutional neural networks (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNets feedback structure can dynamically alter its convolutional filter sensitivities during classification. It harnesses the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strategies (SNES). On the CIFAR-10 and CIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model.},\\narchivePrefix = {arXiv},\\narxivId = {1407.3068},\\nauthor = {Stollenga, Marijn and Masci, Jonathan and Gomez, Faustino and Schmidhuber, Juergen},\\nbooktitle = {arXiv Prepr. arXiv {\\\\ldots}},\\neprint = {1407.3068},\\noptissn = {10495258},\\npages = {13},\\ntitle = {{Deep Networks with Internal Selective Attention through Feedback Connections}},\\nopturl = {http://arxiv.org/abs/1407.3068},\\nyear = {2014}\\n}',\n",
       " 'Vezhnevets2017': '@article{Vezhnevets2017,\\nabstract = {We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment.},\\narchivePrefix = {arXiv},\\narxivId = {1703.01161},\\nauthor = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},\\neprint = {1703.01161},\\njournal = {arXiv},\\nmonth = {mar},\\ntitle = {{FeUdal Networks for Hierarchical Reinforcement Learning}},\\nopturl = {http://arxiv.org/abs/1703.01161},\\nyear = {2017}\\n}',\n",
       " 'Hinton2006dbn': '@article{Hinton2006dbn,\\nabstract = {We show how to use â€œcomplementary priorsâ€ to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connecti...},\\nauthor = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},\\noptdoi = {10.1162/neco.2006.18.7.1527},\\noptissn = {0899-7667},\\njournal = {Neural Comput.},\\nmonth = {jul},\\nnumber = {7},\\npages = {1527--1554},\\npublisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info',\n",
       " 'Pezeshki2016': '@article{Pezeshki2016,\\nabstract = {Manual labeling of data is and will remain a costly endeavor. For this reason, semi-supervised learning remains a topic of practical importance. The recently proposed Ladder Network is one such approach that has proven to be very successful. In addition to the supervised objective, the Ladder Network also adds an unsupervised objective corresponding to the reconstruction costs of a stack of denoising autoencoders. Although the results are impressive, the Ladder Network has many components intertwined, whose contributions are not obvious in such a complex architecture. In order to help elucidate and disentangle the different ingredients in the Ladder Network recipe, this paper presents an extensive experimental investigation of variants of the Ladder Network in which we replace or remove individual components to gain more insight into their relative importance. We find that all of the components are necessary for achieving optimal performance, but they do not contribute equally. For semi-supervised tasks, we conclude that the most important contribution is made by the lateral connection, followed by the application of noise, and finally the choice of combinator function in the decoder path. We also find that as the number of labeled training examples increases, the lateral connections and reconstruction criterion become less important, with most of the improvement in generalization due to the injection of noise in each layer. Furthermore, we present a new type of combinator functions that outperforms the original design in both fully- and semi-supervised tasks, reducing record test error rates on Permutation-Invariant MNIST to 0.57{\\\\%} for supervised setting, and to 0.97{\\\\%} and 1.0{\\\\%} for semi-supervised settings with 1000 and 100 labeled examples respectively.},\\narchivePrefix = {arXiv},\\narxivId = {1511.06430},\\nauthor = {Pezeshki, Mohammad and Fan, Linxi and Brakel, Philemon and Courville, Aaron and Bengio, Yoshua},\\neprint = {1511.06430},\\noptisbn = {9290795158},\\noptissn = {9290795158},\\njournal = {Iclr},\\npages = {1--15},\\ntitle = {{Deconstructing the Ladder Network Architecture}},\\nopturl = {http://arxiv.org/abs/1511.06430},\\nvolume = {48},\\nyear = {2016}\\n}',\n",
       " 'Mumford1992': \"@article{Mumford1992,\\nabstract = {This paper is a sequel to an earlier paper which proposed an active role for the thalamus, inte-grating multiple hypotheses formed in the cortex via the thalamo-cortical loop. In this paper, I put forward a hypothesis on the role of the reciprocal, topographic pathways between two cortical areas, one often a 'higher' area dealing with more abstract information about the world, the other 'lower', dealing with more concrete data. The higher area attempts to fit its ab-stractions to the data it receives from lower areas by sending back to them from its deep pyramidal cells a template reconstruction best fitting the lower level view. The lower area attempts to reconcile the reconstruction of its view that it receives from higher areas with what it knows, sending back from its superficial pyramidal cells the features in its data which are not predicted by the higher area. The whole calculation is done with all areas working simultaneously, but with order imposed by synchronous activity in the various top-down, bot-tom-up loops. Evidence for this theory is reviewed and experimental tests are proposed. A third part of this paper will deal with extensions of these ideas to the frontal lobe.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1408.1149},\\nauthor = {Mumford, D.},\\noptdoi = {10.1007/BF00198477},\\neprint = {arXiv:1408.1149},\\noptisbn = {0340-1200},\\noptissn = {03401200},\\njournal = {Biol. Cybern.},\\nnumber = {3},\\npages = {241--251},\\npmid = {1912004},\\ntitle = {{On the computational architecture of the neocortex - II The role of cortico-cortical loops}},\\nopturl = {http://cs.brown.edu/people/tld/projects/cortex/course/suggested{\\\\_}reading{\\\\_}list/supplements/documents/MumfordBC-92.pdf},\\nvolume = {66},\\nyear = {1992}\\n}\",\n",
       " 'Usunier2016': '@article{Usunier2016,\\nabstract = {We consider scenarios from the real-time strategy game StarCraft as new benchmarks for reinforcement learning algorithms. We propose micromanagement tasks, which present the problem of the short-term, low-level control of army members during a battle. From a reinforcement learning point of view, these scenarios are challenging because the state-action space is very large, and because there is no obvious feature representation for the state-action evaluation function. We describe our approach to tackle the micromanagement scenarios with deep neural network controllers from raw state features given by the game engine. In addition, we present a heuristic reinforcement learning algorithm which combines direct exploration in the policy space and backpropagation. This algorithm allows for the collection of traces for learning using deterministic policies, which appears much more efficient than, for example, {\\\\{}$\\\\backslash$epsilon{\\\\}}-greedy exploration. Experiments show that with this algorithm, we successfully learn non-trivial strategies for scenarios with armies of up to 15 agents, where both Q-learning and REINFORCE struggle.},\\narchivePrefix = {arXiv},\\narxivId = {1609.02993},\\nauthor = {Usunier, Nicolas and Synnaeve, Gabriel and Lin, Zeming and Chintala, Soumith},\\neprint = {1609.02993},\\njournal = {arXiv},\\nmonth = {sep},\\npages = {1--19},\\ntitle = {{Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks}},\\nopturl = {http://arxiv.org/abs/1609.02993},\\nyear = {2016}\\n}',\n",
       " 'Chen2017': \"@article{Chen2017,\\nabstract = {Representation learning seeks to expose certain aspects of observed data in a learned representation that's amenable to downstream tasks like classification. For instance, a good representation for 2D images might be one that describes only global structure and discards information about detailed texture. In this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN. Our proposed VAE model allows us to have control over what the global latent code can learn and by designing the architecture accordingly, we can force the global latent code to discard irrelevant information such as texture in 2D images, and hence the code only â€œautoencodesâ€ data in a lossy fashion. In addition, by leveraging autoregressive models as both prior distribution p(z) and decoding distribution p(x|z), we can greatly improve generative modeling performance of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and Caltech-101 Silhouettes density estimation tasks.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1611.02731v1},\\nauthor = {Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter and Science, Computer and Science, Computer},\\neprint = {arXiv:1611.02731v1},\\njournal = {Int. Conf. Learn. Represent.},\\nmonth = {nov},\\npages = {1--14},\\ntitle = {{Variational Lossy Autoencoder}},\\nopturl = {http://arxiv.org/abs/1611.02731},\\nyear = {2017}\\n}\",\n",
       " 'Dipietro2017': '@article{Dipietro2017,\\nabstract = {Recurrent neural networks (RNNs) have achieved state-of-the-art performance on many diverse tasks, from machine translation to surgical activity recognition, yet training RNNs to capture long-term dependencies remains difficult. To date, the vast majority of successful RNN architectures alleviate this problem by facilitating long-term gradient flow using nearly-additive connections between adjacent states, as originally introduced in long short-term memory (LSTM). In this paper, we investigate a different approach for encouraging gradient flow that is based on NARX RNNs, which generalize typical RNNs by allowing direct connections from the distant past. Analytically, we 1) generalize previous gradient decompositions for typical RNNs to general NARX RNNs and 2) formally connect gradient flow to edges along paths. We then introduce an example architecture that is based on these ideas, and we demonstrate that this architecture matches or exceeds LSTM performance on 5 diverse tasks. Finally we describe many avenues for future work, including the exploration of other NARX RNN architectures, the possible combination of mechanisms from LSTM and NARX RNNs, and the adoption of recent LSTM-based advances to NARX RNN architectures.},\\narchivePrefix = {arXiv},\\narxivId = {1702.07805},\\nauthor = {DiPietro, Robert and Rupprecht, Christian and Navab, Nassir and Hager, Gregory D.},\\neprint = {1702.07805},\\nmonth = {feb},\\ntitle = {{Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies}},\\nopturl = {http://arxiv.org/abs/1702.07805},\\nyear = {2017}\\n}',\n",
       " 'Author2017': '@article{Author2017,\\nabstract = {The reinforcement learning paradigm allows, in principle, for complex behaviours 1 to be learned directly from simple reward signals. In practice, it is hard to design 2 a reward signal that, encourages desired behaviour. As a result, reward functions 3 tend to be carefully hand-designed or else derived from demonstration data. In this 4 paper we attempt to explore the extent to which a highly enriched environment can 5 promote sensible behavior, while relying on a simple reward signal. Specifically, 6 by training agents in a much wider diversity of rich environmental contexts, we 7 find that we encourage the emergence of robust behaviours that perform well 8 across a suite of tasks. We demonstrate this principle in the context of locomotion 9 behaviours â€“ tasks known for their brittleness in terms of reward function design. 10 We train multiple bodies on a diverse set of challenging terrains and obstacles, 11 using a simple reward function based solely on forward progress. Using a novel, 12 high-performance variant of policy gradient reinforcement learning, our agent 13 learns emergent locomotion behaviours including running, jumping, crouching and 14 turning. A summary of our results can be viewed in this video.},\\narchivePrefix = {arXiv},\\narxivId = {1707.02286},\\nauthor = {Author, Anonymous and Address, Affiliation},\\neprint = {1707.02286},\\nmonth = {jul},\\nnumber = {Nips},\\ntitle = {{Emergence of Locomotion Behaviours in Rich Environments}},\\nopturl = {http://arxiv.org/abs/1707.02286},\\nyear = {2017}\\n}',\n",
       " 'Friston2016': \"@misc{Friston2016,\\nabstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},\\nauthor = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},\\nbooktitle = {Neurosci. Biobehav. Rev.},\\noptdoi = {10.1016/j.neubiorev.2016.06.022},\\noptisbn = {0149-7634},\\noptissn = {18737528},\\nkeywords = {Active inference,Bayesian inference,Bayesian surprise,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Information gain},\\nmonth = {sep},\\npages = {862--879},\\npmid = {27375276},\\ntitle = {{Active inference and learning}},\\nopturl = {http://linkinghub.elsevier.com/retrieve/pii/S0149763416301336},\\nvolume = {68},\\nyear = {2016}\\n}\",\n",
       " 'Bengio2009': \"@inproceedings{Bengio2009,\\nabstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illus- trates gradually more concepts, and gradu- ally more complex ones. Here, we formal- ize such training strategies in the context of machine learning, and call them â€œcurricu- lum learningâ€. In the context of recent re- search studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neu- ral networks), we explore curriculum learn- ing in various set-ups. The experiments show that significant improvements in generaliza- tion can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},\\naddress = {New York, New York, USA},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Bengio, Yoshua and Louradour, J{\\\\'{e}}r{\\\\^{o}}me and Collobert, Ronan and Weston, Jason},\\nbooktitle = {ICML},\\noptdoi = {10.1145/1553374.1553380},\\neprint = {arXiv:1011.1669v3},\\noptisbn = {9781605585161},\\noptissn = {0022-5193},\\npmid = {5414602},\\npublisher = {ACM Press},\\ntitle = {{Curriculum learning}},\\nopturl = {http://portal.acm.org/citation.cfm?optdoid=1553374.1553380},\\nyear = {2009}\\n}\",\n",
       " 'Ning2016': '@article{Ning2016,\\nabstract = {In this paper, we develop a new approach of spatially supervised recurrent convolutional neural networks for visual object tracking. Our recurrent convolutional network exploits the history of locations as well as the distinctive visual features learned by the deep neural networks. Inspired by recent bounding box regression methods for object detection, we study the regression capability of Long Short-Term Memory (LSTM) in the temporal domain, and propose to concatenate high-level visual features produced by convolutional networks with region information. In contrast to existing deep learning based trackers that use binary classification for region candidates, we use regression for direct prediction of the tracking locations both at the convolutional layer and at the recurrent unit. Our extensive experimental results and performance comparison with state-of-the-art tracking methods on challenging benchmark video tracking datasets shows that our tracker is more accurate and robust while maintaining low computational cost. For most test video sequences, our method achieves the best tracking performance, often outperforms the second best by a large margin.},\\narchivePrefix = {arXiv},\\narxivId = {1607.05781},\\nauthor = {Ning, Guanghan and Zhang, Zhi and Huang, Chen and He, Zhihai and Ren, Xiaobo and Wang, Haohong},\\neprint = {1607.05781},\\njournal = {arXiv Prepr. arXiv1607.05781},\\ntitle = {{Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking}},\\nopturl = {http://arxiv.org/abs/1607.05781},\\nyear = {2016}\\n}',\n",
       " 'Geiger2013': '@article{Geiger2013,\\nabstract = {Abstract We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10â€“100 Hz using a variety of sensor modalities such as high-resolution color and ...},\\nauthor = {Geiger, A. and Lenz, P. and Stiller, C. and Urtasun, R.},\\noptdoi = {10.1177/0278364913491297},\\noptissn = {0278-3649},\\njournal = {Int. J. Rob. Res.},\\nkeywords = {Benchmarks,Dataset,GPS,KITTI,SLAM,Stereo,autonomous driving,cameras,computer vision,field robotics,laser,mobile robotics,object detection,optical flow,tracking},\\nmonth = {sep},\\nnumber = {11},\\npages = {1231--1237},\\npublisher = {SAGE PublicationsSage UK: London, England},\\ntitle = {{Vision meets robotics: The KITTI dataset}},\\nopturl = {http://ijr.sagepub.com/cgi/optdoi/10.1177/0278364913491297},\\nvolume = {32},\\nyear = {2013}\\n}',\n",
       " 'Mishkin2015': '@article{Mishkin2015,\\nabstract = {Layer-sequential unit-variance (LSUV) initialization - a simple strategy for weight initialization for deep net learning - is proposed. The strategy proceeds from the first to the final layer, normalizing the variance of the output of each layer to be equal to one. We show that with the strategy, learning of very deep nets via standard stochastic gradient descent is at least as fast as the complex schemes proposed specifically for very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava et al. (2015)). Performance that is state-of-the-art, or very close to it, is achieved on the MNIST, CIFAR, ImageNet datasets.},\\narchivePrefix = {arXiv},\\narxivId = {1511.06422},\\nauthor = {Mishkin, Dmytro and Matas, Jiri},\\noptdoi = {10.1016/0898-1221(96)87329-9},\\neprint = {1511.06422},\\noptisbn = {0262560992},\\noptissn = {08981221},\\njournal = {Iclr},\\nkeywords = {Initialization,Optimization},\\nmonth = {nov},\\npages = {1--8},\\npmid = {21595383},\\ntitle = {{All you need is a good init}},\\nopturl = {http://arxiv.org/abs/1511.06422},\\nyear = {2015}\\n}',\n",
       " 'KthActivityRecognition': '@inproceedings{KthActivityRecognition,\\nabstract = {Local space-time features capture local events in video and can be adapted to the size, the frequency and the veloc-ity of moving patterns. In this paper we demonstrate how such features can be used for recognizing complex motion patterns. We construct video representations in terms of lo-cal space-time features and integrate such representations with SVM classification schemes for recognition. For the purpose of evaluation we introduce a new video database containing 2391 sequences of six human actions performed by 25 people in four different scenarios. The presented re-sults of action recognition justify the proposed method and demonstrate its advantage compared to other relative ap-proaches for action recognition.},\\narchivePrefix = {arXiv},\\narxivId = {1505.04868},\\nauthor = {Schuldt, Christian and Laptev, Ivan and Caputo, Barbara},\\nbooktitle = {ICPR},\\noptdoi = {10.1109/ICPR.2004.1334462},\\neprint = {1505.04868},\\noptisbn = {0769521282},\\noptissn = {10514651},\\npmid = {12171414},\\npublisher = {IEEE},\\ntitle = {{Recognizing human actions: A local SVM approach}},\\nopturl = {http://ieeexplore.ieee.org/document/1334462/},\\nyear = {2004}\\n}',\n",
       " 'Okada2017': '@article{Okada2017,\\nabstract = {In this paper, we introduce Path Integral Networks (PI-Net), a recurrent network representation of the Path Integral optimal control algorithm. The network includes both system dynamics and cost models, used for optimal control based planning. PI-Net is fully differentiable, learning both dynamics and cost models end-to-end by back-propagation and stochastic gradient descent. Because of this, PI-Net can learn to plan. PI-Net has several advantages: it can generalize to unseen states thanks to planning, it can be applied to continuous control tasks, and it allows for a wide variety learning schemes, including imitation and reinforcement learning. Preliminary experiment results show that PI-Net, trained by imitation learning, can mimic control demonstrations for two simulated problems; a linear system and a pendulum swing-up problem. We also show that PI-Net is able to learn dynamics and cost models latent in the demonstrations.},\\narchivePrefix = {arXiv},\\narxivId = {1706.09597},\\nauthor = {Okada, Masashi and Rigazio, Luca and Aoshima, Takenobu},\\neprint = {1706.09597},\\nmonth = {jun},\\ntitle = {{Path Integral Networks: End-to-End Differentiable Optimal Control}},\\nopturl = {http://arxiv.org/abs/1706.09597},\\nyear = {2017}\\n}',\n",
       " 'Gauthier2016': '@article{Gauthier2016,\\nabstract = {A distinguishing property of human intelligence is the ability to flexibly use language in order to communicate complex ideas with other humans in a variety of contexts. Research in natural language dialogue should focus on designing communicative agents which can integrate themselves into these contexts and productively collaborate with humans. In this abstract, we propose a general situated language learning paradigm which is designed to bring about robust language agents able to cooperate productively with humans.},\\narchivePrefix = {arXiv},\\narxivId = {1610.03585},\\nauthor = {Gauthier, Jon and Mordatch, Igor},\\neprint = {1610.03585},\\njournal = {ArXiv},\\ntitle = {{A Paradigm for Situated and Goal-Driven Language Learning}},\\nopturl = {http://arxiv.org/abs/1610.03585},\\nyear = {2016}\\n}',\n",
       " 'Oland2017': '@article{Oland2017,\\nabstract = {In this work, we show that saturating output activation functions, such as the softmax, impede learning on a number of standard classification tasks. Moreover, we present results showing that the utility of softmax does not stem from the normalization, as some have speculated. In fact, the normalization makes things worse. Rather, the advantage is in the exponentiation of error gradients. This exponential gradient boosting is shown to speed up convergence and improve generalization. To this end, we demonstrate faster convergence and better performance on diverse classification tasks: image classification using CIFAR-10 and ImageNet, and semantic segmentation using PASCAL VOC 2012. In the latter case, using the state-of-the-art neural network architecture, the model converged 33{\\\\%} faster with our method (roughly two days of training less) than with the standard softmax activation, and with a slightly better performance to boot.},\\narchivePrefix = {arXiv},\\narxivId = {1707.04199},\\nauthor = {Oland, Anders and Bansal, Aayush and Dannenberg, Roger B. and Raj, Bhiksha},\\neprint = {1707.04199},\\nmonth = {jul},\\ntitle = {{Be Careful What You Backpropagate: A Case For Linear Output Activations {\\\\&} Gradient Boosting}},\\nopturl = {http://arxiv.org/abs/1707.04199},\\nyear = {2017}\\n}',\n",
       " 'Ionescu': '@article{Ionescu,\\nabstract = {Deep neural network architectures have recently pro-duced excellent results in a variety of areas in artificial intelligence and visual recognition, well surpassing tradi-tional shallow architectures trained using hand-designed features. The power of deep networks stems both from their ability to perform local computations followed by pointwise non-linearities over increasingly larger receptive fields, and from the simplicity and scalability of the gradient-descent training procedure based on backpropagation. An open problem is the inclusion of layers that perform global, struc-tured matrix computations like segmentation (e.g. normal-ized cuts) or higher-order pooling (e.g. log-tangent space metrics defined over the manifold of symmetric positive def-inite matrices) while preserving the validity and efficiency of an end-to-end deep training framework. In this paper we propose a sound mathematical apparatus to formally inte-grate global structured computation into deep computation architectures. At the heart of our methodology is the de-velopment of the theory and practice of backpropagation that generalizes to the calculus of adjoint matrix variations. We perform segmentation experiments using the BSDS and MSCOCO benchmarks and demonstrate that deep networks relying on second-order pooling and normalized cuts lay-ers, trained end-to-end using matrix backpropagation, out-perform counterparts that do not take advantage of such global layers.},\\nauthor = {Ionescu, Catalin and Vantzos, Orestis and Sminchisescu, Cristian},\\npages = {2965--2973},\\ntitle = {{Matrix Backpropagation for Deep Networks with Structured Layers}},\\nopturl = {http://www.cv-foundation.org/openaccess/content{\\\\_}iccv{\\\\_}2015/papers/Ionescu{\\\\_}Matrix{\\\\_}Backpropagation{\\\\_}for{\\\\_}ICCV{\\\\_}2015{\\\\_}paper.pdf}\\n}',\n",
       " 'Kakar2017': '@article{Kakar2017,\\nabstract = {A survey study was conducted from June to December 2009 using standard parasitological procedures to determine the prevalence of tick infestation among cattle of different breeds in Maiduguri, Northeastern Nigeria.  The tick species identified were  Boophilus microplus ,  Amblyomma variegatum ,  Hyalomma  spp.,  Rhipicephalus sanguineous  and  Ornithodorus  spp. Of the 205 cattle examined, 63.4{\\\\%} (95{\\\\%} CI: 56.8 â€“ 70.0) were tick infested. Males had a non â€“ significantly (P {\\\\textgreater} 0.05) higher infestation rate of 63.4{\\\\%} (56.7 â€“ 71.7) compared with the females 60.9{\\\\%} (46.8 â€“ 75.0). Younger animals aged â‰¤ 3 years had a significantly (P {\\\\textless} 0.05) higher prevalence of 85.4{\\\\%} (74.6 â€“ 96.2) as compared with the adults aged {\\\\textgreater} 3 â€“ 7 years 55.8{\\\\%} (46.3 â€“ 65.3) and older animals {\\\\textgreater} 7 years 35.0{\\\\%} (22.9 â€“ 47.1). Among breeds, Wadara and Kuri had significantly (P {\\\\textless} 0.05) higher infestation rates of 66.1{\\\\%} (57.9 â€“ 74.3) and 66.7{\\\\%} (13.4 â€“ 120.0) respectively. Gudali had 60.9{\\\\%} (41.0 â€“ 80.8), Rahaji 58.0{\\\\%} (44.3 â€“ 71.7) and Bunaji 50.0{\\\\%} (19.3 â€“ 119.3). Based on the predilection sites, the udder and external genitalia, inner thigh and under the tail/perineum were the most tick-infested sites with 84.3{\\\\%} (78.3 â€“ 88.5), 79.0{\\\\%} (73.4 â€“ 84.6) and 69.8{\\\\%} (63.5 â€“ 76.1) respectively (P {\\\\textless} 0.05). While the less preferred sites eyes, neck/dewlap, ears and all over the body each had prevalence of 26.3{\\\\%} (20.3 â€“ 32.3), 14.6{\\\\%} (9.8 â€“ 1.4), 12.2{\\\\%} (7.7 â€“ 16.7) and 11.2{\\\\%} (6.9 â€“ 15.5) respectively. This study reveals high prevalence of tick infestation among indigenous cattle in Maiduguri. This might hamper cattle production and productivity in Nigeria. Thus, it is recommended that appropriate control strategies be instituted to control ticks in the study area.   optdoi:    http://dx.optdoi.org/10.3329/bjvm.v12i2.21279          Bangl. J. Vet. Med   . (2014). 12 (2): 161-166   \\xa0},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Kakar, M. E. and Khan, M. A. and Khan, M. S. and Ashraf, K. and Kakar, M. A. and Hamdullah and Jan, S. and Razzaq, A.},\\noptdoi = {10.1017/CBO9781107415324.004},\\neprint = {arXiv:1011.1669v3},\\noptisbn = {9788578110796},\\noptissn = {10187081},\\njournal = {J. Anim. Plant Sci.},\\nkeywords = {Balochistan,Cattle,Prevalence,Quetta,Tick infestation},\\nmonth = {jul},\\nnumber = {3},\\npages = {797--802},\\npmid = {25246403},\\ntitle = {{Prevalence of tick infestation in different breeds of cattle in balochistan}},\\nopturl = {http://arxiv.org/abs/1507.02672},\\nvolume = {27},\\nyear = {2017}\\n}',\n",
       " 'Christiano2016': '@article{Christiano2016,\\nabstract = {â€” Developing control policies in simulation is often more practical and safer than directly running experiments in the real world. This applies to policies obtained from planning and optimization, and even more so to policies obtained from reinforcement learning, which is often very data demanding. However, a policy that succeeds in simulation often doesnt work when deployed on a real robot. Nevertheless, often the overall gist of what the policy does in simulation remains valid in the real world. In this paper we investigate such settings, where the sequence of states traversed in simulation remains reasonable for the real world, even if the details of the controls are not, as could be the case when the key differences lie in detailed friction, contact, mass and geometry properties. During execution, at each time step our approach computes what the simulation-based control policy would do, but then, rather than executing these controls on the real robot, our approach computes what the simulation expects the resulting next state(s) will be, and then relies on a learned deep inverse dynamics model to decide which real-world action is most suitable to achieve those next states. Deep models are only as good as their training data, and we also propose an approach for data collec-tion to (incrementally) learn the deep inverse dynamics model. Our experiments shows our approach compares favorably with various baselines that have been developed for dealing with simulation to real world model discrepancy, including output error control and Gaussian dynamics adaptation.},\\narchivePrefix = {arXiv},\\narxivId = {1610.03518},\\nauthor = {Christiano, Paul and Shah, Zain and Mordatch, Igor and Schneider, Jonas and Blackwell, Trevor and Tobin, Joshua and Abbeel, Pieter and Zaremba, Wojciech},\\neprint = {1610.03518},\\njournal = {arXiv Prepr.},\\ntitle = {{Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model}},\\nopturl = {https://arxiv.org/pdf/1610.03518v1.pdf},\\nyear = {2016}\\n}',\n",
       " 'Milner2008': \"@article{Milner2008,\\nabstract = {The model proposed by the authors of two cortical systems providing 'vision for action' and 'vision for perception', respectively, owed much to the inspiration of Larry Weiskrantz. In the present article some essential concepts inherent in the model are summarized, and certain clarifications and refinements are offered. Some illustrations are given of recent experiments by ourselves and others that have prompted us to sharpen these concepts. Our explicit hope in writing our book in 1995 was to provide a theoretical framework that would stimulate research in the field. Conversely, well-designed empirical contributions conceived within the framework of the model are the only way for us to progress along the route towards a fully fleshed-out specification of its workings. {\\\\textcopyright} 2007 Elsevier Ltd. All rights reserved.},\\nauthor = {Milner, A. D. and Goodale, M. A.},\\noptdoi = {10.1016/j.neuropsychologia.2007.10.005},\\nfile = {:Users/adam/Documents/Mendeley/Milner, Goodale - 2008 - Two visual systems re-viewed.pdf:pdf},\\noptisbn = {4618471212},\\noptissn = {00283932},\\njournal = {Neuropsychologia},\\nkeywords = {Cortex,Dorsal stream,Perception,Ventral stream,Vision,Visuomotor control},\\nnumber = {3},\\npages = {774--785},\\npmid = {18037456},\\ntitle = {{Two visual systems re-viewed}},\\nopturl = {https://mechanism.ucsd.edu/teaching/w12/philneuro/milner.twovisualsystemre-viewed.2008.pdf},\\nvolume = {46},\\nyear = {2008}\\n}\",\n",
       " 'SÃ¸nderby2016a': '@misc{SÃ¸nderby2016a,\\nabstract = {Variational Autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difficult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model, the Ladder Variational Autoencoder, that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally, we observe that batch normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.},\\narchivePrefix = {arXiv},\\narxivId = {1602.02282},\\nauthor = {S{\\\\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\\\\o}e, Lars and S{\\\\o}nderby, S{\\\\o}ren Kaae and Winther, Ole},\\nbooktitle = {Nips},\\neprint = {1602.02282},\\noptissn = {10495258},\\nnumber = {Nips},\\npages = {3738--3746},\\ntitle = {{Ladder Variational Autoencoders}},\\nopturl = {http://arxiv.org/abs/1602.02282},\\nyear = {2016}\\n}',\n",
       " 'Sutton1991': \"@article{Sutton1991,\\nabstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Sutton, Richard S.},\\noptdoi = {10.1145/122344.122377},\\neprint = {arXiv:1011.1669v3},\\noptisbn = {1-55860-141-4},\\noptissn = {0163-5719},\\njournal = {ACM SIGART Bull.},\\nmonth = {jul},\\nnumber = {4},\\npages = {160--163},\\npmid = {15003161},\\npublisher = {ACM},\\ntitle = {{Dyna, an integrated architecture for learning, planning, and reacting}},\\nopturl = {http://portal.acm.org/citation.cfm?id=122377{\\\\%}5Cnhttp://portal.acm.org/ft{\\\\_}gateway.cfm?id=122377{\\\\&}type=pdf{\\\\&}CFID=15362012{\\\\&}CFTOKEN=82111550},\\nvolume = {2},\\nyear = {1991}\\n}\",\n",
       " 'Lapedes1988': '@article{Lapedes1988,\\nauthor = {Lapedes, AS and Farber, RM},\\njournal = {NIPS},\\ntitle = {{How neural nets work}},\\nopturl = {http://papers.nips.cc/paper/59-how-neural-nets-work.pdf},\\nyear = {1988}\\n}',\n",
       " 'Jaderberg2016': '@inproceedings{Jaderberg2016,\\nabstract = {Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880$\\\\backslash${\\\\%} expert human performance, and a challenging suite of first-person, three-dimensional $\\\\backslash$emph{\\\\{}Labyrinth{\\\\}} tasks leading to a mean speedup in learning of 10{\\\\$}\\\\backslashtimes{\\\\$} and averaging 87$\\\\backslash${\\\\%} expert human performance on Labyrinth.},\\narchivePrefix = {arXiv},\\narxivId = {1611.05397},\\nauthor = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},\\nbooktitle = {arXiv:1611.05397},\\noptdoi = {10.1051/0004-6361/201527329},\\neprint = {1611.05397},\\nfile = {:Users/adam/Documents/Mendeley/Jaderberg et al. - 2016 - Reinforcement Learning with Unsupervised Auxiliary Tasks.pdf:pdf},\\noptisbn = {2004012439},\\noptissn = {0004-6361},\\npmid = {23459267},\\ntitle = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},\\nopturl = {http://arxiv.org/abs/1611.05397},\\nyear = {2016}\\n}',\n",
       " 'Decety2003': \"@inproceedings{Decety2003,\\nabstract = {There is converging evidence from developmental and cognitive psychology, as well as from neuroscience, to suggest that the self is both special and social, and that self-other interaction is the driving force behind self-development. We review experimental findings which demonstrate that human infants are motivated for social interactions and suggest that the development of an awareness of other minds is rooted in the implicit notion that others are like the self. We then marshal evidence from functional neuroimaging explorations of the neurophysiological substrate of shared representations between the self and others, using various ecological paradigms such as mentally representing one's own actions versus others' actions, watching the actions executed by others, imitating the others' actions versus being imitated by others. We suggest that within this shared neural network the inferior parietal cortex and the prefrontal cortex in the right hemisphere play a special role in the essential ability to distinguish the self from others, and in the way the self represents the other. Interestingly, the right hemisphere develops its functions earlier than the left. ?? 2003 Elsevier Inc. All rights reserved.},\\nauthor = {Decety, Jean and Chaminade, Thierry},\\nbooktitle = {Conscious. Cogn.},\\noptdoi = {10.1016/S1053-8100(03)00076-X},\\noptisbn = {1053-8100 (Print) 1053-8100 (Linking)},\\noptissn = {10538100},\\nkeywords = {Agency,Empathy,Imitation,Intersubjectivity,Prefrontal cortex,Right parietal cortex,Self-other connectedness,Shared representations},\\nnumber = {4},\\npages = {577--596},\\npmid = {14656502},\\ntitle = {{When the self represents the other: A new cognitive neuroscience view on psychological identification}},\\nopturl = {http://journalpsyche.org/articles/0xc063.pdf},\\nvolume = {12},\\nyear = {2003}\\n}\",\n",
       " 'Cheung2016gtc': '@inproceedings{Cheung2016gtc,\\nauthor = {Cheung, Brian},\\nbooktitle = {GPU Technol. Conf.},\\ntitle = {{Neural Attention for Object Tracking}},\\nopturl = {http://on-demand.gputechconf.com/gtc/2016/presentation/s6497-brian-cheung-neural-attention-for-object-tracking.pdf},\\nyear = {2016}\\n}',\n",
       " 'Fristona': \"@article{Fristona,\\nabstract = {This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidenceâ€”or minimizing variational free energyâ€”we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes' optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technicall...},\\narchivePrefix = {arXiv},\\narxivId = {1309.2848v1},\\nauthor = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and Pezzulo, Giovanni},\\noptdoi = {10.1162/NECO_a_00912},\\neprint = {1309.2848v1},\\noptisbn = {0899-7667},\\noptissn = {0899-7667},\\njournal = {Neural Comput.},\\nnumber = {1},\\npages = {1--49},\\npmid = {25602775},\\ntitle = {{Active Inference: A Process Theory}},\\nopturl = {http://www.fil.ion.ucl.ac.uk/{~}karl/Active Inference A Process Theory.pdf http://www.mitpressjournals.org/optdoi/10.1162/NECO{\\\\_}a{\\\\_}00912},\\nvolume = {29},\\nyear = {2017}\\n}\",\n",
       " 'Zhang2017a': '@article{Zhang2017a,\\nabstract = {In this paper we introduce a fully end-to-end approach for visual tracking in videos that learns to predict the bounding box locations of a target object at every frame. An important insight is that the tracking problem can be considered as a sequential decision-making process and historical semantics encode highly relevant information for future decisions. Based on this intuition, we formulate our model as a recurrent convolutional neural network agent that interacts with a video overtime, and our model can be trained with reinforcement learning (RL) algorithms to learn good tracking policies that pay attention to continuous, inter-frame correlation and maximize tracking performance in the long run. The proposed tracking algorithm achieves state-of-the-art performance in an existing tracking benchmark and operates at frame-rates faster than real-time. To the best of our knowledge, our tracker is the first neural-network tracker that combines convolutional and recurrent networks with RL algorithms.},\\narchivePrefix = {arXiv},\\narxivId = {1701.08936},\\nauthor = {Zhang, Da and Maei, Hamid and Wang, Xin and Wang, Yuan-Fang},\\neprint = {1701.08936},\\nmonth = {jan},\\ntitle = {{Deep Reinforcement Learning for Visual Object Tracking in Videos}},\\nopturl = {http://arxiv.org/abs/1701.08936},\\nyear = {2017}\\n}',\n",
       " 'Ungerleider2000': '@article{Ungerleider2000,\\nabstract = {A typical scene contains many different objects that, because of $\\\\backslash$nthe limited processing capacity of the visual system, compete for $\\\\backslash$nneural representation. The competition among multiple objects in $\\\\backslash$nvisual cortex can be biased by both bot-tom- up sensory-driven $\\\\backslash$nmechanisms and top-down influences, such as selective atten-tion. $\\\\backslash$nFunctional brain imaging studies reveal that, both in the absence $\\\\backslash$nand in the presence of visual stimulation, biasing signals due to $\\\\backslash$nselective attention can modulate neural activity in visual cortex $\\\\backslash$nin several ways. Although the competition among stimuli for $\\\\backslash$nrepresentation is ultimately resolved within visual cortex, the $\\\\backslash$nsource of top-down biasing signals derives from a network of $\\\\backslash$nareas in frontal and parietal cortex.},\\nauthor = {Kastner, Sabine and Ungerleider, Leslie G.},\\noptdoi = {10.1146/annurev.neuro.23.1.315},\\noptissn = {0147-006X},\\njournal = {Annu. Rev. Neurosci.},\\nnumber = {1},\\npages = {315--341},\\npmid = {10845067},\\npublisher = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA},\\ntitle = {{Mechanisms of visual attention in the human cortex}},\\nvolume = {23},\\nyear = {2000}\\n}',\n",
       " 'Moore2016': '@article{Moore2016,\\nabstract = {We introduce a framework for modeling parameter symmetries in variational inference by explicitly mixing a base approximating density over a symmetry group. We show that this can be done tractably for the case of a Gaussian mixture over the orthogonal group under an isotropic variance assumption. Initial results show that inference with a symmetrized posterior avoids component collapse and leads to improved predictive performance.},\\nauthor = {Moore, David A},\\nfile = {:Users/adam/Documents/Mendeley/Moore - 2016 - Symmetrized Variational Inference.pdf:pdf},\\nnumber = {Nips},\\ntitle = {{Symmetrized Variational Inference}},\\nopturl = {http://approximateinference.org/accepted/Moore2016.pdf},\\nyear = {2016}\\n}',\n",
       " 'Spratling2016': '@article{Spratling2016,\\nabstract = {ABSTRACTPredictive coding (PC) is a leading theory of cortical function that has previously been shown to explain a great deal of neurophysiological and psychophysical data. Here it is shown that PC can perform almost exact Bayesian inference when applied to computing with population codes. It is demonstrated that the proposed algorithm, based on PC, can: decode probability distributions encoded as noisy population codes; combine priors with likelihoods to calculate posteriors; perform cue integration and cue segregation; perform function approximation; be extended to perform hierarchical inference; simultaneously represent and reason about multiple stimuli; and perform inference with multi-modal and non-Gaussian probability distributions. PC thus provides a neural network-based method for performing probabilistic computation and provides a simple, yet comprehensive, theory of how the cerebral cortex performs Bayesian inference.},\\nauthor = {Spratling, M. W.},\\noptdoi = {10.1080/09540091.2016.1243655},\\noptissn = {0954-0091},\\njournal = {Conn. Sci.},\\nkeywords = {Bayes,function approximation,inference,multisensory integration,neural networks,population coding,predictive coding,priors},\\nnumber = {0},\\npages = {1--38},\\ntitle = {{A neural implementation of Bayesian inference based on predictive coding}},\\nopturl = {https://www.tandfonline.com/optdoi/full/10.1080/09540091.2016.1243655},\\nvolume = {0},\\nyear = {2016}\\n}',\n",
       " 'Wang2008': '@article{Wang2008,\\nabstract = {We introduce Gaussian process dynamical models (GPDM) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensionalmotion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, using Gaussian process priors for both the dynamics and the observation mappings. This results in a non-parametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach, and compare four learning algorithms on human motion capture data in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces.},\\nauthor = {Wang, Jack M. and Fleet, David J. and Hertzmann, Aaron},\\noptdoi = {10.1109/TPAMI.2007.1167},\\noptisbn = {978-1-4577-1102-2},\\noptissn = {01628828},\\njournal = {IEEE Trans. Pattern Anal. Mach. Intell.},\\nkeywords = {Animation,Machine learning,Motion,Stochastic processes,Time series analysis,Tracking},\\nmonth = {feb},\\nnumber = {2},\\npages = {283--298},\\npmid = {18084059},\\ntitle = {{Gaussian process dynamical models for human motion}},\\nopturl = {http://ieeexplore.ieee.org/document/4359316/},\\nvolume = {30},\\nyear = {2008}\\n}',\n",
       " 'Pathak2016': \"@article{Pathak2016,\\nabstract = {This paper presents a novel yet intuitive approach to unsupervised feature learning. Inspired by the human visual system, we explore whether low-level motion-based grouping cues can be used to learn an effective visual representation. Specifically, we use unsupervised motion-based segmentation on videos to obtain segments, which we use as 'pseudo ground truth' to train a convolutional network to segment objects from a single frame. Given the extensive evidence that motion plays a key role in the development of the human visual system, we hope that this straightforward approach to unsupervised learning will be more effective than cleverly designed 'pretext' tasks studied in the literature. Indeed, our extensive experiments show that this is the case. When used for transfer learning on object detection, our representation significantly outperforms previous unsupervised approaches across multiple settings, especially when training data for the target task is scarce.},\\narchivePrefix = {arXiv},\\narxivId = {1612.06370},\\nauthor = {Pathak, Deepak and Girshick, Ross and Doll{\\\\'{a}}r, Piotr and Darrell, Trevor and Hariharan, Bharath},\\noptdoi = {10.1109/CVPR.2017.638},\\neprint = {1612.06370},\\njournal = {arXiv:1612.06370 [cs.CV]},\\nmonth = {dec},\\ntitle = {{Learning Features by Watching Objects Move}},\\nopturl = {http://arxiv.org/abs/1612.06370},\\nyear = {2016}\\n}\",\n",
       " 'Nagabandi2017': '@article{Nagabandi2017,\\nabstract = {Model-free deep reinforcement learning methods have successfully learned com-plex behavioral strategies for a wide range of tasks, but typically require many samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that medium-sized neural network models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits to accomplish various complex locomotion tasks. We also propose using deep neural network dynamics models to initialize a model-free learner, in order to com-bine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We perform this pre-initialization by using rollouts from the trained model-based controller as supervision to pre-train a policy, and then fine-tune the policy using a model-free method. We empirically demon-strate that this resulting hybrid algorithm can drastically accelerate model-free learning and outperform purely model-free learners on several MuJoCo locomo-tion benchmark tasks, achieving sample efficiency gains over a purely model-free learner of 330Ã— on swimmer, 26Ã— on hopper, 4Ã— on half-cheetah, and 3Ã— on ant. Videos can be found at https://sites.google.com/view/mbmf.},\\narchivePrefix = {arXiv},\\narxivId = {1708.02596},\\nauthor = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},\\neprint = {1708.02596},\\nmonth = {aug},\\ntitle = {{Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning}},\\nopturl = {http://arxiv.org/abs/1708.02596 https://arxiv.org/pdf/1708.02596.pdf},\\nyear = {2017}\\n}',\n",
       " 'Engelcke2016': '@article{Engelcke2016,\\nabstract = {This paper proposes a computationally efficient approach to detecting objects natively in 3D point clouds using convolutional neural networks (CNNs). In particular, this is achieved by leveraging a feature-centric voting scheme to implement novel convolutional layers which explicitly exploit the sparsity encountered in the input. To this end, we examine the trade-off between accuracy and speed for different architectures and additionally propose to use an L1 penalty on the filter activations to further encourage sparsity in the intermediate representations. To the best of our knowledge, this is the first work to propose sparse convolutional layers and L1 regularisation for efficient large-scale processing of 3D data. We demonstrate the efficacy of our approach on the KITTI object detection benchmark and show that Vote3Deep models with as few as three layers outperform the previous state of the art in both laser and laser-vision based approaches by margins of up to 40{\\\\%} while remaining highly competitive in terms of processing time.},\\narchivePrefix = {arXiv},\\narxivId = {1609.06666},\\nauthor = {Engelcke, Martin and Rao, Dushyant and Wang, Dominic Zeng and Tong, Chi Hay and Posner, Ingmar},\\neprint = {1609.06666},\\noptisbn = {9781509046324},\\nmonth = {sep},\\ntitle = {{Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks}},\\nopturl = {http://arxiv.org/abs/1609.06666},\\nyear = {2016}\\n}',\n",
       " 'Russakovsky2015': '@article{Russakovsky2015,\\nabstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},\\narchivePrefix = {arXiv},\\narxivId = {1409.0575},\\nauthor = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},\\noptdoi = {10.1007/s11263-015-0816-y},\\neprint = {1409.0575},\\noptisbn = {0920-5691},\\noptissn = {15731405},\\njournal = {Int. J. Comput. Vis.},\\nkeywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},\\nmonth = {sep},\\nnumber = {3},\\npages = {211--252},\\npmid = {16190471},\\ntitle = {{ImageNet Large Scale Visual Recognition Challenge}},\\nopturl = {http://arxiv.org/abs/1409.0575},\\nvolume = {115},\\nyear = {2015}\\n}',\n",
       " 'Pereyra2017': \"@article{Pereyra2017,\\nabstract = {We systematically explore regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. Furthermore, we connect a maximum entropy based confidence penalty to label smoothing through the direction of the KL divergence. We exhaustively evaluate the proposed confidence penalty and label smoothing on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and the confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyperparameters, suggesting the wide applicability of these regularizers.},\\narchivePrefix = {arXiv},\\narxivId = {1701.06548},\\nauthor = {Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\\\\L}ukasz and Hinton, Geoffrey},\\neprint = {1701.06548},\\njournal = {Arxiv},\\npages = {1--12},\\ntitle = {{Regularizing Neural Networks by Penalizing Confident Output Distributions}},\\nopturl = {http://arxiv.org/abs/1701.06548},\\nyear = {2017}\\n}\",\n",
       " 'Ba2016': '@article{Ba2016,\\nabstract = {Until recently, research on artificial neural networks was largely restricted to systems with only two types of variable: Neural activities that represent the current or recent input and weights that learn to capture regularities among inputs, outputs and payoffs. There is no good reason for this restriction. Synapses have dynamics at many different time-scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights. These \"fast weights\" can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proved very helpful in sequence-to-sequence models. By using fast weights we can avoid the need to store copies of neural activity patterns.},\\narchivePrefix = {arXiv},\\narxivId = {1610.06258},\\nauthor = {Ba, Jimmy and Hinton, Geoffrey and Mnih, Volodymyr and Leibo, Joel Z. and Ionescu, Catalin},\\neprint = {1610.06258},\\njournal = {Adv. Neural Inf. Process. Syst.},\\nmonth = {oct},\\npages = {1--10},\\ntitle = {{Using Fast Weights to Attend to the Recent Past}},\\nopturl = {http://arxiv.org/abs/1610.06258},\\nyear = {2016}\\n}',\n",
       " 'Friston2010a': '@article{Friston2010a,\\nabstract = {We suggested recently that attention can be understood as inferring the level of uncertainty or precision during hierarchical perception. In this paper, we try to substantiate this claim using neuronal simulations of directed spatial attention and biased competition. These simulations assume that neuronal activity encodes a probabilistic representation of the world that optimizes free-energy in a Bayesian fashion. Because free-energy bounds surprise or the (negative) log-evidence for internal models of the world, this optimization can be regarded as evidence accumulation or (generalized) predictive coding. Crucially, both predictions about the state of the world generating sensory data and the precision of those data have to be optimized. Here, we show that if the precision depends on the states, one can explain many aspects of attention. We illustrate this in the context of the Posner paradigm, using the simulations to generate both psychophysical and electrophysiological responses. These simulated responses are consistent with attentional bias or gating, competition for attentional resources, attentional capture and associated speed-accuracy trade-offs. Furthermore, if we present both attended and non-attended stimuli simultaneously, biased competition for neuronal representation emerges as a principled and straightforward property of Bayes-optimal perception.},\\nauthor = {Feldman, Harriet and Friston, Karl J.},\\noptdoi = {10.3389/fnhum.2010.00215},\\noptisbn = {1662-5161},\\noptissn = {1662-5161},\\njournal = {Front. Hum. Neurosci.},\\npmid = {21160551},\\ntitle = {{Attention, Uncertainty, and Free-Energy}},\\nopturl = {http://www.fil.ion.ucl.ac.uk/{~}karl/Attention uncertainty and free-energy.pdf http://journal.frontiersin.org/article/10.3389/fnhum.2010.00215/abstract},\\nvolume = {4},\\nyear = {2010}\\n}',\n",
       " 'Zhao2016a': '@article{Zhao2016a,\\nabstract = {We introduce the \"Energy-based Generative Adversarial Network\" (EBGAN) model which views the discriminator in GAN framework as an energy function that associates low energies with the regions near the data manifold and higher energies everywhere else. Similar to the probabilistic GANs, a generator is trained to produce contrastive samples with minimal energies, while the energy function is trained to assign high energies to those generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary discriminant network. Among them, an instantiation of EBGANs is to use an auto-encoder architecture alongside the energy being the reconstruction error. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.},\\narchivePrefix = {arXiv},\\narxivId = {1609.03126},\\nauthor = {Zhao, Junbo and Mathieu, Michael and LeCun, Yann},\\noptdoi = {10.1016/j.neunet.2014.10.001},\\neprint = {1609.03126},\\noptisbn = {9781509008063},\\noptissn = {18792782},\\njournal = {Nips},\\nmonth = {sep},\\nnumber = {2006},\\npages = {1--15},\\npmid = {25462632},\\ntitle = {{Energy-based Generative Adversarial Network}},\\nopturl = {http://arxiv.org/abs/1609.03126},\\nyear = {2016}\\n}',\n",
       " 'Chi2011': \"@article{Chi2011,\\nabstract = {Pedagogical strategies are policies for a tutor to decide the next$\\\\backslash$naction when there are multiple actions available. When the content$\\\\backslash$nis controlled to be the same across experimental conditions, there$\\\\backslash$nhas been little evidence that tutorial decisions have an impact on$\\\\backslash$nstudents' learning. In this paper, we applied Reinforcement Learning$\\\\backslash$n(RL) to induce two sets of pedagogical policies from pre-existing$\\\\backslash$nhuman interaction data. The NormGain set was derived with the goal$\\\\backslash$nof enhancing tutorial decisions that contribute to learning while$\\\\backslash$nthe InvNormGain set was derived with the goal of enhancing those$\\\\backslash$ndecisions that contribute less or even nothing to learning. The two$\\\\backslash$nsets were then tested with human students. Our results show that$\\\\backslash$nwhen the content was controlled to be the same, different pedagogical$\\\\backslash$npolicies did make a difference in learning and more specifically,$\\\\backslash$nthe NormGain students outperformed their peers. Overall our results$\\\\backslash$nsuggest that content exposure and practice opportunities can help$\\\\backslash$nstudents to learn even when tutors have poor pedagogical tutorial$\\\\backslash$ntactics. However, with effective tutorial tactics, students can learn$\\\\backslash$neven more. (Contains 9 tables, 6 figures, and 2 footnotes.)},\\narchivePrefix = {arXiv},\\narxivId = {1206.2944},\\nauthor = {Chi, Min and Vanlehn, Kurt and Litman, Diane and Jordan, Pamela},\\noptdoi = {10.3233/JAI-2011-014},\\neprint = {1206.2944},\\noptisbn = {9781618395993},\\noptissn = {15604292},\\njournal = {Int. J. Artif. Intell. Educ.},\\nkeywords = {Reinforcement learning,human learning,intelligent tutoring systems,pedagogical strategy},\\nmonth = {jun},\\nnumber = {1-2},\\npages = {83--113},\\ntitle = {{An evaluation of pedagogical tutorial tactics for a natural language tutoring system: A reinforcement learning approach}},\\nopturl = {http://arxiv.org/abs/1206.2944},\\nvolume = {21},\\nyear = {2011}\\n}\",\n",
       " 'Brabandere2016dfn': '@article{Brabandere2016dfn,\\nabstract = {In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.},\\narchivePrefix = {arXiv},\\narxivId = {1605.09673},\\nauthor = {{De Brabandere}, Bert and Jia, Xu and Tuytelaars, Tinne and {Van Gool}, Luc},\\neprint = {1605.09673},\\njournal = {NIPS},\\ntitle = {{Dynamic Filter Networks}},\\nopturl = {http://arxiv.org/abs/1605.09673},\\nyear = {2016}\\n}',\n",
       " 'Vot2016': '@inproceedings{Vot2016,\\nabstract = {The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 pre-decessor are: (i) a new VOT2015 dataset twice as large as in VOT2014 with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2014 evaluation methodology by introduction of a new performance measure. The dataset, the evaluation kit as well as the results are publicly available at the challenge website 1 .},\\nauthor = {Kristan, Matej and Matas, Jiri and Leonardis, Ale{\\\\v{s}} and Felsberg, Michael and Cehovin, Luk and Fern{\\\\\\'{a}}ndez, Gustavo and Voj{\\\\\\'{i}}, Tom{\\\\\\'{a}}{\\\\v{s}} and H{\\\\\"{a}}ger, Gustav and Nebehay, Georg and Pflugfelder, Roman and Gupta, Abhinav and Bibi, Adel and Luke{\\\\v{z}}i{\\\\v{c}}, Alan and Garcia-Martin, Alvaro and Saffari, Amir and Torr, Philip H S and Wang, Qiang and Martin-Nieto, Rafael and Pelapur, Rengarajan and Bowden, Richard and Zhu, Chun and Becker, Stefan and Duffner, Stefan and Hicks, Stephen L and Golodetz, Stuart and Choi, Sunglok and Wu, Tianfu and Mauthner, Thomas and Pridmore, Tony and Hu, Weiming and H{\\\\\"{u}}bner, Wolfgang and Wang, Xiaomeng and Li, Xin and Shi, Xinchu and Zhao, Xu and Mei, Xue and Shizeng, Yao and Hua, Yang and Li, Yang and Lu, Yang and Li, Yuezun and Chen, Zhaoyun and Huang, Zehua and Chen, Zhe and Zhang, Zhe and He, Zhenyu and Hong, Zhibin},\\nbooktitle = {ECCV Work.},\\ntitle = {{The Visual Object Tracking Vot2016 challenge results}},\\nopturl = {http://personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/2016/Lebeda{\\\\_}Vot2016.pdf},\\nyear = {2016}\\n}',\n",
       " 'Siegelmann1995': '@article{Siegelmann1995,\\nabstract = {THis paper deals with finite size networks which consist of interconnections of synchronously evolving processors. Each processor updates its state by applying a \"sigmoidal\" function to a linear combination of the previous states of all units. We prove that one may simulate all Turing machines by such nets. In particular, one can simulate multi-stack Turing machines in real time, and there is a net made up of 886 processors which computes universal partial-recursive function. Products (high order nets) are not required, contrary to what has been stated in literature. Non-deterministic Turing machines can be simulated by non-deterministic rational nets, also in real time. The simulation result has many consequences regarding the decidability, or more generally the complexity, of questions about recursive ents.},\\nauthor = {Siegelmann, Hava T. and Sontag, Eduardo D.},\\noptdoi = {10.1006/jcss.1995.1013},\\noptisbn = {089791497X},\\noptissn = {00220000},\\njournal = {J. Comput. Syst. Sci.},\\nmonth = {feb},\\nnumber = {1},\\npages = {132--150},\\npmid = {23773339},\\ntitle = {{On the Computational Power of Neural Nets}},\\nopturl = {http://ac.els-cdn.com/S0022000085710136/1-s2.0-S0022000085710136-main.pdf?{\\\\_}tid=9cbb7f1a-03ea-11e7-b330-00000aab0f6c{\\\\&}acdnat=1488969364{\\\\_}8337956f98013aea42f4be8a65ca1b1b},\\nvolume = {50},\\nyear = {1995}\\n}',\n",
       " 'Denil2013': \"@article{Denil2013,\\nabstract = {We demonstrate that there is signiï¬cant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95{\\\\%} of the weights of a network without any drop in accuracy.},\\narchivePrefix = {arXiv},\\narxivId = {1306.0543},\\nauthor = {Denil, Misha and Shakibi, Babak and Dinh, Laurent and Ranzato, Marc'Aurelio and de Freitas, Nando},\\neprint = {1306.0543},\\noptissn = {10495258},\\njournal = {NIPS},\\nmonth = {jun},\\npages = {2148--2156},\\ntitle = {{Predicting Parameters in Deep Learning}},\\nopturl = {http://arxiv.org/abs/1306.0543 http://papers.nips.cc/paper/5025-predicting-parameters-in-deep-learning},\\nyear = {2013}\\n}\",\n",
       " 'Vinyals2014': '@inproceedings{Vinyals2014,\\nabstract = {Syntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation.},\\narchivePrefix = {arXiv},\\narxivId = {1412.7449},\\nauthor = {Vinyals, Oriol and Kaiser, Lukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},\\nbooktitle = {NIPS},\\noptdoi = {10.1146/annurev.neuro.26.041002.131047},\\neprint = {1412.7449},\\noptisbn = {9789078328414},\\noptissn = {10495258},\\npmid = {14527267},\\ntitle = {{Grammar as a Foreign Language}},\\nopturl = {http://arxiv.org/abs/1409.0473 http://arxiv.org/abs/1412.7449},\\nyear = {2015}\\n}',\n",
       " 'Hassabis2017': \"@article{Hassabis2017,\\nabstract = {The fields of neuroscience and artificial intelligence (AI) have a long and intertwined history. In more recent times, however, communication and collaboration between the two fields has become less commonplace. In this article, we argue that better understanding biological brains could play a vital role in building intelligent machines. We survey historical interactions between the AI and neuroscience fields and emphasize current advances in AI that have been inspired by the study of neural computation in humans and other animals. We conclude by highlighting shared themes that may be key for advancing future research in both fields. In recent years, rapid progress has been made in the related fields of neuroscience and artificial intelligence (AI). At the dawn of the computer age, work on AI was inextricably inter-twined with neuroscience and psychology, and many of the early pioneers straddled both fields, with collaborations between these disciplines proving highly productive (Churchland and Sejnowski, 1988; Hebb, 1949; Hinton et al., 1986; Hopfield, 1982; McCulloch and Pitts, 1943; Turing, 1950). However, more recently, the interaction has become much less common-place, as both subjects have grown enormously in complexity and disciplinary boundaries have solidified. In this review, we argue for the critical and ongoing importance of neuroscience in generating ideas that will accelerate and guide AI research (see Hassabis commentary in Brooks et al., 2012). We begin with the premise that building human-level general AI (or ''Turing-powerful'' intelligent systems; Turing, 1936) is a daunting task, because the search space of possible solutions is vast and likely only very sparsely populated. We argue that this therefore underscores the utility of scrutinizing the inner workings of the human brainâ€” the only existing proof that such an intelligence is even possible. Studying animal cognition and its neural implementation also has a vital role to play, as it can provide a window into various important aspects of higher-level general intelligence. The benefits to developing AI of closely examining biological intelligence are two-fold. First, neuroscience provides a rich source of inspiration for new types of algorithms and architec-tures, independent of and complementary to the mathematical and logic-based methods and ideas that have largely dominated traditional approaches to AI. For example, were a new facet of biological computation found to be critical to supporting a cogni-tive function, then we would consider it an excellent candidate for incorporation into artificial systems. Second, neuroscience can provide validation of AI techniques that already exist. If a known algorithm is subsequently found to be implemented in the brain, then that is strong support for its plausibility as an in-tegral component of an overall general intelligence system. Such clues can be critical to a long-term research program when determining where to allocate resources most},\\nauthor = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},\\noptdoi = {10.1016/j.neuron.2017.06.011},\\noptissn = {0896-6273},\\njournal = {Neuron},\\nkeywords = {artificial intelligence,brain,cognition,learning,neural network},\\nnumber = {2},\\npages = {245--258},\\npmid = {28728020},\\ntitle = {{Review Neuroscience-Inspired Artificial Intelligence}},\\nopturl = {http://dx.optdoi.org/10.1016/j.neuron.2017.06.011},\\nvolume = {95},\\nyear = {2017}\\n}\",\n",
       " 'Klambauer2017': '@article{Klambauer2017,\\nabstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are \"scaled exponential linear units\" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},\\narchivePrefix = {arXiv},\\narxivId = {1706.02515},\\nauthor = {Klambauer, G{\\\\\"{u}}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},\\noptdoi = {1706.02515},\\neprint = {1706.02515},\\nmonth = {jun},\\ntitle = {{Self-Normalizing Neural Networks}},\\nopturl = {http://arxiv.org/abs/1706.02515},\\nyear = {2017}\\n}',\n",
       " 'ShwartzZiv2017': '@article{ShwartzZiv2017,\\nabstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work proposed to analyze DNNs in the $\\\\backslash$textit{\\\\{}Information Plane{\\\\}}; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on {\\\\{}$\\\\backslash$emph compression{\\\\}} of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer.},\\narchivePrefix = {arXiv},\\narxivId = {1703.00810},\\nauthor = {Shwartz-Ziv, Ravid and Tishby, Naftali},\\neprint = {1703.00810},\\nmonth = {mar},\\ntitle = {{Opening the Black Box of Deep Neural Networks via Information}},\\nopturl = {http://arxiv.org/abs/1703.00810},\\nyear = {2017}\\n}',\n",
       " 'Minka2001': '@article{Minka2001,\\nabstract = {This paper presents a new deterministic approximation technique in Bayesian networks. This method, Expectation Propagation, unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propaga- tion in Bayesian networks. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expec- tation Propagation approximates the belief states by only retaining expectations, such as mean and variance, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models showExpectation Propagation to be convincingly better than methods with similar computational cost: Laplaces method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers},\\narchivePrefix = {arXiv},\\narxivId = {1301.2294},\\nauthor = {Minka, Thomas P},\\neprint = {1301.2294},\\noptisbn = {1-55860-800-1},\\njournal = {Uncertain. Artif. Intell.},\\nnumber = {2},\\npages = {362--369},\\ntitle = {{Expectation Propagation for Approximate Bayesian Inference}},\\nopturl = {http://citeseerx.ist.psu.edu/viewdoc/download?optdoi=10.1.1.86.1319{\\\\&}rep=rep1{\\\\&}type=pdf},\\nvolume = {17},\\nyear = {2001}\\n}',\n",
       " 'Hafner2017': '@article{Hafner2017,\\nabstract = {We propose a deep learning model inspired by neocortical communication via the thalamus. Our model consists of recurrent neural modules that send features via a routing center, endowing the modules with the flexibility to share features over multiple time steps. We show that our model learns to route information hierarchically, processing input data by a chain of modules. We observe common architectures, such as feed forward neural networks and skip connections, emerging as special cases of our architecture, while novel connectivity patterns are learned for the text8 compression task. We demonstrate that our model outperforms standard recurrent neural networks on three sequential benchmarks.},\\narchivePrefix = {arXiv},\\narxivId = {1706.05744},\\nauthor = {Hafner, Danijar and Irpan, Alex and Davidson, James and Heess, Nicolas},\\neprint = {1706.05744},\\nmonth = {jun},\\ntitle = {{Learning Hierarchical Information Flow with Recurrent Neural Modules}},\\nopturl = {http://arxiv.org/abs/1706.05744},\\nyear = {2017}\\n}',\n",
       " 'Andrychowicz2016': '@article{Andrychowicz2016,\\nabstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},\\narchivePrefix = {arXiv},\\narxivId = {1606.04474},\\nauthor = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and de Freitas, Nando},\\noptdoi = {10.1007/s10115-008-0151-5},\\neprint = {1606.04474},\\noptisbn = {1011500801515},\\noptissn = {0219-1377},\\njournal = {Nips},\\nmonth = {jun},\\npages = {1--16},\\npmid = {207591},\\ntitle = {{Learning to learn by gradient descent by gradient descent}},\\nopturl = {http://arxiv.org/abs/1606.04474},\\nyear = {2016}\\n}',\n",
       " 'Rolfe2016': '@article{Rolfe2016,\\nabstract = {Probabilistic models with discrete latent variables naturally capture datasets composed of discrete classes. However, they are difficult to train efficiently, since backpropagation through discrete variables is generally not possible. We present a novel method to train a class of probabilistic models with discrete latent variables using the variational autoencoder framework, including backpropagation through the discrete latent variables. The associated class of probabilistic models comprises an undirected discrete component and a directed hierarchical continuous component. The discrete component captures the distribution over the disconnected smooth manifolds induced by the continuous component. As a result, this class of models efficiently learns both the class of objects in an image, and their specific realization in pixels, from unsupervised data, and outperforms state-of-the-art methods on the permutation-invariant MNIST, Omniglot, and Caltech-101 Silhouettes datasets.},\\narchivePrefix = {arXiv},\\narxivId = {1609.02200},\\nauthor = {Rolfe, Jason Tyler},\\neprint = {1609.02200},\\noptisbn = {1511.02386},\\nmonth = {sep},\\ntitle = {{Discrete Variational Autoencoders}},\\nopturl = {http://arxiv.org/abs/1609.02200},\\nyear = {2016}\\n}',\n",
       " 'Bayer2015': '@inproceedings{Bayer2015,\\nabstract = {Leveraging advances in variational inference, we propose to enhance recurrent neural networks with latent variables, resulting in Stochastic Recurrent Networks (STORNs). The model i) can be trained with stochastic gradient methods, ii) allows structured and multi-modal conditionals at each time step, iii) features a reliable estimator of the marginal likelihood and iv) is a generalisation of deterministic recurrent neural networks. We evaluate the method on four polyphonic musical data sets and motion capture data.},\\narchivePrefix = {arXiv},\\narxivId = {1411.7610},\\nauthor = {Bayer, Justin and Osendorfer, Christian},\\nbooktitle = {ICLR},\\neprint = {1411.7610},\\nmonth = {nov},\\ntitle = {{Learning Stochastic Recurrent Networks}},\\nopturl = {http://arxiv.org/abs/1411.7610},\\nyear = {2015}\\n}',\n",
       " 'Vinyals2015': '@article{Vinyals2015,\\nabstract = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent ap- proaches such as sequence-to-sequence [1] and Neural Turing Machines [2], be- cause the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems â€“ finding planar convex hulls, computing Delaunay triangu- lations, and the planar Travelling Salesman Problem â€“ using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems. 1},\\narchivePrefix = {arXiv},\\narxivId = {1506.03134},\\nauthor = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},\\noptdoi = {10.1016/j.neunet.2014.09.003},\\neprint = {1506.03134},\\noptisbn = {0893-6080},\\noptissn = {10495258},\\njournal = {Neural Inf. Process. Syst. 2015},\\nmonth = {jun},\\npages = {1--9},\\npmid = {25462637},\\ntitle = {{Pointer Networks}},\\nopturl = {http://arxiv.org/abs/1506.03134},\\nyear = {2015}\\n}',\n",
       " 'Goroshin2015': \"@article{Goroshin2015,\\nabstract = {Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. We also address the problem of inherent uncertainty in prediction by introducing latent variables that are non-deterministic functions of the input into the network architecture.},\\nannote = {- phase-pooling operator uses a differentiable version of max and argmax, which is expectation of the variable and expectation of location map under soft-max distribution\\n- max gives the magnitude m, argmax gives the phase p\\n- encoder performs phase-pooling to give m and p\\n- prediction layer extrapolates from frames t-1 and t to t by assuming locally stable m and locally-linear p\\n- decoder inverts the transoformation by using m and p and does some convolutions\\n- local curvature measure is given by cosine distance in the feature space between (t-1, t) and (t, t+1)\\n- latent variables delta of dim(delta) {\\\\textless}{\\\\textless} dim(z) are used to augment the latent space; there are separate deltas for every input (non-parametric) and they are fitted during the forward pass via SGD\\n- deltas are meant to explain uncertainty when the sequence is non-deterministic; using them results in sharper predictions (cool); \\n- deltas change the global distribution by introducing local variations, something like variational logistic regression from Bishop\\n\\n- the linear prediction layer is similar to my idea of dynamic model in the PCVAE. \\n- Using prediction of the dynamic model as a prior for the actual state acts as a slowness penalty and encourages smoothness of the latent representation.\\n\\n\\n- they analyze learnt encoder filters from a shallow one-layer encoder to validate what they're optdoing; I should put more emphasis on property investigation in my work!},\\narchivePrefix = {arXiv},\\narxivId = {1506.03011},\\nauthor = {Goroshin, Ross and Mathieu, Michael and LeCun, Yann},\\neprint = {1506.03011},\\noptissn = {10495258},\\ntitle = {{Learning to Linearize Under Uncertainty}},\\nopturl = {http://arxiv.org/abs/1506.03011},\\nyear = {2015}\\n}\",\n",
       " 'Milner2012': '@article{Milner2012,\\nabstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and proteinâˆ’protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\\\\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD â‰¤ 2.0 {\\\\AA} for the interface backbone atoms) increased from 21{\\\\%} with default Glide SP settings to 58{\\\\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\\\\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\\\\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},\\narchivePrefix = {arXiv},\\narxivId = {arXiv:1011.1669v3},\\nauthor = {Milner, David and Goodale, Mel},\\noptdoi = {10.1093/acprof:oso/9780198524724.001.0001},\\neprint = {arXiv:1011.1669v3},\\nfile = {:Users/adam/Documents/Mendeley/Milner, Goodale - 2012 - The Visual Brain in Action.pdf:pdf},\\noptisbn = {9780191689239},\\noptissn = {1098-6596},\\njournal = {Vis. Brain Action},\\nkeywords = {Action,Cognitive science,Conscious perception,Euroimaging,Mri,Neuroscience,Perception,Psychology,Unconscious vision,Visual processing},\\npages = {1--320},\\npmid = {25246403},\\ntitle = {{The Visual Brain in Action}},\\nyear = {2012}\\n}',\n",
       " 'Dai2017': '@article{Dai2017,\\nabstract = {Convolutional neural networks (CNNs) are inherently limited to model geometric transformations due to the fixed geometric structures in its building modules. In this work, we introduce two new modules to enhance the transformation modeling capacity of CNNs, namely, deformable convolution and deformable RoI pooling. Both are based on the idea of augmenting the spatial sampling locations in the modules with additional offsets and learning the offsets from target tasks, without additional supervision. The new modules can readily replace their plain counterparts in existing CNNs and can be easily trained end-to-end by standard back-propagation, giving rise to deformable convolutional networks. Extensive experiments validate the effectiveness of our approach on sophisticated vision tasks of object detection and semantic segmentation. The code would be released.},\\narchivePrefix = {arXiv},\\narxivId = {1703.06211},\\nauthor = {Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen and Radford, Alec and Metz, Luke and Chintala, Soumith and Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},\\noptdoi = {10.1051/0004-6361/201527329},\\neprint = {1703.06211},\\noptisbn = {2004012439},\\noptissn = {0004-6361},\\njournal = {Iccv-C},\\npages = {1--15},\\npmid = {23459267},\\ntitle = {{Deformable Convolutional Networks}},\\nopturl = {http://arxiv.org/abs/1703.06211{\\\\%}5Cnhttp://arxiv.org/abs/1511.06434},\\nyear = {2017}\\n}',\n",
       " 'Valmadre2017': '@inproceedings{Valmadre2017,\\nabstract = {The Correlation Filter is an algorithm that trains a linear template to discriminate between images and their translations. It is well suited to object tracking because its formulation in the Fourier domain provides a fast solution, enabling the detector to be re-trained once per frame. Previous works that use the Correlation Filter, however, have adopted features that were either manually designed or trained for a different task. This work is the first to overcome this limitation by interpreting the Correlation Filter learner, which has a closed-form solution, as a differentiable layer in a deep neural network. This enables learning deep features that are tightly coupled to the Correlation Filter. Experiments illustrate that our method has the important practical benefit of allowing lightweight architectures to achieve state-of-the-art performance at high framerates.},\\narchivePrefix = {arXiv},\\narxivId = {1704.06036},\\nauthor = {Valmadre, Jack and Bertinetto, Luca and Henriques, Jo{\\\\~{a}}o F. and Vedaldi, Andrea and Torr, Philip H. S.},\\nbooktitle = {CVPR},\\neprint = {1704.06036},\\ntitle = {{End-to-end representation learning for Correlation Filter based tracking}},\\nopturl = {http://arxiv.org/abs/1704.06036},\\nyear = {2017}\\n}',\n",
       " 'Kahou2015ratm': \"@article{Kahou2015ratm,\\nabstract = {This work presents an attention mechanism-based neural network approach for tracking objects in video. A recurrent neural network is trained to predict the position of an object at time t + 1 given a series of selective glimpses into video frames at time steps 1 to t. The proposed recurrent attentive tracking model can be trained using simple gradient-based training. Various settings are explored in experiments on artificial data to justify design choices.},\\narchivePrefix = {arXiv},\\narxivId = {1510.08660},\\nauthor = {Kaho{\\\\'{u}}, Samira Ebrahimi and Michalski, Vincent and Memisevic, Roland},\\neprint = {1510.08660},\\njournal = {CVPR Work.},\\nkeywords = {Attention Model},\\ntitle = {{RATM: Recurrent Attentive Tracking Model}},\\nopturl = {http://arxiv.org/pdf/1510.08660v3.pdf},\\nyear = {2017}\\n}\",\n",
       " 'LealTaixe2015': \"@article{LealTaixe2015,\\nabstract = {In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization of quantitative benchmarks for multiple target tracking. One of the few exceptions is the well-known PETS dataset, targeted primarily at surveillance applications. Despite being widely used, it is often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. This paper describes our work toward a novel multiple object tracking benchmark aimed to address such issues. We discuss the challenges of creating such a framework, collecting existing and new data, gathering state-of-the-art methods to be tested on the datasets, and finally creating a unified evaluation system. With MOTChallenge we aim to pave the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking.},\\narchivePrefix = {arXiv},\\narxivId = {1504.01942},\\nauthor = {Leal-Taix{\\\\'{e}}, Laura and Milan, Anton and Reid, Ian and Roth, Stefan and Schindler, Konrad},\\neprint = {1504.01942},\\nmonth = {apr},\\ntitle = {{MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking}},\\nopturl = {http://arxiv.org/abs/1504.01942},\\nyear = {2015}\\n}\",\n",
       " 'Krahenbuhl2015': '@article{Krahenbuhl2015,\\nabstract = {Convolutional Neural Networks spread through computer vision like a wildfire, impacting almost all visual tasks imaginable. Despite this, few researchers dare to train their models from scratch. Most work builds on one of a handful of ImageNet pre-trained models, and fine-tunes or adapts these for specific tasks. This is in large part due to the difficulty of properly initializing these networks from scratch. A small miscalibration of the initial weights leads to vanishing or exploding gradients, as well as poor convergence properties. In this work we present a fast and simple data-dependent initialization procedure, that sets the weights of a network such that all units in the network train at roughly the same rate, avoiding vanishing or exploding gradients. Our initialization matches the current state-of-the-art unsupervised or self-supervised pre-training methods on standard computer vision tasks, such as image classification and object detection, while being roughly three orders of magnitude faster. When combined with pre-training methods, our initialization significantly outperforms prior work, narrowing the gap between supervised and unsupervised pre-training.},\\narchivePrefix = {arXiv},\\narxivId = {1511.06856},\\nauthor = {Kr{\\\\\"{a}}henb{\\\\\"{u}}hl, Philipp and Doersch, Carl and Donahue, Jeff and Darrell, Trevor},\\neprint = {1511.06856},\\njournal = {Int. Conf. Comput. Vis.},\\nmonth = {nov},\\npages = {1--12},\\ntitle = {{Data-dependent Initializations of Convolutional Neural Networks}},\\nopturl = {http://arxiv.org/abs/1511.06856},\\nyear = {2015}\\n}',\n",
       " 'Ondruska2016': '@inproceedings{Ondruska2016,\\nabstract = {This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data â€“ as commonly encountered in robotics applications â€“ and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise},\\narchivePrefix = {arXiv},\\narxivId = {1602.00991},\\nauthor = {Ondruska, Peter and Posner, Ingmar},\\nbooktitle = {AAAI},\\neprint = {1602.00991},\\noptisbn = {9781577357605},\\nkeywords = {Technical Papers: Robotics},\\nmonth = {feb},\\npages = {3361--3367},\\npmid = {217420},\\ntitle = {{Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks}},\\nopturl = {http://arxiv.org/abs/1602.00991 http://www.robots.ox.ac.uk/{~}mobile/Papers/2016AAAI{\\\\_}ondruska.pdf{\\\\%}5Cnhttps://www.youtube.com/watch?v=cdeWCpfUGWc},\\nyear = {2016}\\n}\\n\\n% !tex root=main.tex',\n",
       " 'Bamler2017perturbative': '@article{Bamler2017perturbative,\\n  title={Perturbative Black Box Variational Inference},\\n  author={Bamler, Robert and Zhang, Cheng and Opper, Manfred and Mandt, Stephan},\\n  journal={arXiv preprint arXiv:1709.07433},\\n  year={2017}\\n}',\n",
       " 'Andrieu2010particle': '@article{Andrieu2010particle,\\n  title={Particle {M}arkov chain {M}onte {C}arlo methods},\\n  author={Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},\\n  journal={{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}},\\n  volume={72},\\n  number={3},\\n  pages={269--342},\\n  year={2010},\\n  publisher={Wiley Online Library}\\n}',\n",
       " 'Chung2015recurrent': '@inproceedings{Chung2015recurrent,\\n  title={A recurrent latent variable model for sequential data},\\n  author={Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron C and Bengio, Yoshua},\\n  booktitle={Advances in neural information processing systems},\\n  pages={2980--2988},\\n  year={2015}\\n}',\n",
       " 'Ondruska2016deep': '@inproceedings{Ondruska2016deep,\\n  author = {Peter OndrÃºÅ¡ka and Ingmar Posner},\\n  title = {Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks},\\n  booktitle = {AAAI Conference on Artificial Intelligence},\\n  year = {2016}\\n}',\n",
       " 'Boulanger2012modeling': \"@inproceedings{Boulanger2012modeling,\\n  author =    {Nicolas Boulanger-Lewandowski and Yoshua Bengio and Pascal Vincent},\\n  title =     {Modeling Temporal Dependencies in High-Dimensional Sequences: Application to Polyphonic Music Generation and Transcription},\\n  booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML-12)},\\n  series =    {ICML '12},\\n  year =      {2012},\\n  editor =    {John Langford and Joelle Pineau},\\n  location =  {Edinburgh, Scotland, GB},\\n  isbn =      {978-1-4503-1285-1},\\n  month =     {July},\\n  publisher = {Omnipress},\\n  address =   {New York, NY, USA},\\n  pages=      {1159--1166}\\n}\",\n",
       " 'Doucet2002marginal': '@article{Doucet2002marginal,\\n  title={Marginal maximum a posteriori estimation using {M}arkov chain {M}onte {C}arlo},\\n  author={Doucet, Arnaud and Godsill, Simon J and Robert, Christian P},\\n  journal={{Statistics and Computing}},\\n  volume={12},\\n  number={1},\\n  pages={77--84},\\n  year={2002},\\n  publisher={Springer}\\n}',\n",
       " 'Rainforth2016bayesian': '@inproceedings{Rainforth2016bayesian,\\n  title={Bayesian optimization for probabilistic programs},\\n  author={Rainforth, Tom and Le, Tuan-Anh and van de Meent, Jan-Willem and Osborne, Michael A and Wood, Frank},\\n  booktitle={NIPS},\\n  pages={280--288},\\n  year={2016}\\n}',\n",
       " 'Muller2004optimal': '@article{Muller2004optimal,\\n  title={Optimal {B}ayesian design by inhomogeneous {M}arkov chain simulation},\\n  author={M{\\\\\"u}ller, Peter and Sans{\\\\\\'o}, Bruno and De Iorio, Maria},\\n  journal={{Journal of the American Statistical Association}},\\n  volume={99},\\n  number={467},\\n  pages={788--798},\\n  year={2004},\\n  publisher={Taylor \\\\& Francis}\\n}',\n",
       " 'Chen2014stochastic': '@inproceedings{Chen2014stochastic,\\n  title={Stochastic Gradient {H}amiltonian {M}onte {C}arlo},\\n  author={Chen, Tianqi and Fox, Emily B and Guestrin, Carlos},\\n  booktitle={ICML},\\n  pages={1683--1691},\\n  year={2014}\\n}',\n",
       " 'Mackay2003information': '@book{Mackay2003information,\\n  title = {Information theory, inference and learning algorithms},\\n  author = {MacKay, David JC},\\n  year = {2003},\\n  publisher = {{Cambridge University Press}}\\n}',\n",
       " 'Box1976science': '@article{Box1976science,\\n  title = {Science and statistics},\\n  author = {Box, George EP},\\n  journal = {Journal of the American Statistical Association},\\n  volume = {71},\\n  number = {356},\\n  pages = {791--799},\\n  year = {1976},\\n  publisher = {Taylor \\\\& Francis}\\n}',\n",
       " 'Rasmussen2001occam': \"@article{Rasmussen2001occam,\\n  title = {Occam's razor},\\n  author = {Rasmussen, Carl Edward and Ghahramani, Zoubin},\\n  journal = {{Advances in Neural Information Processing Systems}},\\n  pages = {294--300},\\n  year = {2001},\\n  publisher = {MIT; 1998}\\n}\",\n",
       " 'Del2004feynman': '@article{Del2004feynman,\\n  title={{Feynman-Kac} formulae: genealogical and interacting particle systems with applications},\\n  author={Del Moral, P},\\n  journal={Probability and its applications},\\n  year={2004},\\n  publisher={New York: Springer}\\n}',\n",
       " 'Griewank2008evaluating': '@book{Griewank2008evaluating,\\n  title={Evaluating derivatives: principles and techniques of algorithmic differentiation},\\n  author={Griewank, Andreas and Walther, Andrea},\\n  year={2008},\\n  publisher={SIAM}\\n}',\n",
       " 'Collobert2002torch': \"@techreport{Collobert2002torch,\\n  title={Torch: a modular machine learning software library},\\n  author={Collobert, Ronan and Bengio, Samy and Mari{\\\\'e}thoz, Johnny},\\n  year={2002},\\n  institution={Idiap}\\n}\",\n",
       " 'Baydin2015automatic': '@article{Baydin2015automatic,\\n  title = {Automatic differentiation in machine learning: a survey},\\n  author = {Baydin, A. G. and Pearlmutter, B. A. and Radul, A. A. and Siskind, J. M.},\\n  journal = {arXiv preprint arXiv:1502.05767},\\n  year = {2015}\\n}',\n",
       " 'Abadi2015tensorflow': \"@misc{Abadi2015tensorflow,\\ntitle={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},\\nnote={Software available from tensorflow.org},\\nauthor={\\n    Mart\\\\'{\\\\i}n~Abadi and\\n    others},\\n  year={2015},\\n}\",\n",
       " 'Rumelhart1988learning': '@article{Rumelhart1988learning,\\n  title={Learning representations by back-propagating errors},\\n  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},\\n  journal={Cognitive modeling},\\n  volume={5},\\n  number={3},\\n  pages={1},\\n  year={1988}\\n}',\n",
       " 'Baydin2016diffsharp': '@inproceedings{Baydin2016diffsharp,\\n  author = {Baydin, AtÄ±lÄ±m GÃ¼neÅŸ and Pearlmutter, Barak A. and Siskind, Jeffrey Mark},\\n  booktitle = {International Conference on Algorithmic Differentiation},\\n  title = {DiffSharp: An AD Library for .NET Languages},\\n  year = {2016}\\n}',\n",
       " 'Doucet2009tutorial': '@article{Doucet2009tutorial,\\n  title={A tutorial on particle filtering and smoothing: Fifteen years later},\\n  author={Doucet, Arnaud and Johansen, Adam M},\\n  journal={Handbook of nonlinear filtering},\\n  volume={12},\\n  number={656-704},\\n  pages={3},\\n  year={2009}\\n}',\n",
       " 'Pearlmutter2008reverse': '@article{Pearlmutter2008reverse,\\n  title={Reverse-mode AD in a functional framework: Lambda the ultimate backpropagator},\\n  author={Pearlmutter, Barak A and Siskind, Jeffrey Mark},\\n  journal={TOPLAS},\\n  volume={30},\\n  number={2},\\n  pages={7},\\n  year={2008},\\n  publisher={ACM}\\n}',\n",
       " 'Ruder2016overview': '@article{Ruder2016overview,\\n  author    = {Sebastian Ruder},\\n  title     = {An overview of gradient descent optimization algorithms},\\n  journal   = {CoRR},\\n  volume    = {abs/1609.04747},\\n  year      = {2016},\\n  timestamp = {Mon, 03 Oct 2016 17:51:10 +0200},\\n  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Ruder16},\\n  bibsource = {dblp computer science bibliography, http://dblp.org}\\n}',\n",
       " 'Gu2015neural': '@inproceedings{Gu2015neural,\\n  title={Neural adaptive sequential {M}onte {C}arlo},\\n  author={Gu, Shixiang and Ghahramani, Zoubin and Turner, Richard E},\\n  booktitle={NIPS},\\n  pages={2629--2637},\\n  year={2015}\\n}',\n",
       " 'Durbin2000time': '@article{Durbin2000time,\\n author = {J. Durbin and S. J. Koopman},\\n journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},\\n number = {1},\\n pages = {3-56},\\n publisher = {[Royal Statistical Society, Wiley]},\\n title = {Time Series Analysis of Non-Gaussian Observations Based on State Space Models from Both Classical and Bayesian Perspectives},\\n volume = {62},\\n year = {2000}\\n}',\n",
       " 'Kingma2014adam': '@article{Kingma2014adam,\\n  title={Adam: A method for stochastic optimization},\\n  author={Kingma, Diederik and Ba, Jimmy},\\n  journal={arXiv preprint arXiv:1412.6980},\\n  year={2014}\\n}',\n",
       " 'Del2006sequential': '@article{Del2006sequential,\\n  title={Sequential monte carlo samplers},\\n  author={Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},\\n  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},\\n  volume={68},\\n  number={3},\\n  pages={411--436},\\n  year={2006},\\n  publisher={Wiley Online Library}\\n}',\n",
       " 'Kantas2009overview': '@article{Kantas2009overview,\\n  title={An overview of sequential {M}onte {C}arlo methods for parameter estimation in general state-space models},\\n  author={Kantas, Nicholas and Doucet, Arnaud and Singh, Sumeetpal Sindhu and Maciejowski, Jan Marian},\\n  journal={IFAC Proceedings Volumes},\\n  volume={42},\\n  number={10},\\n  pages={774--785},\\n  year={2009},\\n  publisher={Elsevier}\\n}',\n",
       " 'Doucet2003parameter': \"@article{Doucet2003parameter,\\n  title={Parameter estimation in general state-space models using particle methods},\\n  author={Doucet, Arnaud and Tadi{\\\\'c}, Vladislav B},\\n  journal={Annals of the institute of Statistical Mathematics},\\n  volume={55},\\n  number={2},\\n  pages={409--422},\\n  year={2003},\\n  publisher={Springer}\\n}\",\n",
       " 'Poyiadjis2011particle': '@article{Poyiadjis2011particle,\\n  title={Particle approximations of the score and observed information matrix in state space models with application to parameter estimation},\\n  author={Poyiadjis, George and Doucet, Arnaud and Singh, Sumeetpal S and others},\\n  journal={Biometrika},\\n  volume={98},\\n  number={1},\\n  pages={65--80},\\n  year={2011}\\n}',\n",
       " 'Candy2016bayesian': '@book{Candy2016bayesian,\\n  title={Bayesian signal processing: classical, modern, and particle filtering methods},\\n  author={Candy, James V},\\n  volume={54},\\n  year={2016},\\n  publisher={John Wiley \\\\& Sons}\\n}',\n",
       " 'Creal2012survey': '@article{Creal2012survey,\\n  title={A survey of sequential {M}onte {C}arlo methods for economics and finance},\\n  author={Creal, Drew},\\n  journal={Econometric reviews},\\n  volume={31},\\n  number={3},\\n  pages={245--296},\\n  year={2012},\\n  publisher={Taylor \\\\& Francis}\\n}',\n",
       " 'Doucet2001introduction': '@incollection{Doucet2001introduction,\\n  title={An introduction to sequential {M}onte {C}arlo methods},\\n  author={Doucet, Arnaud and De Freitas, Nando and Gordon, Neil},\\n  booktitle={Sequential {M}onte {C}arlo methods in practice},\\n  pages={3--14},\\n  year={2001},\\n  publisher={Springer}\\n}',\n",
       " 'Sutton1998reinforcement': '@book{Sutton1998reinforcement,\\n  title={Reinforcement learning: An introduction},\\n  author={Sutton, Richard S and Barto, Andrew G},\\n  volume={1},\\n  year={1998},\\n  publisher={MIT press Cambridge}\\n}',\n",
       " 'Andrieu2009pseudo': '@article{Andrieu2009pseudo,\\n  title={The pseudo-marginal approach for efficient {M}onte {C}arlo computations},\\n  author={Andrieu, Christophe and Roberts, Gareth O},\\n  journal={The Annals of Statistics},\\n  pages={697--725},\\n  year={2009},\\n  publisher={JSTOR}\\n}',\n",
       " 'Poyiadjis2006gradient': '@inproceedings{Poyiadjis2006gradient,\\n  title={Gradient-free maximum likelihood parameter estimation with particle filters},\\n  author={Poyiadjis, George and Singh, Sumeetpal S and Doucet, Arnaud},\\n  booktitle={American Control Conference, 2006},\\n  pages={6--pp},\\n  year={2006},\\n  organization={IEEE}\\n}',\n",
       " 'Coquelin2009particle': \"@inproceedings{Coquelin2009particle,\\n  title={Particle filter-based policy gradient in POMDPs},\\n  author={Coquelin, Pierre-Arnaud and Deguest, Romain and Munos, R{\\\\'e}mi},\\n  booktitle={NIPS},\\n  pages={337--344},\\n  year={2009}\\n}\",\n",
       " 'Kiefer1952stochastic': '@article{Kiefer1952stochastic,\\n  title={Stochastic estimation of the maximum of a regression function},\\n  author={Kiefer, Jack and Wolfowitz, Jacob and others},\\n  journal={The Annals of Mathematical Statistics},\\n  volume={23},\\n  number={3},\\n  pages={462--466},\\n  year={1952},\\n  publisher={Institute of Mathematical Statistics}\\n}',\n",
       " 'Spall1992multivariate': '@article{Spall1992multivariate,\\n  title={Multivariate stochastic approximation using a simultaneous perturbation gradient approximation},\\n  author={Spall, James C},\\n  journal={IEEE transactions on automatic control},\\n  volume={37},\\n  number={3},\\n  pages={332--341},\\n  year={1992},\\n  publisher={IEEE}\\n}',\n",
       " 'Chen2016variational': '@inproceedings{Chen2016variational,\\n  title={Variational Lossy Autoencoder},\\n  author={Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},\\n  year = {2017},\\n  booktitle = {ICLR}\\n}',\n",
       " 'Gregor2015draw': '@inproceedings{Gregor2015draw,\\n  author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan },\\n  title = {{DRAW:} {A} Recurrent Neural Network For Image Generation},\\n  booktitle = {ICML},\\n  pages = {1462--1471},\\n  year = {2015},\\n}',\n",
       " 'Naesseth2014sequential': '@inproceedings{Naesseth2014sequential,\\n  title={Sequential {M}onte {C}arlo for graphical models},\\n  author={Naesseth, Christian Andersson and Lindsten, Fredrik and Sch{\\\\\"o}n, Thomas B},\\n  booktitle={NIPS},\\n  pages={1862--1870},\\n  year={2014}\\n}',\n",
       " 'Douc2005comparison': \"@inproceedings{Douc2005comparison,\\n  title={Comparison of resampling schemes for particle filtering},\\n  author={Douc, Randal and Capp{\\\\'e}, Olivier},\\n  booktitle={ISPA},\\n  pages={64--69},\\n  year={2005},\\n  organization={IEEE}\\n}\",\n",
       " 'Roweis1999unifying': '@article{Roweis1999unifying,\\n  title={A unifying review of linear Gaussian models},\\n  author={Roweis, Sam and Ghahramani, Zoubin},\\n  journal={Neural computation},\\n  volume={11},\\n  number={2},\\n  pages={305--345},\\n  year={1999},\\n  publisher={MIT Press}\\n}',\n",
       " 'Neal2001annealed': '@article{Neal2001annealed,\\n  title={Annealed importance sampling},\\n  author={Neal, Radford M},\\n  journal={Statistics and computing},\\n  volume={11},\\n  number={2},\\n  pages={125--139},\\n  year={2001},\\n  publisher={Springer}\\n}',\n",
       " 'Rainforth2016interacting': '@inproceedings{Rainforth2016interacting,\\n  title={Interacting Particle {M}arkov Chain {M}onte {C}arlo},\\n  author={Rainforth, Tom and Naesseth, Christian A and Lindsten, Fredrik and Paige, Brooks and van de Meent, Jan-Willem and Doucet, Arnaud and Wood, Frank},\\n  booktitle={ICML},\\n  volume={48},\\n  year={2016}\\n}',\n",
       " 'Ehrlich2015gradient': '@article{Ehrlich2015gradient,\\n  title={Gradient free parameter estimation for hidden {M}arkov models with intractable likelihoods},\\n  author={Ehrlich, Elena and Jasra, Ajay and Kantas, Nikolas},\\n  journal={Methodology and Computing in Applied Probability},\\n  volume={17},\\n  number={2},\\n  pages={315},\\n  year={2015},\\n  publisher={Springer Science \\\\& Business Media}\\n}',\n",
       " 'Berard2014lognormal': \"@article{Berard2014lognormal,\\n  title={A lognormal central limit theorem for particle approximations of normalizing constants},\\n  author={B{\\\\'e}rard, Jean and Del Moral, Pierre and Doucet, Arnaud and others},\\n  journal={Electronic Journal of Probability},\\n  volume={19},\\n  number={94},\\n  pages={1--28},\\n  year={2014},\\n  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}\\n}\",\n",
       " 'Ghahramani2015probabilistic': '@article{Ghahramani2015probabilistic,\\n  title={Probabilistic machine learning and artificial intelligence},\\n  author={Ghahramani, Zoubin},\\n  journal={Nature},\\n  volume={521},\\n  number={7553},\\n  pages={452--459},\\n  year={2015},\\n  publisher={Nature Research}\\n}',\n",
       " 'Chen2017variational': '@inproceedings{Chen2017variational,\\n  title = {Variational Lossy Autoencoder},\\n  author = {Chen, Xi and Kingma, Diederik P. and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},\\n  year = {2017},\\n  booktitle = {ICLR}\\n}',\n",
       " 'Stuhlmuller2013learning': '@inproceedings{Stuhlmuller2013learning,\\n  title={Learning stochastic inverses},\\n  author={Stuhlm{\\\\\"u}ller, Andreas and Taylor, Jacob and Goodman, Noah},\\n  booktitle={Advances in neural information processing systems},\\n  pages={3048--3056},\\n  year={2013}\\n}',\n",
       " 'Huggins2015convergence': '@article{Huggins2015convergence,\\n  title={Convergence of Sequential {M}onte {C}arlo-based Sampling Methods},\\n  author={Huggins, Jonathan H and Roy, Daniel M},\\n  journal={arXiv preprint arXiv:1503.00966},\\n  year={2015}\\n}',\n",
       " 'Rezende2015variational': '@inproceedings{Rezende2015variational,\\n  title={Variational Inference with Normalizing Flows},\\n  author={Rezende, Danilo and Mohamed, Shakir},\\n  booktitle={ICML},\\n  pages={1530--1538},\\n  year={2015}\\n}',\n",
       " 'Kingma2016improving': '@article{Kingma2016improving,\\n  title={Improving variational inference with inverse autoregressive flow},\\n  author={Kingma, Diederik P and Salimans, Tim and Welling, Max},\\n  journal={arXiv preprint arXiv:1606.04934},\\n  year={2016}\\n}',\n",
       " 'Salimans2015markov': '@inproceedings{Salimans2015markov,\\n  title={{M}arkov Chain {M}onte {C}arlo and Variational Inference: Bridging the Gap},\\n  author={Salimans, Tim and Kingma, Diederik and Welling, Max},\\n  booktitle={ICML},\\n  year={2015}\\n}',\n",
       " 'Gordon2014probabilistic': '@inproceedings{Gordon2014probabilistic,\\n  title={Probabilistic programming},\\n  author={Gordon, Andrew D and Henzinger, Thomas A and Nori, Aditya V and Rajamani, Sriram K},\\n  booktitle={Future of Software Engineering, FOSE 2014},\\n  pages={167--181},\\n  year={2014},\\n  organization={ACM}\\n}',\n",
       " 'Narayanan2016probabilistic': '@article{Narayanan2016probabilistic,\\n  author  = {Praveen Narayanan and\\n             Jacques Carette and\\n             Wren Romano and\\n             Chung{-}chieh Shan and\\n             Robert Zinkov},\\n  title   = {Probabilistic Inference by Program Transformation in {Hakaru} (System\\n             Description)},\\n  journal = {Functional and Logic Programming - 13th International Symposium, {FLOPS}\\n             2016, Kochi, Japan, March 4--6, 2016, Proceedings},\\n  pages   = {62--79},\\n  year    = {2016}\\n}',\n",
       " 'Infernet14': '@misc{Infernet14,\\n  author = \"Minka, T. and Winn, J.M. and Guiver, J.P. and Webster, S. and Zaykov, Y. and Yangel, B. and Spengler, A. and  Bronskill, J.\",\\n  title = {{Infer.NET 2.6}},\\n  year = 2014,\\n  note = {Microsoft Research Cambridge. http://research.microsoft.com/infernet}\\n}',\n",
       " 'Lunn2000winbugs': '@article{Lunn2000winbugs,\\n  title={{WinBUGS}--a {Bayesian} modelling framework: concepts, structure, and extensibility},\\n  author={Lunn, David J and Thomas, Andrew and Best, Nicky and Spiegelhalter, David},\\n  journal={Statistics and Computing},\\n  volume={10},\\n  number={4},\\n  pages={325--337},\\n  year={2000},\\n  publisher={Springer}\\n}',\n",
       " 'Hochreiter1997long': '@article{Hochreiter1997long,\\n  title={Long short-term memory},\\n  author={Hochreiter, Sepp and Schmidhuber, J{\\\\\"u}rgen},\\n  journal={Neural computation},\\n  volume={9},\\n  number={8},\\n  pages={1735--1780},\\n  year={1997},\\n  publisher={MIT Press}\\n}',\n",
       " 'Lecun1998mnist': '@article{Lecun1998mnist,\\n  title={The MNIST database of handwritten digits},\\n  author={LeCun, Yann},\\n  url={http://yann.lecun.com/exdb/mnist/},\\n  year={1998}\\n}',\n",
       " 'Jin2017differentiating': '@unpublished{Jin2017differentiating,\\n    author  = \"Jin, Tom and Le, Tuan Anh and Igl, Max and Rainforth, Tom and Wood, Frank\",\\n    title   = \"Differentiating through Sequential {M}onte {C}arlo for Model Learning\",\\n    year    = \"2017\",\\n    month   = \"March\",\\n    note    = \"Manuscript submitted for publication\",\\n}',\n",
       " 'Krishnan2016structured': '@inproceedings{Krishnan2016structured,\\n  title={Structured Inference Networks for Nonlinear State Space Models},\\n  author={Krishnan, Rahul G and Shalit, Uri and Sontag, David},\\n  booktitle={AAAI},\\n  year={2017}\\n}',\n",
       " 'Chung2015gated': '@inproceedings{Chung2015gated,\\n  title={Gated Feedback Recurrent Neural Networks.},\\n  author={Chung, Junyoung and G{\\\\\"u}l{\\\\c{c}}ehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},\\n  booktitle={ICML},\\n  pages={2067--2075},\\n  year={2015}\\n}',\n",
       " 'Hoffman2013stochastic': '@article{Hoffman2013stochastic,\\n  title={Stochastic variational inference},\\n  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},\\n  journal={The Journal of Machine Learning Research},\\n  volume={14},\\n  number={1},\\n  pages={1303--1347},\\n  year={2013},\\n  publisher={JMLR. org}\\n}',\n",
       " 'Wainwright2008graphical': '@article{Wainwright2008graphical,\\n  title={Graphical models, exponential families, and variational inference},\\n  author={Wainwright, Martin J and Jordan, Michael I and others},\\n  journal={Foundations and Trends{\\\\textregistered} in Machine Learning},\\n  volume={1},\\n  number={1--2},\\n  pages={1--305},\\n  year={2008},\\n  publisher={Now Publishers, Inc.}\\n}',\n",
       " 'Rainforth2017opportunities': '@inproceedings{Rainforth2017opportunities,\\n\\ttitle={On Nesting {M}onte {C}arlo Estimators},\\n\\tauthor={Rainforth, Tom and Cornish, Robert and Yang, Hongseok and Warrington, Andrew and Wood, Frank},\\n\\tbooktitle={ICML},\\n\\tyear={2018}\\n}',\n",
       " 'Le2017auto': '@article{Le2017auto,\\n  title={Auto-Encoding Sequential Monte Carlo},\\n  author={Le, Tuan Anh and Igl, Maximilian and Jin, Tom and Rainforth, Tom and Wood, Frank},\\n  journal={arXiv preprint arXiv:1705.10306},\\n  year={2017}\\n}',\n",
       " 'RezendeVariational2015': '@article{RezendeVariational2015,\\n  title = {Variational {{Inference}} with {{Normalizing Flows}}},\\n  url = {http://arxiv.org/abs/1505.05770},\\n  timestamp = {2017-07-20T09:45:13Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1505.05770},\\n  primaryClass = {cs, stat},\\n  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},\\n  urldate = {2017-03-17},\\n  date = {2015-05-21},\\n  note = {00114},\\n  keywords = {Computer Science - Artificial Intelligence,Computer Science - Learning,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},\\n  file = {Rezende_Mohamed_2015_Variational Inference with Normalizing Flows.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/FKFWWEJ3/Rezende_Mohamed_2015_Variational Inference with Normalizing Flows.pdf:application/pdf},\\n  groups = {Variational Inference}\\n}',\n",
       " 'HenaffModelBased20171': '@article{HenaffModelBased20171,\\n  title = {Model-{{Based Planning}} in {{Discrete Action Spaces}}},\\n  url = {http://arxiv.org/abs/1705.07177},\\n  timestamp = {2017-11-03T08:22:52Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1705.07177},\\n  primaryClass = {cs},\\n  author = {Henaff, Mikael and Whitney, William F. and LeCun, Yann},\\n  date = {2017-05-19},\\n  note = {00001},\\n  keywords = {Computer Science - Artificial Intelligence},\\n  file = {Henaff et al_2017_Model-Based Planning in Discrete Action Spaces.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/M34EFZPH/Henaff et al_2017_Model-Based Planning in Discrete Action Spaces.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/XVIW7MEC/1705.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'IsolaImageImage2016': '@article{IsolaImageImage2016,\\n  title = {Image-to-{{Image Translation}} with {{Conditional Adversarial Networks}}},\\n  url = {http://arxiv.org/abs/1611.07004},\\n  timestamp = {2017-11-03T08:23:08Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1611.07004},\\n  primaryClass = {cs},\\n  author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},\\n  date = {2016-11-21},\\n  note = {00199},\\n  keywords = {Computer Science - Computer Vision and Pattern Recognition},\\n  file = {Isola et al_2016_Image-to-Image Translation with Conditional Adversarial Networks.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/ZDQN8JVU/Isola et al_2016_Image-to-Image Translation with Conditional Adversarial Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/P5S7SKWT/1611.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'SrivastavaFirstOrder2012': '@inproceedings{SrivastavaFirstOrder2012,\\n  title = {First-Order Models for Pomdps},\\n  timestamp = {2017-11-03T08:23:25Z},\\n  booktitle = {{{UAI Workshop}} on {{Statistical Relational Artificial Intelligence}} ({{StarAI}})},\\n  author = {Srivastava, Siddharth and Russell, Stuart and Pfeffer, Avi and Analytics, Charles River},\\n  date = {2012},\\n  note = {00003},\\n  file = {Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/8ITQQRZM/Srivastava et al. - 2012 - First-order models for pomdps.pdf:application/pdf;Fulltext:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/VDG4C3TU/Srivastava et al. - 2012 - First-order models for pomdps.pdf:application/pdf},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'SalimansMarkov2015': '@inproceedings{SalimansMarkov2015,\\n  title = {Markov Chain Monte Carlo and Variational Inference: {{Bridging}} the Gap},\\n  shorttitle = {Markov Chain Monte Carlo and Variational Inference},\\n  timestamp = {2017-11-03T08:35:51Z},\\n  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}} ({{ICML}}-15)},\\n  author = {Salimans, Tim and Kingma, Diederik and Welling, Max},\\n  date = {2015},\\n  pages = {1218--1226},\\n  note = {00110},\\n  file = {Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/2S2WDAQW/Salimans et al. - 2015 - Markov chain monte carlo and variational inference.pdf:application/pdf;Salimans et al_2015_Markov chain monte carlo and variational inference.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/I3PPVKWA/Salimans et al_2015_Markov chain monte carlo and variational inference.pdf:application/pdf},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'LiRenyi2016': '@article{LiRenyi2016,\\n  title = {RÃ©nyi {{Divergence Variational Inference}}},\\n  volume = {1050},\\n  timestamp = {2017-11-03T08:56:10Z},\\n  journaltitle = {stat},\\n  author = {Li, Yingzhen and Turner, Richard E.},\\n  date = {2016},\\n  pages = {28},\\n  note = {00024},\\n  file = {Fulltext:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/TX3R72ZA/Li and Turner - 2016 - RÃ©nyi Divergence Variational Inference.pdf:application/pdf;Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/VR8SXHT2/Li and Turner - 2016 - RÃ©nyi Divergence Variational Inference.pdf:application/pdf},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'MnihVariational2016': '@inproceedings{MnihVariational2016,\\n  title = {Variational {{Inference}} for {{Monte Carlo Objectives}}},\\n  url = {http://proceedings.mlr.press/v48/mnihb16.html},\\n  eventtitle = {International Conference on Machine Learning},\\n  timestamp = {2017-11-03T08:58:29Z},\\n  langid = {english},\\n  booktitle = {{{PMLR}}},\\n  author = {Mnih, Andriy and Rezende, Danilo},\\n  urldate = {2017-11-03},\\n  date = {2016-06-11},\\n  pages = {2188--2196},\\n  note = {00039},\\n  file = {Mnih_Rezende_2016_Variational Inference for Monte Carlo Objectives.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/9ZPXI8EU/Mnih_Rezende_2016_Variational Inference for Monte Carlo Objectives.pdf:application/pdf;Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/23FQP93B/mnihb16.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'KingmaImproving20161': '@article{KingmaImproving20161,\\n  title = {Improving {{Variational Inference}} with {{Inverse Autoregressive Flow}}},\\n  url = {http://arxiv.org/abs/1606.04934},\\n  timestamp = {2017-11-03T09:04:40Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1606.04934},\\n  primaryClass = {cs, stat},\\n  author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},\\n  date = {2016-06-15},\\n  note = {00066},\\n  keywords = {Computer Science - Learning,Statistics - Machine Learning},\\n  file = {Kingma et al_2016_Improving Variational Inference with Inverse Autoregressive Flow.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/5HSDGUQ6/Kingma et al_2016_Improving Variational Inference with Inverse Autoregressive Flow.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/7GF59DSH/1606.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'MaaloeAuxiliary2016': '@article{MaaloeAuxiliary2016,\\n  title = {Auxiliary {{Deep Generative Models}}},\\n  url = {http://arxiv.org/abs/1602.05473},\\n  timestamp = {2017-11-03T09:08:04Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1602.05473},\\n  primaryClass = {cs, stat},\\n  author = {MaalÃ¸e, Lars and SÃ¸nderby, Casper Kaae and SÃ¸nderby, SÃ¸ren Kaae and Winther, Ole},\\n  date = {2016-02-17},\\n  note = {00089},\\n  keywords = {Computer Science - Artificial Intelligence,Computer Science - Learning,Statistics - Machine Learning},\\n  file = {MaalÃ¸e et al_2016_Auxiliary Deep Generative Models.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/ZFCIH2WN/MaalÃ¸e et al_2016_Auxiliary Deep Generative Models.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/XV9MTABQ/1602.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'SoNderbyLadder2016': '@incollection{SoNderbyLadder2016,\\n  title = {Ladder {{Variational Autoencoders}}},\\n  url = {http://papers.nips.cc/paper/6275-ladder-variational-autoencoders.pdf},\\n  timestamp = {2017-11-03T09:11:27Z},\\n  booktitle = {Advances in {{Neural Information Processing Systems}} 29},\\n  publisher = {{Curran Associates, Inc.}},\\n  author = {SÃ¸ nderby, Casper Kaae and Raiko, Tapani and MaalÃ¸ e, Lars and SÃ¸ nderby, SÃ¸ ren Kaae and Winther, Ole},\\n  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},\\n  date = {2016},\\n  pages = {3738--3746},\\n  note = {00000},\\n  file = {SÃ¸ nderby et al_2016_Ladder Variational Autoencoders.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/37WZD3M9/SÃ¸ nderby et al_2016_Ladder Variational Autoencoders.pdf:application/pdf;NIPS Snapshort:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/43INRP2F/6275-ladder-variational-autoencoders.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'RolfeDiscrete2016': '@article{RolfeDiscrete2016,\\n  title = {Discrete {{Variational Autoencoders}}},\\n  url = {http://arxiv.org/abs/1609.02200},\\n  timestamp = {2017-11-03T09:12:26Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1609.02200},\\n  primaryClass = {cs, stat},\\n  author = {Rolfe, Jason Tyler},\\n  date = {2016-09-07},\\n  note = {00009},\\n  keywords = {Computer Science - Learning,Statistics - Machine Learning},\\n  file = {Rolfe_2016_Discrete Variational Autoencoders.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/JK9R98C9/Rolfe_2016_Discrete Variational Autoencoders.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/3P9EPKBW/1609.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'MakhzaniAdversarial2015': '@article{MakhzaniAdversarial2015,\\n  title = {Adversarial {{Autoencoders}}},\\n  url = {http://arxiv.org/abs/1511.05644},\\n  timestamp = {2017-11-03T09:16:15Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1511.05644},\\n  primaryClass = {cs},\\n  author = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},\\n  date = {2015-11-17},\\n  note = {00131},\\n  keywords = {Computer Science - Learning},\\n  file = {Makhzani et al_2015_Adversarial Autoencoders.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/VHNU8BEZ/Makhzani et al_2015_Adversarial Autoencoders.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/7VWX43BI/1511.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'TranVariational2015': '@article{TranVariational2015,\\n  title = {The {{Variational Gaussian Process}}},\\n  url = {http://arxiv.org/abs/1511.06499},\\n  timestamp = {2017-11-03T09:49:24Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1511.06499},\\n  primaryClass = {cs, stat},\\n  author = {Tran, Dustin and Ranganath, Rajesh and Blei, David M.},\\n  date = {2015-11-20},\\n  keywords = {Computer Science - Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Computation,Statistics - Machine Learning},\\n  file = {Tran et al_2015_The Variational Gaussian Process.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/HHFQP54S/Tran et al_2015_The Variational Gaussian Process.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/I89ITN7H/1511.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'BornscheinReweighted2014': '@article{BornscheinReweighted2014,\\n  title = {Reweighted {{Wake}}-{{Sleep}}},\\n  url = {http://arxiv.org/abs/1406.2751},\\n  timestamp = {2017-11-03T09:51:04Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1406.2751},\\n  primaryClass = {cs},\\n  author = {Bornschein, JÃ¶rg and Bengio, Yoshua},\\n  date = {2014-06-10},\\n  keywords = {Computer Science - Learning},\\n  file = {Bornschein_Bengio_2014_Reweighted Wake-Sleep.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/JB5PX838/Bornschein_Bengio_2014_Reweighted Wake-Sleep.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/879N34U3/1406.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'BamlerPerturbative2017': '@article{BamlerPerturbative2017,\\n  title = {Perturbative {{Black Box Variational Inference}}},\\n  url = {http://arxiv.org/abs/1709.07433},\\n  timestamp = {2017-11-03T11:49:34Z},\\n  archivePrefix = {arXiv},\\n  eprinttype = {arxiv},\\n  eprint = {1709.07433},\\n  primaryClass = {cs, stat},\\n  author = {Bamler, Robert and Zhang, Cheng and Opper, Manfred and Mandt, Stephan},\\n  date = {2017-09-21},\\n  keywords = {Computer Science - Learning,Statistics - Machine Learning},\\n  file = {Bamler et al_2017_Perturbative Black Box Variational Inference.pdf:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/NC5Q8GMN/Bamler et al_2017_Perturbative Black Box Variational Inference.pdf:application/pdf;arXiv.org Snapshot:/Users/migl/Library/Application Support/Zotero/Profiles/blsovwcl.default/zotero/storage/KCA9X3CB/1709.html:text/html},\\n  groups = {00\\\\_toSortRelevant,00\\\\_toSortRelevant}\\n}',\n",
       " 'Burda2015importance': '@article{Burda2015importance,\\n  title={Importance weighted autoencoders},\\n  author={Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},\\n  journal={arXiv preprint arXiv:1509.00519},\\n  year={2015}\\n}',\n",
       " 'Ranganath2016hierarchical': '@inproceedings{Ranganath2016hierarchical,\\n  title={Hierarchical variational models},\\n  author={Ranganath, Rajesh and Tran, Dustin and Blei, David},\\n  booktitle={ICML},\\n  year={2016}\\n}',\n",
       " 'Li2016renyi': \"@inproceedings{Li2016renyi,\\n  title={R{\\\\'e}nyi divergence variational inference},\\n  author={Li, Yingzhen and Turner, Richard E},\\n  booktitle={NIPS},\\n  year={2016}\\n}\",\n",
       " 'Turner2011two': '@article{Turner2011two,\\n  title={Two problems with variational expectation maximisation for time-series models},\\n  author={Turner, Richard E and Sahani, Maneesh},\\n  journal={Bayesian Time series models},\\n  pages={115--138},\\n  year={2011},\\n  publisher={Cambridge, UK: Cambridge Univ. Press}\\n}',\n",
       " 'Fort2017mcmc': '@article{Fort2017mcmc,\\n  title={MCMC design-based non-parametric regression for rare event. Application to nested risk computations},\\n  author={Fort, Gersende and Gobet, Emmanuel and Moulines, Eric},\\n  journal={Monte Carlo Methods and Applications},\\n  volume={23},\\n  number={1},\\n  pages={21--42},\\n  year={2017}\\n}',\n",
       " 'Hesterberg1988advances': '@phdthesis{Hesterberg1988advances,\\n\\ttitle={Advances in importance sampling},\\n\\tauthor={Hesterberg, Timothy Classen},\\n\\tyear={1988},\\n\\tschool={Stanford University}\\n}',\n",
       " 'Roberts2009signal': '@inproceedings{Roberts2009signal,\\n\\ttitle={Signal-to-noise ratio analysis of policy gradient algorithms},\\n\\tauthor={Roberts, John W and Tedrake, Russ},\\n\\tbooktitle={NIPS},\\n\\tyear={2009}\\n}',\n",
       " 'Cremer2017reinterpreting': '@article{Cremer2017reinterpreting,\\n\\ttitle={Reinterpreting Importance-Weighted Autoencoders},\\n\\tauthor={Cremer, Chris and Morris, Quaid and Duvenaud, David},\\n\\tjournal={arXiv preprint arXiv:1704.02916},\\n\\tyear={2017}\\n}',\n",
       " 'Mcbook': '@book{Mcbook,\\n\\tauthor = {Art B. Owen},\\n\\tyear = 2013,\\n\\ttitle = {Monte Carlo theory, methods and examples}\\n}',\n",
       " 'Ruiz2016overdispersed': '@article{Ruiz2016overdispersed,\\n\\ttitle={Overdispersed black-box variational inference},\\n\\tauthor={Ruiz, Francisco JR and Titsias, Michalis K and Blei, David M},\\n\\tjournal={arXiv preprint arXiv:1603.01140},\\n\\tyear={2016}\\n}',\n",
       " 'Lecun1998gradient': \"@article{Lecun1998gradient,\\n\\ttitle={Gradient-based learning applied to document recognition},\\n\\tauthor={LeCun, Yann and Bottou, L{\\\\'e}on and Bengio, Yoshua and Haffner, Patrick},\\n\\tjournal={Proceedings of the IEEE},\\n\\tvolume={86},\\n\\tnumber={11},\\n\\tpages={2278--2324},\\n\\tyear={1998},\\n\\tpublisher={IEEE}\\n}\",\n",
       " 'An2015variational': '@article{An2015variational,\\n\\ttitle={Variational autoencoder based anomaly detection using reconstruction probability},\\n\\tauthor={An, Jinwon and Cho, Sungzoon},\\n\\tjournal={SNU Data Mining Center, Tech. Rep.},\\n\\tyear={2015}\\n}',\n",
       " 'Engel2018latent': '@inproceedings{Engel2018latent,\\n\\ttitle={Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models},\\n\\tauthor={Jesse Engel and Matthew Hoffman and Adam Roberts},\\n\\tbooktitle={ICLR},\\n\\tyear={2018}\\n}',\n",
       " 'Gregor2016towards': '@inproceedings{Gregor2016towards,\\n\\ttitle={Towards conceptual compression},\\n\\tauthor={Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},\\n\\tbooktitle={NIPS},\\n\\tyear={2016}\\n}',\n",
       " 'Ranganath2014black': '@inproceedings{Ranganath2014black,\\n\\ttitle={Black box variational inference},\\n\\tauthor={Ranganath, Rajesh and Gerrish, Sean and Blei, David},\\n\\tbooktitle={AISTATS},\\n\\tyear={2014}\\n}',\n",
       " 'Bourlard1988auto': \"@article{Bourlard1988auto,\\n\\ttitle={Auto-association by multilayer perceptrons and singular value decomposition},\\n\\tauthor={Bourlard, Herv{\\\\'e} and Kamp, Yves},\\n\\tjournal={Biological cybernetics},\\n\\tvolume={59},\\n\\tnumber={4-5},\\n\\tpages={291--294},\\n\\tyear={1988},\\n\\tpublisher={Springer}\\n}\",\n",
       " 'Hinton1994autoencoders': '@inproceedings{Hinton1994autoencoders,\\n\\ttitle={Autoencoders, minimum description length and Helmholtz free energy},\\n\\tauthor={Hinton, Geoffrey E and Zemel, Richard S},\\n\\tbooktitle={NIPS},\\n\\tyear={1994}\\n}',\n",
       " 'Rainforth2017thesis': '@phdthesis{Rainforth2017thesis,\\n\\ttitle = {{Automating Inference, Learning, and Design using \\n\\tProbabilistic Programming}},\\n\\tauthor = {Rainforth, Tom},\\n\\tinstitution = {University of Oxford},\\n\\tyear = {2017}\\n}'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_bib_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing ref: Bamlerperturbative2017\n",
      "missing ref: Bomultrasonic1971\n",
      "missing ref: Bravatasystematic2007\n",
      "missing ref: Edlerultrasonic1957\n",
      "missing ref: Footdemographics2000\n",
      "missing ref: Gagliardicardiac1996\n",
      "missing ref: Gagliardirontgen1996\n",
      "missing ref: Gagliardiultrasonography1996\n",
      "missing ref: Griffithsector1974\n",
      "missing ref: Harveyexercitatio1628\n",
      "missing ref: Hologan\n",
      "missing ref: Ilsvrc15\n",
      "missing ref: Kthactivityrecognition\n",
      "missing ref: Leesoncardiovascular2011\n",
      "missing ref: Maaloeauxiliary2016\n",
      "missing ref: Otb\n",
      "missing ref: Rezendevariational2015\n",
      "missing ref: Salimansmarkov2015\n",
      "missing ref: Savarese2016goturn\n",
      "missing ref: Sonderbyladder2016\n",
      "missing ref: Sousanew2005\n",
      "missing ref: Tranvariational2015\n",
      "missing ref: Valmadre2017cfnn\n",
      "missing ref: Vongoethewilhelm1829\n",
      "missing ref: Webbintroduction2002\n"
     ]
    }
   ],
   "source": [
    "used_bib_entries = []\n",
    "\n",
    "for used_ref in all_used_refs:\n",
    "    \n",
    "    entry = formatted_bib_entries.get(used_ref, None)\n",
    "    \n",
    "    if entry is None:\n",
    "        print('missing ref: {}'.format(used_ref))\n",
    "    \n",
    "    else:\n",
    "        used_bib_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "522\n",
      "234\n"
     ]
    }
   ],
   "source": [
    "print(len(used_bib_entries))\n",
    "print(len(formatted_bib_entries))\n",
    "print(len(all_used_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bib_file = '\\n\\n'.join(used_bib_entries)\n",
    "with open('references.bib', 'w') as f:\n",
    "    f.write(master_bib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MOT16': 'Mot16',\n",
       " 'DroneDataset': 'Dronedataset',\n",
       " 'li2019way': 'Li2019way',\n",
       " 'su2016crowd': 'Su2016crowd',\n",
       " 'fernando2018soft': 'Fernando2018soft',\n",
       " 'vemula2018social': 'Vemula2018social',\n",
       " 'choi2019learning': 'Choi2019learning',\n",
       " 'zhang2019sr': 'Zhang2019sr',\n",
       " 'sadeghian2019sophie': 'Sadeghian2019sophie',\n",
       " 'varshneya2017human': 'Varshneya2017human',\n",
       " 'scholler2019simpler': 'Scholler2019simpler',\n",
       " 'UCY': 'Ucy',\n",
       " 'ETH': 'Eth',\n",
       " 'grewal2011kalman': 'Grewal2011kalman',\n",
       " 'IGP': 'Igp',\n",
       " 'rudenko2018joint': 'Rudenko2018joint',\n",
       " 'yamaguchi2011you': 'Yamaguchi2011you',\n",
       " 'social-lstm': 'SocialLstm',\n",
       " 'sun20183dof': 'Sun20183dof',\n",
       " 'bae2017confidence': 'Bae2017confidence',\n",
       " 'keuper2018motion': 'Keuper2018motion',\n",
       " 'kosiorek2017hierch': 'Kosiorek2017hierch',\n",
       " 'lecun2015deep': 'Lecun2015deep',\n",
       " 'kemp2008discovery': 'Kemp2008discovery',\n",
       " 'lecun1989backpropagation': 'Lecun1989backpropagation',\n",
       " 'cho2015unsupervised': 'Cho2015unsupervised',\n",
       " 'kwak2015unsupervised': 'Kwak2015unsupervised',\n",
       " 'xiao2016track': 'Xiao2016track',\n",
       " 'babaeizadeh2017stochastic': 'Babaeizadeh2017stochastic',\n",
       " 'tulyakov2017mocogan': 'Tulyakov2017mocogan',\n",
       " 'denton2017unsupervised': 'Denton2017unsupervised',\n",
       " 'ranzato2014video': 'Ranzato2014video',\n",
       " 'srivastava2015unsupervised': 'Srivastava2015unsupervised',\n",
       " 'neiswanger2012unsupervised': 'Neiswanger2012unsupervised',\n",
       " 'weber2017imagination': 'Weber2017imagination',\n",
       " 'kingma2013auto': 'Kingma2013auto',\n",
       " 'ristani2016performance': 'Ristani2016performance',\n",
       " 'tieleman2012rms': 'Tieleman2012rms',\n",
       " 'maddison2017filtering': 'Maddison2017filtering',\n",
       " 'gulrajani2016pixelvae': 'Gulrajani2016pixelvae',\n",
       " 'kim2018disentangling': 'Kim2018disentangling',\n",
       " 'itseez2015opencv': 'Itseez2015opencv',\n",
       " 'schulter2017deepnf': 'Schulter2017deepnf',\n",
       " 'bewley2016sort': 'Bewley2016sort',\n",
       " 'valmadre2017end': 'Valmadre2017end',\n",
       " 'karl2017dvbf': 'Karl2017dvbf',\n",
       " 'ondruska2016deepts': 'Ondruska2016deepts',\n",
       " 'shi2016subpixel': 'Shi2016subpixel',\n",
       " 'kingma2015adam': 'Kingma2015adam',\n",
       " 'zaheer2017deeps': 'Zaheer2017deeps',\n",
       " 'ha2018worldm': 'Ha2018worldm',\n",
       " 'jacobsen2016struc': 'Jacobsen2016struc',\n",
       " 'oord2016cond': 'Oord2016cond',\n",
       " 'lalonde': 'Lalonde',\n",
       " 'lenssen': 'Lenssen',\n",
       " 'duarte': 'Duarte',\n",
       " 'encapsule': 'Encapsule',\n",
       " 'zhang2018fast': 'Zhang2018fast',\n",
       " 'wang2018optimization': 'Wang2018optimization',\n",
       " 'saqur': 'Saqur',\n",
       " 'jaiswal': 'Jaiswal',\n",
       " 'upadhyay': 'Upadhyay',\n",
       " 'zhao20183d': 'Zhao20183d',\n",
       " 'mallat': 'Mallat',\n",
       " 'sparsecaps': 'Sparsecaps',\n",
       " 'kocvok': 'Kocvok',\n",
       " 'imsat': 'Imsat',\n",
       " 'iic': 'Iic',\n",
       " 'gan': 'Gan',\n",
       " 'ae': 'Ae',\n",
       " 'adc': 'Adc',\n",
       " 'liu2019soft': 'Liu2019soft',\n",
       " 'Ba2016LayerN': 'Ba2016layern',\n",
       " 'hinton1995wake': 'Hinton1995wake',\n",
       " 'bornschein2015reweighted': 'Bornschein2015reweighted',\n",
       " 'jang2017categorical': 'Jang2017categorical',\n",
       " 'maddison2017concrete': 'Maddison2017concrete',\n",
       " 'tucker2017rebar': 'Tucker2017rebar',\n",
       " 'grathwohl2018backpropagation': 'Grathwohl2018backpropagation',\n",
       " 'burda2016importance': 'Burda2016importance',\n",
       " 'mnih2016variational': 'Mnih2016variational',\n",
       " 'kingma2014auto': 'Kingma2014auto',\n",
       " 'rezende2014stochastic': 'Rezende2014stochastic',\n",
       " 'naesseth2017variational': 'Naesseth2017variational',\n",
       " 'le2018autoencoding': 'Le2018autoencoding',\n",
       " 'rainforth2018tighter': 'Rainforth2018tighter',\n",
       " 'williams1992simple': 'Williams1992simple',\n",
       " 'mnih2014neural': 'Mnih2014neural',\n",
       " 'dayan1995helmholtz': 'Dayan1995helmholtz',\n",
       " 'eslami2016attend': 'Eslami2016attend',\n",
       " 'miao2016language': 'Miao2016language',\n",
       " 'goodfellow2014generative': 'Goodfellow2014generative',\n",
       " 'mohamed2016learning': 'Mohamed2016learning',\n",
       " 'le2017inference': 'Le2017inference',\n",
       " 'gershman2014amortized': 'Gershman2014amortized',\n",
       " 'schulman2015gradient': 'Schulman2015gradient',\n",
       " 'johnson2016composing': 'Johnson2016composing',\n",
       " 'adams2010learning': 'Adams2010learning',\n",
       " 'neiswanger2014dependent': 'Neiswanger2014dependent',\n",
       " 'rasmussen2000infinite': 'Rasmussen2000infinite',\n",
       " 'kemp2006learning': 'Kemp2006learning',\n",
       " 'blei2003latent': 'Blei2003latent',\n",
       " 'ghahramani1996factorial': 'Ghahramani1996factorial',\n",
       " 'juang1991hidden': 'Juang1991hidden',\n",
       " 'chater2006probabilistic': 'Chater2006probabilistic',\n",
       " 'fei2003bayesian': 'Fei2003bayesian',\n",
       " 'kemp2006learningoverhypotheses': 'Kemp2006learningoverhypotheses',\n",
       " 'gu2016muprop': 'Gu2016muprop',\n",
       " 'owen2000safe': 'Owen2000safe',\n",
       " 'hesterberg1995weighted': 'Hesterberg1995weighted',\n",
       " 'saul1996mean': 'Saul1996mean',\n",
       " 'lake2018emergence': 'Lake2018emergence',\n",
       " 'paige2016inference': 'Paige2016inference',\n",
       " 'robbins1951stochastic': 'Robbins1951stochastic',\n",
       " 'neal1992connectionist': 'Neal1992connectionist',\n",
       " 'graves2014neural': 'Graves2014neural',\n",
       " 'sukhbaatar2015end': 'Sukhbaatar2015end',\n",
       " 'graves2016hybrid': 'Graves2016hybrid',\n",
       " 'graves2016adaptive': 'Graves2016adaptive',\n",
       " 'xu2015show': 'Xu2015show',\n",
       " 'grefenstette2015learning': 'Grefenstette2015learning',\n",
       " 'rolfe2016dvae': 'Rolfe2016dvae',\n",
       " 'vahdat2018dvaepp': 'Vahdat2018dvaepp',\n",
       " 'vahdat2018dvaehash': 'Vahdat2018dvaehash',\n",
       " 'minka2005divergence': 'Minka2005divergence',\n",
       " 'chatterjee2018sample': 'Chatterjee2018sample',\n",
       " 'owen2013monte': 'Owen2013monte',\n",
       " 'chen2018stochastic': 'Chen2018stochastic',\n",
       " 'manning1999foundations': 'Manning1999foundations',\n",
       " 'sisson2018handbook': 'Sisson2018handbook',\n",
       " 'oord2017neural': 'Oord2017neural',\n",
       " 'tucker2019doubly': 'Tucker2019doubly',\n",
       " 'lari1990estimation': 'Lari1990estimation',\n",
       " 'earley1970efficient': 'Earley1970efficient',\n",
       " 'booth1973applying': 'Booth1973applying',\n",
       " 'chen2014fast': 'Chen2014fast',\n",
       " 'tai2015improved': 'Tai2015improved',\n",
       " 'neural2017neural': 'Neural2017neural',\n",
       " 'younger1967recognition': 'Younger1967recognition',\n",
       " 'dempster1977maximum': 'Dempster1977maximum',\n",
       " 'klein2003parsing': 'Klein2003parsing',\n",
       " 'kosiorek2018sequential': 'Kosiorek2018sequential',\n",
       " 'goodman2008church': 'Goodman2008church',\n",
       " 'wood2014new': 'Wood2014new',\n",
       " 'mansinghka2014venture': 'Mansinghka2014venture',\n",
       " 'siddharth2017learning': 'Siddharth2017learning',\n",
       " 'bingham2019pyro': 'Bingham2019pyro',\n",
       " 'tran2017deep': 'Tran2017deep',\n",
       " 'vandemeent2018intro': 'Vandemeent2018intro',\n",
       " 'denton2018stochastic': 'Denton2018stochastic',\n",
       " 'OConnor2017': 'Oconnor2017',\n",
       " 'VerSteeg2014': 'Versteeg2014',\n",
       " 'yu2016unitbox': 'Yu2016unitbox',\n",
       " 'Hinton2015RMSProp': 'Hinton2015rmsprop',\n",
       " 'DeVries2017': 'Devries2017',\n",
       " 'McIntosh2009': 'Mcintosh2009',\n",
       " 'DiPietro2017': 'Dipietro2017',\n",
       " 'KTH_activity_recognition': 'KthActivityRecognition',\n",
       " 'VOT2016': 'Vot2016',\n",
       " 'Shwartz-Ziv2017': 'ShwartzZiv2017',\n",
       " 'Leal-Taixe2015': 'LealTaixe2015',\n",
       " 'bamler2017perturbative': 'Bamler2017perturbative',\n",
       " 'andrieu2010particle': 'Andrieu2010particle',\n",
       " 'chung2015recurrent': 'Chung2015recurrent',\n",
       " 'ondruska2016deep': 'Ondruska2016deep',\n",
       " 'boulanger2012modeling': 'Boulanger2012modeling',\n",
       " 'doucet2002marginal': 'Doucet2002marginal',\n",
       " 'rainforth2016bayesian': 'Rainforth2016bayesian',\n",
       " 'muller2004optimal': 'Muller2004optimal',\n",
       " 'chen2014stochastic': 'Chen2014stochastic',\n",
       " 'mackay2003information': 'Mackay2003information',\n",
       " 'box1976science': 'Box1976science',\n",
       " 'rasmussen2001occam': 'Rasmussen2001occam',\n",
       " 'del2004feynman': 'Del2004feynman',\n",
       " 'griewank2008evaluating': 'Griewank2008evaluating',\n",
       " 'collobert2002torch': 'Collobert2002torch',\n",
       " 'baydin2015automatic': 'Baydin2015automatic',\n",
       " 'abadi2015tensorflow': 'Abadi2015tensorflow',\n",
       " 'rumelhart1988learning': 'Rumelhart1988learning',\n",
       " 'baydin2016diffsharp': 'Baydin2016diffsharp',\n",
       " 'doucet2009tutorial': 'Doucet2009tutorial',\n",
       " 'pearlmutter2008reverse': 'Pearlmutter2008reverse',\n",
       " 'ruder2016overview': 'Ruder2016overview',\n",
       " 'gu2015neural': 'Gu2015neural',\n",
       " 'durbin2000time': 'Durbin2000time',\n",
       " 'kingma2014adam': 'Kingma2014adam',\n",
       " 'del2006sequential': 'Del2006sequential',\n",
       " 'kantas2009overview': 'Kantas2009overview',\n",
       " 'doucet2003parameter': 'Doucet2003parameter',\n",
       " 'poyiadjis2011particle': 'Poyiadjis2011particle',\n",
       " 'candy2016bayesian': 'Candy2016bayesian',\n",
       " 'creal2012survey': 'Creal2012survey',\n",
       " 'doucet2001introduction': 'Doucet2001introduction',\n",
       " 'sutton1998reinforcement': 'Sutton1998reinforcement',\n",
       " 'andrieu2009pseudo': 'Andrieu2009pseudo',\n",
       " 'poyiadjis2006gradient': 'Poyiadjis2006gradient',\n",
       " 'coquelin2009particle': 'Coquelin2009particle',\n",
       " 'kiefer1952stochastic': 'Kiefer1952stochastic',\n",
       " 'spall1992multivariate': 'Spall1992multivariate',\n",
       " 'chen2016variational': 'Chen2016variational',\n",
       " 'gregor2015draw': 'Gregor2015draw',\n",
       " 'naesseth2014sequential': 'Naesseth2014sequential',\n",
       " 'douc2005comparison': 'Douc2005comparison',\n",
       " 'roweis1999unifying': 'Roweis1999unifying',\n",
       " 'neal2001annealed': 'Neal2001annealed',\n",
       " 'rainforth2016interacting': 'Rainforth2016interacting',\n",
       " 'ehrlich2015gradient': 'Ehrlich2015gradient',\n",
       " 'berard2014lognormal': 'Berard2014lognormal',\n",
       " 'ghahramani2015probabilistic': 'Ghahramani2015probabilistic',\n",
       " 'chen2017variational': 'Chen2017variational',\n",
       " 'stuhlmuller2013learning': 'Stuhlmuller2013learning',\n",
       " 'huggins2015convergence': 'Huggins2015convergence',\n",
       " 'rezende2015variational': 'Rezende2015variational',\n",
       " 'kingma2016improving': 'Kingma2016improving',\n",
       " 'salimans2015markov': 'Salimans2015markov',\n",
       " 'gordon2014probabilistic': 'Gordon2014probabilistic',\n",
       " 'narayanan2016probabilistic': 'Narayanan2016probabilistic',\n",
       " 'InferNET14': 'Infernet14',\n",
       " 'lunn2000winbugs': 'Lunn2000winbugs',\n",
       " 'hochreiter1997long': 'Hochreiter1997long',\n",
       " 'lecun1998mnist': 'Lecun1998mnist',\n",
       " 'jin2017differentiating': 'Jin2017differentiating',\n",
       " 'krishnan2016structured': 'Krishnan2016structured',\n",
       " 'chung2015gated': 'Chung2015gated',\n",
       " 'hoffman2013stochastic': 'Hoffman2013stochastic',\n",
       " 'wainwright2008graphical': 'Wainwright2008graphical',\n",
       " 'rainforth2017opportunities': 'Rainforth2017opportunities',\n",
       " 'le2017auto': 'Le2017auto',\n",
       " 'rezende_variational_2015': 'RezendeVariational2015',\n",
       " 'henaff_model-based_2017-1': 'HenaffModelBased20171',\n",
       " 'isola_image--image_2016': 'IsolaImageImage2016',\n",
       " 'srivastava_first-order_2012': 'SrivastavaFirstOrder2012',\n",
       " 'salimans_markov_2015': 'SalimansMarkov2015',\n",
       " 'li_renyi_2016': 'LiRenyi2016',\n",
       " 'mnih_variational_2016': 'MnihVariational2016',\n",
       " 'kingma_improving_2016-1': 'KingmaImproving20161',\n",
       " 'maaloe_auxiliary_2016': 'MaaloeAuxiliary2016',\n",
       " 'so_nderby_ladder_2016': 'SoNderbyLadder2016',\n",
       " 'rolfe_discrete_2016': 'RolfeDiscrete2016',\n",
       " 'makhzani_adversarial_2015': 'MakhzaniAdversarial2015',\n",
       " 'tran_variational_2015': 'TranVariational2015',\n",
       " 'bornschein_reweighted_2014': 'BornscheinReweighted2014',\n",
       " 'bamler_perturbative_2017': 'BamlerPerturbative2017',\n",
       " 'burda2015importance': 'Burda2015importance',\n",
       " 'ranganath2016hierarchical': 'Ranganath2016hierarchical',\n",
       " 'li2016renyi': 'Li2016renyi',\n",
       " 'turner2011two': 'Turner2011two',\n",
       " 'fort2017mcmc': 'Fort2017mcmc',\n",
       " 'hesterberg1988advances': 'Hesterberg1988advances',\n",
       " 'roberts2009signal': 'Roberts2009signal',\n",
       " 'cremer2017reinterpreting': 'Cremer2017reinterpreting',\n",
       " 'mcbook': 'Mcbook',\n",
       " 'ruiz2016overdispersed': 'Ruiz2016overdispersed',\n",
       " 'lecun1998gradient': 'Lecun1998gradient',\n",
       " 'an2015variational': 'An2015variational',\n",
       " 'engel2018latent': 'Engel2018latent',\n",
       " 'gregor2016towards': 'Gregor2016towards',\n",
       " 'ranganath2014black': 'Ranganath2014black',\n",
       " 'bourlard1988auto': 'Bourlard1988auto',\n",
       " 'hinton1994autoencoders': 'Hinton1994autoencoders',\n",
       " 'rainforth2017thesis': 'Rainforth2017thesis'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tex_file in tex_files:\n",
    "    content = open(tex_file).read()\n",
    "    refs = extract_refs(content)\n",
    "    replaced = False\n",
    "    for ref in refs:\n",
    "        if ref in ref_map:\n",
    "            content = content.replace(ref, ref_map[ref])\n",
    "            replaced = True\n",
    "            \n",
    "    if replaced:\n",
    "        with open(tex_file, 'w') as f:\n",
    "            f.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
