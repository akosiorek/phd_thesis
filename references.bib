@inproceedings{Adams2010learning,
  title={Learning the structure of deep sparse graphical models},
  author={Adams, Ryan and Wallach, Hanna and Ghahramani, Zoubin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2010}
}

@inproceedings{Alahi2016social,
	title={Social {LSTM}: Human trajectory prediction in crowded spaces},
	author={Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2016}
}

@inproceedings{Haeusser2018adc,
  title={Associative Deep Clustering: Training a Classification Network with No Labels},
  author={Haeusser, Philip and Plapp, Johannes and Golkov, Vladimir and Aljalbout, Elie and Cremers, Daniel},
  booktitle={German Conference on Pattern Recognition},
  pages={18--32},
  year={2018},
%   organization={Springer}
}

@inproceedings{Bengio2007greedy,
  title={Greedy Layer-wise Training of Deep Networks},
  author={Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
  booktitle={Advances in Neural Information Processing Systems},
  pages={153--160},
  year={2007}
}

@article{Ba2016layern,
   title={Layer Normalization},
   author={Jimmy Ba and Jamie Kiros and G E Hinton},
   journal={CoRR},
   year={2016},
   volume={abs/1607.06450}
 }

@article{Bae2017confidence,
  title={Confidence-based data association and discriminative deep appearance learning for robust online multi-object tracking},
  author={Bae, Seung-Hwan and Yoon, Kuk-Jin},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
}

@article{Bamler2017perturbative,
  title={Perturbative Black Box Variational Inference},
  author={Bamler, Robert and Zhang, Cheng and Opper, Manfred and Mandt, Stephan},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint = {1709.07433},
  year={2017}
}

@article{Battaglia2016,
abstract = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},
archivePrefix = {arXiv},
eprint = {1612.00222},
author = {Battaglia, Peter W and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and Koray Kavukcuoglu},
eprint = {1612.00222},
optissn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {dec},
pages = {4502--4510},
title = {{Interaction Networks for Learning about Objects, Relations and Physics}},
opturl = {http://arxiv.org/abs/1612.00222},
year = {2016}
}

@article{Battaglia2018relnets,
	title={Relational inductive biases, deep learning, and graph networks},
	author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vin{\'i}cius Flores and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and G{\"u}lçehre, Çaglar and Song, H Francis and Ballard, Andrew J and Gilmer, Justin and Dahl, George E and Vaswani, Ashish and Allen, Kelsey R and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas Manfred Otto and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matthew M and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	archivePrefix={arXiv},
	year={2018},
	eprint={1806.01261}
}

@inproceedings{Bengio2009,
abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illus- trates gradually more concepts, and gradu- ally more complex ones. Here, we formal- ize such training strategies in the context of machine learning, and call them “curricu- lum learning”. In the context of recent re- search studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neu- ral networks), we explore curriculum learn- ing in various set-ups. The experiments show that significant improvements in generaliza- tion can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bengio, Yoshua and Louradour, J{\'{e}}r{\^{o}}me and Collobert, Ronan and Weston, Jason},
booktitle = {International Conference on Machine Learning},
optdoi = {10.1145/1553374.1553380},
eprint = {arXiv:1011.1669v3},
optisbn = {9781605585161},
optissn = {0022-5193},
pmid = {5414602},
title = {{Curriculum learning}},
opturl = {http://portal.acm.org/citation.cfm?optdoid=1553374.1553380},
year = {2009}
}

@inproceedings{Bewley2016sort,
  title={Simple online and realtime tracking},
  author={Alex Bewley and ZongYuan Ge and Lionel Ott and Fabio Tozeto Ramos and Ben Upcroft},
  booktitle={IEEE International Conference on Image Processing},
  year={2016},
  pages={3464-3468}
}

@article{Blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{Booth1973applying,
  title={Applying probability measures to abstract languages},
  author={Booth, Taylor L and Thompson, Richard A},
  journal={IEEE transactions on Computers},
  volume={100},
  number={5},
  pages={442--450},
  year={1973},
  publisher={IEEE}
}

@inproceedings{Bornschein2015reweighted,
  title        = {Reweighted Wake-Sleep},
  author       = {Bornschein, J{\"o}rg and Bengio, Yoshua},
  booktitle    = {International Conference on Learning Representations},
  year         = 2015
}

@article{Bourlard1988auto,
	title={Auto-association by multilayer perceptrons and singular value decomposition},
	author={Bourlard, Herv{\'e} and Kamp, Yves},
	journal={Biological cybernetics},
	volume={59},
	number={4-5},
	pages={291--294},
	year={1988},
	publisher={Springer}
}

@article{Brabandere2016dfn,
abstract = {In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.},
archivePrefix = {arXiv},
arxivId = {1605.09673},
author = {{De Brabandere}, Bert and Jia, Xu and Tuytelaars, Tinne and {Van Gool}, Luc},
eprint = {1605.09673},
journal = {Advances in Neural Information Processing Systems},
title = {{Dynamic Filter Networks}},
opturl = {http://arxiv.org/abs/1605.09673},
year = {2016}
}

@inproceedings{Burda2016iwae,
abstract = {The variational autoencoder (VAE; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.},
archivePrefix = {arXiv},
eprint = {1509.00519},
author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
booktitle = {International Conference on Learning Representations},
issn = {1312.6114v10},
month = sep,
title = {{Importance Weighted Autoencoders}},
url = {http://arxiv.org/abs/1509.00519},
year = {2016}
}

@article{Burgess2019monet,
  title={MONet: Unsupervised Scene Decomposition and Representation},
  author={Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint = {1901.11390},
  year={2019}
}

@article{Chater2006probabilistic,
  title={Probabilistic models of language processing and acquisition},
  author={Chater, Nick and Manning, Christopher D},
  journal={Trends in cognitive sciences},
  volume={10},
  number={7},
  pages={335--344},
  year={2006},
  publisher={Elsevier}
}

@article{Chatterjee2018sample,
  title={The sample size required in importance sampling},
  author={Chatterjee, Sourav and Diaconis, Persi and others},
  journal={The Annals of Applied Probability},
  volume={28},
  number={2},
  pages={1099--1135},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{Chen2014fast,
  title={A fast and accurate dependency parser using neural networks},
  author={Chen, Danqi and Manning, Christopher},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={740--750},
  year={2014}
}

@inproceedings{Chen2016variational,
  title={Variational Lossy Autoencoder},
  author={Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  year = {2017},
  booktitle = {International Conference on Learning Representations}
}

@article{Chen2018stochastic,
  title={Stochastic gradient descent with biased but consistent gradient estimators},
  author={Chen, Jie and Luss, Ronny},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint = {1807.11880},
  year={2018}
}

@inproceedings{Cheung2016gtc,
author = {Cheung, Brian},
booktitle = {GPU Technology Conference},
title = {{Neural Attention for Object Tracking}},
opturl = {http://on-demand.gputechconf.com/gtc/2016/presentation/s6497-brian-cheung-neural-attention-for-object-tracking.pdf},
year = {2016}
}

@article{Ciaparrone2019deepmot,
	title={Deep Learning in Video Multi-Object Tracking: A Survey},
	author={Gioele Ciaparrone and Francisco Luque S{\'a}nchez and Siham Tabik and Luigi Troiano and Roberto Tagliaferri and Francisco Herrera},
	archivePrefix={arXiv},
	year={2019},
	eprint={1907.12740}
}

@article{Cho2015unsupervised,
  title={Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals},
  author={Cho, Minsu and Kwak, Suha and Schmid, Cordelia and Ponce, Jean},
  journal={CoRR},
%   volume={abs/1501.06170},
  archivePrefix = {arXiv},
  eprint = {1501.06170},
  year={2015}
}

@inproceedings{Chung2015,
abstract = {In this paper, we explore the inclusion of latent random variables into the dynamic hidden state of a recurrent neural network (RNN) by combining elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamic hidden state.},
archivePrefix = {arXiv},
author = {Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1506.02216},
issn = {10495258},
month = jun,
title = {{A Recurrent Latent Variable Model for Sequential Data}},
url = {http://arxiv.org/abs/1506.02216},
year = {2015}
}

@article{Clevert2015elu,
  title={Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)},
  author={Djork-Arn{\'e} Clevert and Thomas Unterthiner and Sepp Hochreiter},
  journal={CoRR},
  year={2015},
%   volume={abs/1511.07289}
  archivePrefix = {arXiv},
eprint = {1511.07289},
  
}

@inproceedings{Cohen2016group,
  title={Group Equivariant Convolutional Networks},
  author={Cohen, Taco and Welling, Max},
  booktitle={International Conference on Machine Learning},
  pages={2990--2999},
  year={2016}
}

@inproceedings{Cohen2016steerable,
  title={Steerable CNNs},
  author={Cohen, Taco and Welling, Max},
  booktitle={International Conference on Representation Learning},
  year={2017}
}

@article{Cremer2017reinterpreting,
	title={Reinterpreting Importance-Weighted Autoencoders},
	author={Cremer, Chris and Morris, Quaid and Duvenaud, David},
	journal={CoRR},
	archivePrefix = {arXiv},
	eprint = {1704.02916},
	year={2017}
}

@article{Danesh2019deep,
author = {Rasouli Danesh, Maryam and Yadav, Srishti and Herath, Sachini and Vaghei, Yasaman and Payandeh, Shahram},
year = {2019},
month = {02},
pages = {750},
title = {Deep Attention Models for Human Tracking Using RGBD},
volume = {19},
journal = {Sensors},
}

@article{Dayan1995helmholtz,
  title={The {Helmholtz} machine},
  author={Dayan, Peter and Hinton, Geoffrey E and Neal, Radford M and Zemel, Richard S},
  journal={Neural computation},
  volume={7},
  number={5},
  pages={889--904},
  year={1995},
  publisher={MIT Press}
}

@book{Dayan2001,
abstract = {Annotation Theoretical neuroscience provides a quantitative basis for describing what nervous systems do, determining how they function, and uncovering the general principles by which they operate. This text introduces the basic mathematical and computational methods of theoretical neuroscience and presents applications in a variety of areas including vision, sensory-motor integration, development, learning, and memory. The book is divided into three parts. Part I discusses the relationship between sensory stimuli and neural responses, focusing on the representation of information by the spiking activity of neurons. Part II discusses the modeling of neurons and neural circuits on the basis of cellular and synaptic biophysics. Part III analyzes the role of plasticity in development and learning. An appendix covers the mathematical methods used, and exercises are available on the book's Web site. Neural encoding I: firing rates and spike statistics -- Neural encoding II: reverse correlation and visual receptive fields -- Neural decoding -- Information theory -- Model neurons I: neuroelectronics -- Model neurons II: conductances and morphology -- Network models -- Plasticity and learning -- Classical conditioning and reinforcement learning -- Representational learning -- Mathematical appendix.},
author = {Dayan, Peter. and Abbott, L. F.},
optisbn = {9780262041997},
pages = {460},
publisher = {Massachusetts Institute of Technology Press},
title = {{Theoretical neuroscience : computational and mathematical modeling of neural systems}},
year = {2001}
}

@article{Dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the royal statistical society. Series B (methodological)},
  pages={1--38},
  year={1977},
  publisher={JSTOR}
}

@inproceedings{Denton2017unsupervised,
  title={Unsupervised learning of disentangled representations from video},
  author={Denton, Emily and Birodkar, Vighnesh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4417--4426},
  year={2017}
}

@article{Dronedataset,
  author    = {A. Robicquet and
               A. Sadeghian and
               A. Alahi and
               S. Savaresei},
  title     = { Learning Social Etiquette: Human Trajectory Prediction In Crowded Scenes},
  journal   = {European Conference on Computer Vision},
  year      = {2016},
}

@inproceedings{Duarte,
  title={Videocapsulenet: A simplified network for action detection},
  author={Duarte, Kevin and Rawat, Yogesh and Shah, Mubarak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7610--7619},
  year={2018}
}

@article{Earley1970efficient,
  title={An efficient context-free parsing algorithm},
  author={Earley, Jay},
  journal={Communications of the ACM},
  volume={13},
  number={2},
  pages={94--102},
  year={1970},
  publisher={ACM}
}

@inproceedings{Eslami2016air,
abstract = {We present a framework for efficient inference in structured image models that explicitly reason about objects. We achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time. Crucially, the model itself learns to choose the appropriate number of inference steps. We use this scheme to learn to perform inference in partially specified 2D models (variable-sized variational auto-encoders) and fully specified 3D models (probabilistic renderers). We show that such models learn to identify multiple objects - counting, locating and classifying the elements of a scene - without any supervision, e.g., decomposing 3D images with various numbers of objects in a single forward pass of a neural network. We further show that the networks produce accurate inferences when compared to supervised counterparts, and that their structure leads to improved generalization.},
archivePrefix = {arXiv},
author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1603.08575},
optissn = {10495258},
title = {{Attend, Infer, Repeat: Fast Scene Understanding with Generative Models}},
year = {2016}
}

@inproceedings{Pellegrini2009eth,
  title={You'll never walk alone: Modeling social behavior for multi-target tracking},
  author={Pellegrini, Stefano and Ess, Andreas and Schindler, Konrad and Van Gool, Luc},
  booktitle={IEEE International Conference on Computer Vision},
  year={2009}
}

@article{Fort2017mcmc,
  title={MCMC design-based non-parametric regression for rare event. Application to nested risk computations},
  author={Fort, Gersende and Gobet, Emmanuel and Moulines, Eric},
  journal={Monte Carlo Methods and Applications},
  volume={23},
  number={1},
  pages={21--42},
  year={2017}
}

@inproceedings{Gael2009,
abstract = {We introduce a new probability distribution over a potentially infinite number of binary Markov chains which we call the Markov Indian buffet process. This process extends the IBP to allow temporal dependencies in the hidden variables. We use this stochastic process to build a nonparametric extension of the factorial hidden Markov model. After constructing an inference scheme which combines slice sampling and dynamic programming we demonstrate how the infinite factorial hidden Markov model can be used for blind source separation.},
author = {Gael, Jurgen Van and Teh, Yee Whye and Ghahramani, Zoubin},
booktitle = {Advances in Neural Information Processing Systems},
file = {:Users/adam/Documents/Mendeley/Gael, Teh, Ghahramani - 2009 - The Infinite Factorial Hidden Markov Model.pdf:pdf},
isbn = {9781605609492},
pages = {1697--1704},
title = {{The Infinite Factorial Hidden Markov Model}},
url = {https://papers.Advances in Neural Information Processing Systems.cc/paper/3518-the-infinite-factorial-hidden-markov-model},
year = {2009}
}

@article{Radford2016gan,
  title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={International Conference on Learning Representations},
  year={2016}
}

@article{Geiger2013,
abstract = {Abstract We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10–100 Hz using a variety of sensor modalities such as high-resolution color and ...},
author = {Geiger, A. and Lenz, P. and Stiller, C. and Urtasun, R.},
optdoi = {10.1177/0278364913491297},
optissn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {Benchmarks,Dataset,GPS,KITTI,SLAM,Stereo,autonomous driving,cameras,computer vision,field robotics,laser,mobile robotics,object detection,optical flow,tracking},
month = {sep},
number = {11},
pages = {1231--1237},
publisher = {SAGE PublicationsSage UK: London, England},
title = {{Vision meets robotics: The KITTI dataset}},
opturl = {http://ijr.sagepub.com/cgi/optdoi/10.1177/0278364913491297},
volume = {32},
year = {2013}
}

@inproceedings{Goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@inproceedings{Gordon2018re3,
abstract = {Robust object tracking requires knowledge and understanding of the object being tracked: its appearance, its motion, and how it changes over time. A tracker must be able to modify its underlying model and adapt to new observations. We present Re3, a real-time deep object tracker capable of incorporating long-term temporal information into its model. In line with other recent deep learning techniques, we do not train an online tracker. Instead, we use a recurrent neural network to represent the appearance and motion of the object. We train the network offline to learn how an object's appearance and motion may change, letting it track with a single forward pass at test time. This lightweight model is capable of tracking objects at 150 FPS, while attaining competitive results on challenging benchmarks. We also show that our method handles temporary occlusion better than other comparable trackers using experiments that directly measure performance on sequences with occlusion.},
archivePrefix = {arXiv},
author = {Gordon, Daniel and Farhadi, Ali and Fox, Dieter},
booktitle = {CoRR},
eprint = {1705.06368},
title = {{Re3 : Real-Time Recurrent Regression Networks for Object Tracking}},
year = {2017}
}


@inproceedings{Grathwohl2018backpropagation,
  title        = {Backpropagation through the Void: Optimizing control variates for black-box gradient estimation},
  author       = {Will Grathwohl and Dami Choi and Yuhuai Wu and Geoff Roeder and David Duvenaud},
  booktitle    = {International Conference on Learning Representations},
  year         = 2018
}

@article{Graves2014neural,
  title={Neural {T}uring machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint = {1410.5401},
  year={2014}
}

@inproceedings{Graves2014recurrent,
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for optdoing so.},
archivePrefix = {arXiv},
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
booktitle = {Advances in Neural Information Processing Systems},
optdoi = {ng},
eprint = {1406.6247},
optisbn = {078036404X},
optissn = {0157244X},
title = {{Recurrent Models of Visual Attention}},
year = {2014}
}

@article{Graves2016dnc,
abstract = {Artificial neural networks are remarkably adept at sensory processing, sequence learning and reinforcement learning, but are limited in their ability to represent variables and data structures and to store data over long timescales, owing to the lack of an external memory. Here we introduce a machine learning model called a differentiable neural computer (DNC), which consists of a neural network that can read from and write to an external memory matrix, analogous to the random-access memory in a conventional computer. Like a conventional computer, it can use its memory to represent and manipulate complex data structures, but, like a neural network, it can learn to do so from data. When trained with supervised learning, we demonstrate that a DNC can successfully answer synthetic questions designed to emulate reasoning and inference problems in natural language. We show that it can learn tasks such as finding the shortest path between specified points and inferring the missing links in randomly generated graphs, and then generalize these tasks to specific graphs such as transport networks and family trees. When trained with reinforcement learning, a DNC can complete a moving blocks puzzle in which changing goals are specified by sequences of symbols. Taken together, our results demonstrate that DNCs have the capacity to solve complex, structured tasks that are inaccessible to neural networks without external read–write memory.},
author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'{n}}ska, Agnieszka and Colmenarejo, Sergio G{\'{o}}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
optissn = {0028-0836},
journal = {Nature},
month = {oct},
number = {7626},
pages = {471--476},
publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
title = {{Hybrid computing using a neural network with dynamic external memory}},
opturl = {http://dx.optdoi.org/10.1038/nature20101 http://10.0.4.14/nature20101 http://www.nature.com/nature/journal/v538/n7626/abs/nature20101.html{\#}supplementary-information},
volume = {538},
year = {2016}
}


@inproceedings{Grefenstette2015learning,
  title={Learning to transduce with unbounded memory},
  author={Grefenstette, Edward and Hermann, Karl Moritz and Suleyman, Mustafa and Blunsom, Phil},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1828--1836},
  year={2015}
}

@inproceedings{Greff2016tagger,
  title={Tagger: Deep Unsupervised Perceptual Grouping},
  author={Klaus Greff and Antti Rasmus and Mathias Berglund and Tele Hotloo Hao and Harri Valpola and J{\"u}rgen Schmidhuber},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{Greff2017neuralem,
  title={Neural Expectation Maximization},
  author={Klaus Greff and Sjoerd van Steenkiste and J{\"u}rgen Schmidhuber},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{Greff2019multi,
  title={Multi-Object Representation Learning with Iterative Variational Inference},
  author={Greff, Klaus and Kaufmann, Rapha{\"e}l Lopez and Kabra, Rishab and Watters, Nick and Burgess, Chris and Zoran, Daniel and Matthey, Loic and Botvinick, Matthew and Lerchner, Alexander},
  journal={CoRR},
  	archivePrefix = {arXiv},
  eprint = {1903.00450},
  year={2019}
}

@inproceedings{Gregor2016towards,
	title={Towards conceptual compression},
	author={Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
	booktitle={Advances in Neural Information Processing Systems},
	year={2016}
}

@inproceedings{Gu2016muprop,
  title={MuProp: Unbiased backpropagation for stochastic neural networks},
  author={Gu, Shixiang and Levine, Sergey and Sutskever, Ilya and Mnih, Andriy},
  booktitle    = {International Conference on Learning Representations},
  year         = 2016
}

@article{Gulrajani2016pixelvae,
  title={Pixelvae: A latent variable model for natural images},
  author={Gulrajani, Ishaan and Kumar, Kundan and Ahmed, Faruk and Taiga, Adrien Ali and Visin, Francesco and Vazquez, David and Courville, Aaron},
  journal={CoRR},
    archivePrefix = {arXiv},
eprint = {1611.05013},
  year={2016}
}

@inproceedings{Gutmann2010nce,
  title={Noise-contrastive Estimation: A New Estimation Principle for Unnormalized Statistical Models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={297--304},
  year={2010}
}

@inproceedings{Gupta2019social,
	author    = {Agrim Gupta and
	Justin Johnson and
	Li Fei{-}Fei and
	Silvio Savarese and
	Alexandre Alahi},
	title     = {Social {GAN:} Socially Acceptable Trajectories with Generative Adversarial
	Networks},
	booktitle   = {IEEE Conference on Computer Vision and Pattern Recognition},
	year      = {2018},
}

@article{Ha2018worldm,
  title={World Models},
  author={David Ha and J{\"u}rgen Schmidhuber},
  journal={CoRR},
  year={2018},
%   volume={abs/1803.10122}
    archivePrefix = {arXiv},
eprint = {1603.10122},
}

@article{He2017maskrcnn,
	title={Mask R-CNN},
	author={Kaiming He and Georgia Gkioxari and Piotr Doll{\'a}r and Ross B. Girshick},
	journal={IEEE Transactions n Pattern Analysis and Machine Intelligence},
	year={2017}
}

@inproceedings{Held2016goturn,
abstract = {Machine learning techniques are often used in computer vision due to their ability to leverage large amounts of training data to improve performance. Unfortunately, most generic object trackers are still trained from scratch online and do not benefit from the large number of videos that are readily available for offline training. We propose a method for using neural networks to track generic objects in a way that allows them to improve performance by training on labeled videos. Previous attempts to use neural networks for tracking are very slow to run and not practical for real-time applications. In contrast, our tracker uses a simple feed-forward network with no online training required, allowing our tracker to run at 100 fps during test time. Our tracker trains from both labeled video as well as a large collection of images, which helps prevent overfitting. The tracker learns generic object motion and can be used to track novel objects that do not appear in the training set. We test our network on a standard tracking benchmark to demonstrate our tracker's state-of-the-art performance. Our network learns to track generic objects in real-time as they move throughout the world.},
archivePrefix = {arXiv},
author = {Held, David and Thrun, Sebastian and Savarese, Silvio},
booktitle = {European Conference on Computer Vision Workshop},
optdoi = {10.1007/978-3-319-46448-0_45},
eprint = {1604.01802},
optisbn = {9783319464473},
optissn = {16113349},
keywords = {Deep learning,Machine learning,Neural networks,Tracking},
organization = {Springer},
pmid = {4520227},
title = {{Learning to track at 100 FPS with deep regression networks}},
year = {2016}
}

@phdthesis{Hesterberg1988advances,
	title={Advances in importance sampling},
	author={Hesterberg, Timothy Classen},
	year={1988},
	school={Stanford University}
}

@article{Hesterberg1995weighted,
  title={Weighted average importance sampling and defensive mixture distributions},
  author={Hesterberg, Tim},
  journal={Technometrics},
  volume={37},
  number={2},
  pages={185--194},
  year={1995},
  publisher={Taylor \& Francis}
}


@article{Hinton79,
	author = 	 {Hinton, G. E.},
	title = 	 {Some Demonstrations of the Effects of Structural Descriptions in Mental Imagery},
	journal =  {Cognitive Science},
	year = 	 {1979},
	volume = 	 {3},
	pages = 	 {231--250},
}

@inproceedings{Hinton1994autoencoders,
	title={Autoencoders, minimum description length and Helmholtz free energy},
	author={Hinton, Geoffrey E and Zemel, Richard S},
	booktitle={Advances in Neural Information Processing Systems},
	year={1994}
}

@article{Hinton1995wake,
	title={The" wake-sleep" algorithm for unsupervised neural networks},
	author={Hinton, Geoffrey E and Dayan, Peter and Frey, Brendan J and Neal, Radford M},
	journal={Science},
	volume={268},
	number={5214},
	pages={1158--1161},
	year={1995},
	publisher={American Association for the Advancement of Science}
}

@inproceedings{Hinton2011tae,
  title={Transforming Auto-Encoders},
  author = {Hinton, G. E. and Krizhevsky, A. and Wang, S. D.},
  booktitle={International Conference on Artifical Neural Networks},
  year={2011}
}


@inproceedings{Hinton2018capsule,
  title={Matrix Capsules with EM routing},
  author={Hinton, G. E. and Sabour, Sara and Frosst, Nick},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{Hjelm2019deepinfomax,
  title={Learning Deep Representations by Mutual Information Estimation and Maximization},
  author={R. Devon Hjelm and Alex Fedorov and Samuel Lavoie-Marchildon and Karan Grewal and Adam Trischler and Yoshua Bengio},  
  journal={CoRR},
  archivePrefix = {arXiv},
  year={2019},
  eprint={1808.06670}
}

@inproceedings{Hsieh2018ddpae,
  title={Learning to Decompose and Disentangle Representations for Video Prediction},
  author={Jun-Ting Hsieh and Bingbin Liu and De-An Huang and Li Fei-Fei and Juan Carlos Niebles},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018},
}

@article{Ji2018iic,
  author    = {Xu Ji and
              Jo{\~{a}}o F. Henriques and
              Andrea Vedaldi},
  title     = {Invariant Information Distillation for Unsupervised Image Segmentation
              and Clustering},
  journal   = {CoRR},
%   volume    = {abs/1807.06653},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.06653},
  archivePrefix = {arXiv},
  eprint    = {1807.06653},
%   timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},
%   biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-06653},
%   bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Ilin2017recurrentln,
  title={Recurrent Ladder Networks},
  author={Alexander Ilin and Isabeau Pr{\'e}mont-Schwarz and Tele Hotloo Hao and Antti Rasmus and Rinu Boney and Harri Valpola},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{Hu2017imsat,
  title={Learning Discrete Representations via Information Maximizing Self-augmented Training},
  author={Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},
  booktitle={International Conference on Machine Learning},
  pages={1558--1567},
  year={2017},
%   organization={JMLR. org}
}

@misc{Itseez2015opencv,
  title={Open Source Computer Vision Library},
  author={Itseez},
  year={2015},
  howpublished = {\url{https://github.com/itseez/opencv}}
}

@inproceedings{Jacobsen2016struc,
abstract = {Learning powerful feature representations with CNNs is hard when training data are limited. Pre-training is one way to overcome this, but it requires large datasets suffi-ciently similar to the target domain. Another option is to de-sign priors into the model, which can range from tuned hy-perparameters to fully engineered representations like Scat-tering Networks. We combine these ideas into structured receptive field networks, a model which has a fixed filter basis and yet retains the flexibility of CNNs. This flexibil-ity is achieved by expressing receptive fields in CNNs as a weighted sum over a fixed basis which is similar in spirit to Scattering Networks. The key difference is that we learn arbitrary effective filter sets from the basis rather than mod-eling the filters. This approach explicitly connects clas-sical multiscale image analysis with general CNNs. With structured receptive field networks, we improve consider-ably over unstructured CNNs for small and medium dataset scenarios as well as over Scattering for large datasets. We validate our findings on ILSVRC2012, Cifar-10, Cifar-100 and MNIST. As a realistic small dataset example, we show state-of-the-art classification results on popular 3D MRI brain-disease datasets where pre-training is difficult due to a lack of large public datasets in a similar domain.},
author = {Jacobsen, J{\"{o}}rn-Henrik and {Van Gemert}, Jan and Lou, Zhongyou and Smeulders, Arnold W M},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
file = {:Users/adam/Documents/Mendeley/Jacobsen et al. - 2016 - Structured Receptive Fields in CNNs.pdf:pdf},
title = {{Structured Receptive Fields in CNNs}},
url = {https://www.cv-foundation.org/openaccess/content{\_}IEEE Conference on Computer Vision and Pattern Recognition{\_}2016/papers/Jacobsen{\_}Structured{\_}Receptive{\_}Fields{\_}IEEE Conference on Computer Vision and Pattern Recognition{\_}2016{\_}paper.pdf},
year = {2016}
}

@article{Jacobsen2017dynamic,
  title={Dynamic steerable blocks in deep residual networks},
  author={Jacobsen, J{\"o}rn-Henrik and De Brabandere, Bert and Smeulders, Arnold WM},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint={1706.00598},
  year={2017}
}

@inproceedings{Jaderberg2015,
abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
archivePrefix = {arXiv},
author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
booktitle = {Advances in Neural Information Processing Systems},
optdoi = {10.1038/nbt.3343},
eprint = {1506.02025v1},
optisbn = {9781627480031},
optissn = {1087-0156},
pmid = {26571099},
title = {{Spatial Transformer Networks}},
year = {2015}
}

@inproceedings{Jaderberg2016,
abstract = {Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880$\backslash${\%} expert human performance, and a challenging suite of first-person, three-dimensional $\backslash$emph{\{}Labyrinth{\}} tasks leading to a mean speedup in learning of 10{\$}\backslashtimes{\$} and averaging 87$\backslash${\%} expert human performance on Labyrinth.},
archivePrefix = {arXiv},
author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
booktitle = {arXiv:1611.05397},
optdoi = {10.1051/0004-6361/201527329},
eprint = {1611.05397},
file = {:Users/adam/Documents/Mendeley/Jaderberg et al. - 2016 - Reinforcement Learning with Unsupervised Auxiliary Tasks.pdf:pdf},
optisbn = {2004012439},
optissn = {0004-6361},
pmid = {23459267},
title = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},
opturl = {http://arxiv.org/abs/1611.05397},
year = {2016}
}

@inproceedings{Jaiswal2018capsule,
  title={Capsulegan: Generative adversarial capsule network},
  author={Jaiswal, Ayush and AbdAlmageed, Wael and Wu, Yue and Natarajan, Premkumar},
  booktitle={European Conference on Computer Vision},
  year={2018}
}

@inproceedings{Jang2017categorical,
  title        = {Categorical Reparameterization with {G}umbel-Softmax},
  author       = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle    = {International Conference §on Learning Representations},
  year         = 2017
}


@article{Ji2018iic,
	author    = {Xu Ji and
	Jo{\~{a}}o F. Henriques and
	Andrea Vedaldi},
	title     = {Invariant Information Distillation for Unsupervised Image Segmentation
	and Clustering},
	journal   = {CoRR},
	year      = {2018},
	url       = {http://arxiv.org/abs/1807.06653},
	archivePrefix = {arXiv},
	eprint    = {1807.06653},
}

@article{Juang1991hidden,
  title={Hidden Markov models for speech recognition},
  author={Juang, Biing Hwang and Rabiner, Laurence R},
  journal={Technometrics},
  volume={33},
  number={3},
  pages={251--272},
  year={1991},
  publisher={Taylor \& Francis}
}

@article{Kahou2015ratm,
abstract = {This work presents an attention mechanism-based neural network approach for tracking objects in video. A recurrent neural network is trained to predict the position of an object at time t + 1 given a series of selective glimpses into video frames at time steps 1 to t. The proposed recurrent attentive tracking model can be trained using simple gradient-based training. Various settings are explored in experiments on artificial data to justify design choices.},
archivePrefix = {arXiv},
author = {Kaho{\'{u}}, Samira Ebrahimi and Michalski, Vincent and Memisevic, Roland},
eprint = {1510.08660},
journal = {IEEE Conference on Computer Vision and Pattern Recognition Workshop},
keywords = {Attention Model},
title = {{RATM: Recurrent Attentive Tracking Model}},
opturl = {http://arxiv.org/pdf/1510.08660v3.pdf},
year = {2017}
}

@inproceedings{Karl2017dvbf,
abstract = {We introduce Deep Variational Bayes Filters (DVBF), a new methhttps://arxiv.org/pdf/1605.06432.pdfod for unsupervised learning of latent Markovian state space models. Leveraging recent advances in Stochastic Gradient Variational Bayes, DVBF can overcome intractable inference distributions by means of variational inference. Thus, it can handle highly nonlinear input data with temporal and spatial dependencies such as image sequences without domain knowledge. Our experiments show that enabling backpropagation through transitions enforces state space assumptions and significantly improves information content of the latent embedding. This also enables realistic long-term prediction.},
archivePrefix = {arXiv},
author = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},
booktitle = {International Conference on Learning Representations},
eprint = {1605.06432},
file = {:Users/adam/Documents/Mendeley/Karl et al. - 2017 - Deep Variational Bayes Filters Unsupervised Learning of State Space Models from Raw Data.pdf:pdf},
title = {{Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}},
opturl = {http://arxiv.org/abs/1605.06432 https://arxiv.org/pdf/1605.06432.pdf},
year = {2017}
}

@inproceedings{Kemp2006learning,
  title={Learning systems of concepts with an infinite relational model},
  author={Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, Takeshi and Ueda, Naonori},
  year={2006}
}

@article{Kemp2008discovery,
  title={The discovery of structural form},
  author={Kemp, Charles and Tenenbaum, Joshua B},
  journal={Proceedings of the National Academy of Sciences},
  volume={105},
  number={31},
  pages={10687--10692},
  year={2008},
  publisher={National Acad Sciences}
}

@article{Kendall2017adaptive,
abstract = {Numerous deep learning applications benefit from multi-task learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task's loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.},
archivePrefix = {arXiv},
author = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
eprint = {1705.07115},
journal = {arXiv:1705.07115},
month = {may},
title = {{Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics}},
opturl = {http://arxiv.org/abs/1705.07115},
year = {2017}
}

@article{Keuper2018motion,
  title={Motion segmentation \& multiple object tracking by correlation co-clustering},
  author={Keuper, Margret and Tang, Siyu and Andres, Bjorn and Brox, Thomas and Schiele, Bernt},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2018},
  publisher={IEEE}
}

@inproceedings{Kim2018disentangling,
  title={Disentangling by factorising},
  author={Kim, Hyunjik and Mnih, Andriy},
  booktitle={International Conference on Machine Learning},
    archivePrefix = {arXiv},
eprint = {1802.05983},
  year={2018}
}

@article{Kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={CoRR},
      archivePrefix = {arXiv},
  eprint = {1412.6980},
  year={2014}
}

@inproceedings{Kingma2014auto,
  title={Auto-encoding variational {Bayes}},
  author={Kingma, Diederik P and Welling, Max},
  year = {2014},
  booktitle = {International Conference on Learning Representations}
}

@article{Kingma2015adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={International Conference on Learning Representations},
  year={2015},
%   volume={abs/1412.6980}
    archivePrefix = {arXiv},
eprint = {1412.6980},
}

@article{Kingma2016improving,
  title={Improving variational inference with inverse autoregressive flow},
  author={Kingma, Diederik P and Salimans, Tim and Welling, Max},
  journal={CoRR},
        archivePrefix = {arXiv},
  eprint = {1606.04934},
  year={2016}
}

@inproceedings{Klein2003parsing,
  title={A parsing: fast exact Viterbi parse selection},
  author={Klein, Dan and Manning, Christopher D},
  booktitle={Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1},
  pages={40--47},
  year={2003},
  organization={Association for Computational Linguistics}
}

@article{Kocvok2016cyclic,
  title={Exploiting Cyclic Symmetry in Convolutional Neural Networks},
  author={Dieleman, Sander and De Fauw, Jeffrey and Kavukcuoglu, Koray},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint = {1602.02660},
  year={2016}
}

@inproceedings{Kosiorek2017hierch,
abstract = {Class-agnostic object tracking is particularly difficult in cluttered environments as target specific discriminative models cannot be learned a priori. Inspired by how the human visual cortex employs spatial attention and separate "where" and "what" processing pathways to actively suppress irrelevant visual features, this work develops a hierarchical attentive recurrent model for single object tracking in videos. The first layer of attention discards the majority of background by selecting a region containing the object of interest, while the subsequent layers tune in on visual features particular to the tracked object. This framework is fully differentiable and can be trained in a purely data driven fashion by gradient methods. To improve training convergence, we augment the loss function with terms for a number of auxiliary tasks relevant for tracking. Evaluation of the proposed model is performed on two datasets of increasing difficulty: pedestrian tracking on the KTH activity recognition dataset and the KITTI object tracking dataset.},
archivePrefix = {arXiv},
author = {Kosiorek, Adam R. and Bewley, Alex and Posner, Ingmar},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1706.09262},
month = jun,
title = {{Hierarchical Attentive Recurrent Tracking}},
url = {http://arxiv.org/abs/1706.09262},
year = {2017}
}

@inproceedings{Kosiorek2018sqair,
  title={Sequential Attend, Infer, Repeat: Generative modelling of moving objects},
  author={Kosiorek, Adam and Kim, Hyunjik and Teh, Yee Whye and Posner, Ingmar},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8606--8616},
  archivePrefix = {arXiv},
  eprint = {1806.01794},
  year={2018}
}

@inproceedings{Krizhevsky2012,
author = {{A. Krizhevsky} and {I. Sutskever} and Hinton, Geoffrey E.},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1097--1105},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
opturl = {https://papers.Advances in Neural Information Processing Systems.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks},
year = {2012}
}

@inproceedings{Krueger2016,
abstract = {We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find that zoneout gives significant performance improvements across tasks. We achieve competitive results with relatively simple models in character- and word-level language modelling on the Penn Treebank and Text8 datasets, and combining with recurrent batch normalization yields state-of-the-art results on permuted sequential MNIST.},
archivePrefix = {arXiv},
author = {Krueger, David and Maharaj, Tegan and Kram{\'{a}}r, J{\'{a}}nos and Pezeshki, Mohammad and Ballas, Nicolas and Ke, Nan Rosemary and Goyal, Anirudh and Bengio, Yoshua and Courville, Aaron and Pal, Chris},
booktitle = {International Conference on Learning Representations},
eprint = {1606.01305},
title = {{Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations}},
opturl = {http://arxiv.org/abs/1606.01305},
year = {2017}
}

@article{Kuhn1955hungarian,
  title={The Hungarian Method for the Assignment Problem},
  author={Kuhn, Harold W},
  journal={Naval Research Logistics Quarterly},
%   volume={2},
%   number={1-2},
  pages={83--97},
  year={1955},
  publisher={Wiley Online Library}
}

@inproceedings{Kwak2015unsupervised,
  title={Unsupervised object discovery and tracking in video collections},
  author={Kwak, Suha and Cho, Minsu and Laptev, Ivan and Ponce, Jean and Schmid, Cordelia},
  booktitle={IEEE International Conference on Computer Vision},
  pages={3173--3181},
  year={2015},
  organization={IEEE}
}

@article{Lake2018emergence,
  title={The Emergence of Organizing Structure in Conceptual Representation},
  author={Lake, Brenden M and Lawrence, Neil D and Tenenbaum, Joshua B},
  journal={Cognitive science},
  publisher={Wiley Online Library},
  year={2018}
}

@article{Lalonde2018capsule,
  title={Capsules for object segmentation},
  author={LaLonde, Rodney and Bagci, Ulas},
  journal={arXiv preprint arXiv:1804.04241},
  year={2018}
}

@inproceedings{Lambert2017cows,
	title={Function and flexibility of object exploration in kea and New Caledonian crows},
	author={Megan L Lambert and Martina Schiestl and Raoul Schwing and Alex H Taylor and Gyula K. Gajdon and Katie E Slocombe and Amanda M. Seed},
	booktitle={Royal Society Open Science},
	year={2017},
	doi={10.1098/rsos.170652}
}

@article{Lari1990estimation,
  title={The estimation of stochastic context-free grammars using the inside-outside algorithm},
  author={Lari, Karim and Young, Steve J},
  journal={Computer speech \& language},
  volume={4},
  number={1},
  pages={35--56},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{Le2017inference,
  title={Inference Compilation and Universal Probabilistic Programming},
  author={Le, Tuan Anh and Baydin, Atilim Gunes and Wood, Frank},
  booktitle={AISTATS},
  year={2017}
}

@inproceedings{Le2018autoencoding,
  title = {Auto-Encoding Sequential {M}onte {C}arlo},
  author = {Le, Tuan Anh and Igl, Maximilian and Rainforth, Tom and Jin, Tom and Wood, Frank},
  booktitle = {International Conference on Learning Representations},
  year = {2018}
}

@article{Lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{Lecun1998gradient,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={1998},
	publisher={IEEE}
}

@article{Lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{Lee2019set,
  title={Set Transformer},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam R and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  eprint={1810.00825},
  archivePrefix = {arXiv},
  year={2019},
}


@inproceedings{Lenssen2018group,
  title={Group Equivariant Capsule Networks},
  author={Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8844--8853},
  year={2018}
}

@inproceedings{Li2016renyi,
  title={R{\'e}nyi divergence variational inference},
  author={Li, Yingzhen and Turner, Richard E},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@article{Li2018encapsule,
	author    = {Hongyang Li and
	Xiaoyang Guo and
	Bo Dai and
	Wanli Ouyang and
	Xiaogang Wang},
	title     = {Neural Network Encapsulation},
	journal   = {CoRR},
	year      = {2018},
	archivePrefix = {arXiv},
	eprint    = {1808.03749},
}

@article{Liu2018deepod,
	title={Deep Learning for Generic Object Detection: A Survey},
	author={Li Liu and Wanli Ouyang and Xiaogang Wang and Paul W. Fieguth and Jie Chen and Xinwang Liu and Matti Pietik{\"a}inen},
	journal={International Journal of Computer Vision},
	year={2018},
	pages={1 - 58}
}

@inproceedings{Maddison2017concrete,
  title        = {The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
  author       = {Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  booktitle    = {International Conference on Learning Representations},
  year         = 2017
}

@article{Maddison2017filtering,
  title={Filtering Variational Objectives},
  author={Maddison, Chris J and Lawson, Dieterich and Tucker, George and Heess, Nicolas and Norouzi, Mohammad and Mnih, Andriy and Doucet, Arnaud and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1705.09279},
  year={2017}
}

@inproceedings{Malinowski2015vqn,
	title={Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images},
	author={Mateusz Malinowski and Marcus Rohrbach and Mario Fritz},
	booktitle={IEEE International Conference on Computer Vision},
	year={2015}
}

@inproceedings{Mallat,
  title={Deep Roto-Translation Scattering for Object Classification},
  author={Oyallon, Edouard and Mallat, St{\'e}phane},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2865--2873},
  year={2015}
}

@book{Manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher D and Manning, Christopher D and Sch{\"u}tze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@book{Mcbook,
	author = {Art B. Owen},
	year = 2013,
	title = {Monte Carlo theory, methods and examples}
}

@article{Milan2014,
author = {Milan, Anton and Roth, Stefan and Schindler, Konrad},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Continuous optimization,Multiobject tracking,Tracking-by-detection,Visual surveillance},
title = {{Continuous energy minimization for multitarget tracking}},
year = {2014}
}

@techreport{Minka2005divergence,
  title = {Divergence measures and message passing},
  author = {Minka, Tom},
  year = {2005},
  institution = {Technical report, Microsoft Research}
}

@article{Mnih2013dqn,
	title={Playing Atari with Deep Reinforcement Learning},
	author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
	archivePrefix={ArXiv},
	year={2013},
	eprint={1312.5602}
}

@inproceedings{Mnih2014,
abstract = {Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference model gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.},
archivePrefix = {arXiv},
eprint = {1402.0030v2},
author = {Mnih, Andriy and Gregor, Karol},
booktitle = {International Conference on Machine Learning},
eprint = {arXiv:1402.0030v2},
optisbn = {9781634393973},
keywords = {belief networks,deep learning,variational inference},
month = {jan},
title = {{Neural Variational Inference and Learning in Belief Networks}},
opturl = {http://arxiv.org/abs/1402.0030},
year = {2014}
}

@inproceedings{Mnih2016,
abstract = {Recent progress in deep latent variable models has largely been driven by the development of flexible and scalable variational inference methods. Variational training of this type involves maximizing a lower bound on the log-likelihood, using samples from the variational posterior to compute the required gradients. Recently, Burda et al. (2016) have derived a tighter lower bound using a multi-sample importance sampling estimate of the likelihood and showed that optimizing it yields models that use more of their capacity and achieve higher likelihoods. This development showed the importance of such multi-sample objectives and explained the success of several related approaches. We extend the multi-sample approach to discrete latent variables and analyze the difficulty encountered when estimating the gradients involved. We then develop the first unbiased gradient estimator designed for importance-sampled objectives and evaluate it at training generative and structured output prediction models. The resulting estimator, which is based on low-variance per-sample learning signals, is both simpler and more effective than the NVIL estimator proposed for the single-sample variational objective, and is competitive with the currently used biased estimators.},
archivePrefix = {arXiv},
arxivId = {1602.06725},
author = {Mnih, Andriy and Rezende, Danilo J.},
booktitle = {International Conference on Machine Learning},
eprint = {1602.06725},
issn = {1938-7228},
month = feb,
title = {{Variational inference for Monte Carlo objectives}},
url = {http://arxiv.org/abs/1602.06725},
year = {2016}
}

@article{Mohamed2016learning,
  title={Learning in implicit generative models},
  author={Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1610.03483},
  year={2016}
}

@article{Mot16,
	title = {{MOT}16: {A} Benchmark for Multi-Object Tracking},
	shorttitle = {Mot16},
	author = {Milan, A. and Leal-Taix\'{e}, L. and Reid, I. and Roth, S. and Schindler, K.},
	year = {2016},
	note = {arXiv: 1603.00831},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{Naesseth2017variational,
  title={Variational Sequential Monte Carlo},
  author={Naesseth, Christian A and Linderman, Scott W and Ranganath, Rajesh and Blei, David M},
  journal={arXiv preprint arXiv:1705.11140},
  year={2017}
}

@article{Nam2016,
author = {Nam, Hyeonseob and Han, Bohyung},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
title = {{Learning Multi-Domain Convolutional Neural Networks for Visual Tracking}},
year = {2016}
}

@article{Neal1992connectionist,
  title={Connectionist learning of belief networks},
  author={Neal, Radford M},
  journal={Artificial intelligence},
  volume={56},
  number={1},
  pages={71--113},
  year={1992},
  publisher={Elsevier}
}

@article{Neiswanger2012unsupervised,
  title={Unsupervised Detection and Tracking of Arbitrary Objects with Dependent Dirichlet Process Mixtures},
  author={Neiswanger, Willie and Wood, Frank},
  journal={CoRR},
    archivePrefix = {arXiv},
eprint = {1210.3288},
  year={2012}
}

@inproceedings{Neiswanger2014dependent,
  title={The dependent {D}irichlet process mixture of objects for detection-free tracking and object modeling},
  author={Neiswanger, Willie and Wood, Frank and Xing, Eric},
  booktitle={Artificial Intelligence and Statistics},
  pages={660--668},
  year={2014}
}

@article{Ning2016,
abstract = {In this paper, we develop a new approach of spatially supervised recurrent convolutional neural networks for visual object tracking. Our recurrent convolutional network exploits the history of locations as well as the distinctive visual features learned by the deep neural networks. Inspired by recent bounding box regression methods for object detection, we study the regression capability of Long Short-Term Memory (LSTM) in the temporal domain, and propose to concatenate high-level visual features produced by convolutional networks with region information. In contrast to existing deep learning based trackers that use binary classification for region candidates, we use regression for direct prediction of the tracking locations both at the convolutional layer and at the recurrent unit. Our extensive experimental results and performance comparison with state-of-the-art tracking methods on challenging benchmark video tracking datasets shows that our tracker is more accurate and robust while maintaining low computational cost. For most test video sequences, our method achieves the best tracking performance, often outperforms the second best by a large margin.},
archivePrefix = {arXiv},
arxivId = {1607.05781},
author = {Ning, Guanghan and Zhang, Zhi and Huang, Chen and He, Zhihai and Ren, Xiaobo and Wang, Haohong},
eprint = {1607.05781},
journal = {arXiv Prepr. arXiv1607.05781},
title = {{Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking}},
opturl = {http://arxiv.org/abs/1607.05781},
year = {2016}
}

@article{Olshausen2016foveal,
abstract = {We describe a neural attention model with a learnable retinal sampling lattice. The model is trained on a visual search task requiring the classification of an object embedded in a visual scene amidst background distractors using the smallest number of fixations. We explore the tiling properties that emerge in the model's retinal sampling lattice after training. Specifically, we show that this lattice resembles the eccentricity dependent sampling lattice of the primate retina, with a high resolution region in the fovea surrounded by a low resolution periphery. Furthermore, we find conditions where these emergent properties are amplified or eliminated providing clues to their function.},
archivePrefix = {arXiv},
arxivId = {1611.09430},
author = {Cheung, Brian and Weiss, Eric and Olshausen, Bruno},
eprint = {1611.09430},
journal = {International Conference on Learning Representations},
title = {{Emergence of foveal image sampling from learning to attend in visual scenes}},
opturl = {http://arxiv.org/abs/1611.09430},
year = {2017}
}

@inproceedings{Oord2016cond,
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
archivePrefix = {arXiv},
arxivId = {1606.05328},
author = {van den Oord, Aaron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1606.05328},
month = {jun},
title = {{Conditional Image Generation with PixelCNN Decoders}},
url = {http://arxiv.org/abs/1606.05328},
year = {2016}
}

@inproceedings{Osep2017,
author = {O{\v{s}}ep, Aljo{\v{s}}a and Mehner, Wolfgang and Voigtlaender, Paul and Leibe, Bastian},
booktitle = {International Conference on Robotics and Automation},
title = {{Track, then Decide: Category-Agnostic Vision-based Multi-Object Tracking}},
year = {2018}
}

@inproceedings{Paige2016inference,
  title={Inference networks for Sequential {M}onte {C}arlo in graphical models},
  author={Paige, Brooks and Wood, Frank},
  booktitle={International Conference on Machine Learning},
  year={2016}
}

@article{Posner2016,
author = {Peter Ondruska and Ingmar Posner},
journal = {Association for the Advancement of Artificial Intelligence},
keywords = {Technical Papers: Robotics},
title = {{Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks}},
year = {2016}
}

@inproceedings{Rainforth2017opportunities,
	title={On Nesting {M}onte {C}arlo Estimators},
	author={Rainforth, Tom and Cornish, Robert and Yang, Hongseok and Warrington, Andrew and Wood, Frank},
	booktitle={International Conference on Machine Learning},
	year={2018}
}

@phdthesis{Rainforth2017thesis,
	title = {{Automating Inference, Learning, and Design using 
	Probabilistic Programming}},
	author = {Rainforth, Tom},
	institution = {University of Oxford},
	year = {2017}
}

@inproceedings{Rainforth2018tighter,
  title={Tighter Variational Bounds are Not Necessarily Better},
  author={Rainforth, Tom and Kosiorek, Adam R and Le, Tuan Anh and Maddison, Chris J and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{Ranganath2016hierarchical,
  title={Hierarchical variational models},
  author={Ranganath, Rajesh and Tran, Dustin and Blei, David},
  booktitle={International Conference on Machine Learning},
  year={2016}
}

@article{Ranzato2014video,
  title={Video (language) modeling: a baseline for generative models of natural videos},
  author={Ranzato, MarcAurelio and Szlam, Arthur and Bruna, Joan and Mathieu, Michael and Collobert, Ronan and Chopra, Sumit},
  journal={CoRR},
    archivePrefix = {arXiv},
eprint = {1412.6604},
  year={2014}
}

@inproceedings{Rasmus2015ladder,
  title={Semi-supervised Learning with Ladder Networks},
  author={Antti Rasmus and Mathias Berglund and Mikko Honkala and Harri Valpola and Tapani Raiko},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}

@inproceedings{Rasmussen2000infinite,
  title={The infinite {G}aussian mixture model},
  author={Rasmussen, Carl Edward},
  booktitle={Advances in neural information processing systems},
  pages={554--560},
  year={2000}
}

@article{Redmon15,
  author    = {Joseph Redmon and
               Santosh Kumar Divvala and
               Ross B. Girshick and
               Ali Farhadi},
  title     = {You Only Look Once: Unified, Real-Time Object Detection},
  journal   = {IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
}

@inproceedings{Rezende2014stochastic,
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan },
  title = {Stochastic backpropagation and approximate inference in deep generative models},
  booktitle = {International Conference on Machine Learning},
  year = {2014},
}

@inproceedings{Ristani2016performance,
  title={Performance measures and a data set for multi-target, multi-camera tracking},
  author={Ristani, Ergys and Solera, Francesco and Zou, Roger and Cucchiara, Rita and Tomasi, Carlo},
  booktitle={European Conference on Computer Vision},
  pages={17--35},
  year={2016},
  organization={Springer}
}

@article{Robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@inproceedings{Roberts2009signal,
	title={Signal-to-noise ratio analysis of policy gradient algorithms},
	author={Roberts, John W and Tedrake, Russ},
	booktitle={Advances in Neural Information Processing Systems},
	year={2009}
}

@inproceedings{Rolfe2016dvae,
	title={Discrete Variational Autoencoders},
	author={Jason Tyler Rolfe},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{Rudenko2018joint,
  title={Joint long-term prediction of human motion using a planning-based social force approach},
  author={Rudenko, Andrey and Palmieri, Luigi and Arras, Kai O},
  booktitle={2018 IEEE International Conference on Robotics and Automation},
  year={2018},
  organization={IEEE}
}

@inproceedings{Sabour2017capsule,
  title={Dynamic Routing Between Capsules},
  author={Sabour, Sara and Frosst, Nick and Hinton, G. E.},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{Santoro2017,
abstract = {Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Our work shows how a deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations.},
archivePrefix = {arXiv},
arxivId = {1706.01427},
author = {Santoro, Adam and Raposo, David and Barrett, David G.T. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter W and Lillicrap, Timothy},
eprint = {1706.01427},
journal = {Arxiv},
month = {jun},
pages = {1--16},
title = {{A simple neural network module for relational reasoning}},
opturl = {http://arxiv.org/abs/1706.01427 https://arxiv.org/abs/1706.01427},
year = {2017}
}

@article{Saqur2018capsgan,
  title={CapsGAN: Using dynamic routing for generative adversarial networks},
  author={Saqur, Raeid and Vivona, Sal},
  journal={arXiv preprint arXiv:1806.03968},
  year={2018}
}

@inproceedings{Schlichtkrull2017relgraph,
	title={Modeling Relational Data with Graph Convolutional Networks},
	author={Michael Sejr Schlichtkrull and Thomas Kipf and Peter Bloem and Rianne van den Berg and Ivan Titov and Max Welling},
	booktitle={ESWC},
	year={2017}
}

@article{Scholler2019simpler,
  title={The Simpler the Better: Constant Velocity for Pedestrian Motion Prediction},
  author={Sch{\"o}ller, Christoph and Aravantinos, Vincent and Lay, Florian and Knoll, Alois},
  journal={arXiv preprint arXiv:1903.07933},
  year={2019}
}

% old literatures

@inproceedings{Schulter2017deepnf,
  title={Deep Network Flow for Multi-object Tracking},
  author={Samuel Schulter and Paul Vernaza and Wongun Choi and Manmohan Krishna Chandraker},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017},
  pages={2730-2739}
}

@article{Shi2016subpixel,
  title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network},
  author={Wenzhe Shi and Jose Caballero and Ferenc Huszar and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
  journal={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2016},
  pages={1874-1883}
}

@book{Sisson2018handbook,
  title={Handbook of Approximate Bayesian Computation},
  author={Sisson, Scott A and Fan, Yanan and Beaumont, Mark},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@article{Rawlinson2018sparsecaps,
  title={Sparse Unsupervised Capsules Generalize Better},
  author={Rawlinson, David and Ahmed, Abdelrahman and Kowadlo, Gideon},
  journal={CoRR},
  archivePrefix = {arXiv},
  eprint={1804.06094},
  year={2018}
}

@inproceedings{Srivastava2015unsupervised,
  title={Unsupervised Learning of Video Representations using LSTMs.},
  author={Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
  booktitle={International Conference on Machine Learning},
  pages={843--852},
  year={2015}
}

@article{Steenkiste2018,
  author    = {Sjoerd van Steenkiste and
               Michael Chang and
               Klaus Greff and
               J{\"{u}}rgen Schmidhuber},
  title     = {Relational Neural Expectation Maximization: Unsupervised Discovery
               of Objects and their Interactions},
  journal   = {International Conference on Learning Representations},
  year      = {2018},
}


@inproceedings{Stollenga2014,
abstract = {Traditional convolutional neural networks (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNets feedback structure can dynamically alter its convolutional filter sensitivities during classification. It harnesses the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strategies (SNES). On the CIFAR-10 and CIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model.},
archivePrefix = {arXiv},
arxivId = {1407.3068},
author = {Stollenga, Marijn and Masci, Jonathan and Gomez, Faustino and Schmidhuber, Juergen},
booktitle = {arXiv Prepr. arXiv {\ldots}},
eprint = {1407.3068},
optissn = {10495258},
pages = {13},
title = {{Deep Networks with Internal Selective Attention through Feedback Connections}},
opturl = {http://arxiv.org/abs/1407.3068},
year = {2014}
}

@inproceedings{Sun20183dof,
  title={3DOF pedestrian trajectory prediction learned from long-term autonomous mobile robot deployment data},
  author={Sun, Li and Yan, Zhi and Mellado, Sergi Molina and Hanheide, Marc and Duckett, Tom},
  booktitle={2018 IEEE International Conference on Robotics and Automation},
  year={2018},
  organization={IEEE}
}

@misc{Tieleman2012rms,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

@book{Tieleman2014thesis,
  title={Optimizing Neural Networks That Generate Images},
  author={Tieleman, Tijmen},
  year={2014},
  publisher={University of Toronto, Canada}
}

@inproceedings{Tucker2017rebar,
  title        = {REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models},
  author       = {Tucker, George and Mnih, Andriy and Maddison, Chris J and Lawson, John and Sohl-Dickstein, Jascha},
  booktitle    = {Advances in Neural Information Processing Systems},
  pages        = {2624--2633},
  year         = 2017
}

@inproceedings{Tucker2019doubly,
  title        = {Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives},
  author       = {Tucker, George and Lawson, Dieterich and Gu, Shixiang and Maddison, Chris J.},
  booktitle    = {International Conference on Learning Representations},
  year         = 2019
}

@article{Tulyakov2017mocogan,
  title={Mocogan: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  journal={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{Turner2011two,
  title={Two problems with variational expectation maximisation for time-series models},
  author={Turner, Richard E and Sahani, Maneesh},
  journal={Bayesian Time series models},
  pages={115--138},
  year={2011},
  publisher={Cambridge, UK: Cambridge Univ. Press}
}

@inproceedings{Trautman2010unfreezing,
	title={Unfreezing the robot: Navigation in dense, interacting crowds},
	author={Trautman, Peter and Krause, Andreas},
	booktitle={International Conference on Intelligent Robots and Systems},
	year={2010}
}

@inproceedings{Lerner2007crowds,
	title={Crowds by example},
	author={Lerner, Alon and Chrysanthou, Yiorgos and Lischinski, Dani},
	booktitle={Computer Graphics Forum},
	year={2007}
}


@article{Ungerleider2000,
abstract = {A typical scene contains many different objects that, because of $\backslash$nthe limited processing capacity of the visual system, compete for $\backslash$nneural representation. The competition among multiple objects in $\backslash$nvisual cortex can be biased by both bot-tom- up sensory-driven $\backslash$nmechanisms and top-down influences, such as selective atten-tion. $\backslash$nFunctional brain imaging studies reveal that, both in the absence $\backslash$nand in the presence of visual stimulation, biasing signals due to $\backslash$nselective attention can modulate neural activity in visual cortex $\backslash$nin several ways. Although the competition among stimuli for $\backslash$nrepresentation is ultimately resolved within visual cortex, the $\backslash$nsource of top-down biasing signals derives from a network of $\backslash$nareas in frontal and parietal cortex.},
author = {Kastner, Sabine and Ungerleider, Leslie G.},
optdoi = {10.1146/annurev.neuro.23.1.315},
optissn = {0147-006X},
journal = {Annual Review of Neuroscience},
number = {1},
pages = {315--341},
pmid = {10845067},
publisher = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA},
title = {{Mechanisms of visual attention in the human cortex}},
volume = {23},
year = {2000}
}

@article{Upadhyay,
  title={Generative adversarial network architectures for image synthesis using capsule networks},
  author={Upadhyay, Yash and Schrater, Paul},
  journal={arXiv preprint arXiv:1806.03796},
  year={2018}
}

@inproceedings{Vahdat2018dvaehash,
	title={DVAE\#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors},
	author={Arash Vahdat and Evgeny Andriyash and William G. Macready},
	booktitle={Advances in Neural Information Processing Systems},
	year={2018}
}

@inproceedings{Vahdat2018dvaepp,
	title={DVAE++: Discrete Variational Autoencoders with Overlapping Transformations},
	author={Arash Vahdat and William G. Macready and Zhengbing Bian and Amir Khoshaman},
	booktitle={International Conference on Machine Learning},
	year={2018}
}

@inproceedings{Valmadre2017,
abstract = {The Correlation Filter is an algorithm that trains a linear template to discriminate between images and their translations. It is well suited to object tracking because its formulation in the Fourier domain provides a fast solution, enabling the detector to be re-trained once per frame. Previous works that use the Correlation Filter, however, have adopted features that were either manually designed or trained for a different task. This work is the first to overcome this limitation by interpreting the Correlation Filter learner, which has a closed-form solution, as a differentiable layer in a deep neural network. This enables learning deep features that are tightly coupled to the Correlation Filter. Experiments illustrate that our method has the important practical benefit of allowing lightweight architectures to achieve state-of-the-art performance at high framerates.},
archivePrefix = {arXiv},
arxivId = {1704.06036},
author = {Valmadre, Jack and Bertinetto, Luca and Henriques, Jo{\~{a}}o F. and Vedaldi, Andrea and Torr, Philip H. S.},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
eprint = {1704.06036},
title = {{End-to-end representation learning for Correlation Filter based tracking}},
opturl = {http://arxiv.org/abs/1704.06036},
year = {2017}
}

@article{Varshneya2017human,
  title={Human trajectory prediction using spatially aware deep attention models},
  author={Varshneya, Daksh and Srinivasaraghavan, G},
  eprint={1705.09436},
  year={2017},
  archivePrefix = {arXiv},
}

@article{Vaswani17,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {Neural Information Processing Systems},
  year      = {2017}
}

@article{Veerapaneni2019op3,
	title={Entity Abstraction in Visual Model-Based Reinforcement Learning},
	author={Rishi Veerapaneni and John D. Co-Reyes and Michael Chang and Michael Janner and Chelsea Finn and Jiajun Wu and Joshua B. Tenenbaum and Sergey Levine},
	archivePrefix={arXiv},
	year={2019},
	eprint={1910.12827},
}

@inproceedings{Vinyals2014,
abstract = {Syntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation.},
archivePrefix = {arXiv},
arxivId = {1412.7449},
author = {Vinyals, Oriol and Kaiser, Lukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey},
booktitle = {Advances in Neural Information Processing Systems},
optdoi = {10.1146/annurev.neuro.26.041002.131047},
eprint = {1412.7449},
optisbn = {9789078328414},
optissn = {10495258},
pmid = {14527267},
title = {{Grammar as a Foreign Language}},
opturl = {http://arxiv.org/abs/1409.0473 http://arxiv.org/abs/1412.7449},
year = {2015}
}

@inproceedings{Vot2016,
abstract = {The Visual Object Tracking challenge 2015, VOT2015, aims at comparing short-term single-object visual trackers that do not apply pre-learned models of object appearance. Results of 62 trackers are presented. The number of tested trackers makes VOT 2015 the largest benchmark on short-term tracking to date. For each participating tracker, a short description is provided in the appendix. Features of the VOT2015 challenge that go beyond its VOT2014 pre-decessor are: (i) a new VOT2015 dataset twice as large as in VOT2014 with full annotation of targets by rotated bounding boxes and per-frame attribute, (ii) extensions of the VOT2014 evaluation methodology by introduction of a new performance measure. The dataset, the evaluation kit as well as the results are publicly available at the challenge website 1 .},
author = {Kristan, Matej and Matas, Jiri and Leonardis, Ale{\v{s}} and Felsberg, Michael and Cehovin, Luk and Fern{\'{a}}ndez, Gustavo and Voj{\'{i}}, Tom{\'{a}}{\v{s}} and H{\"{a}}ger, Gustav and Nebehay, Georg and Pflugfelder, Roman and Gupta, Abhinav and Bibi, Adel and Luke{\v{z}}i{\v{c}}, Alan and Garcia-Martin, Alvaro and Saffari, Amir and Torr, Philip H S and Wang, Qiang and Martin-Nieto, Rafael and Pelapur, Rengarajan and Bowden, Richard and Zhu, Chun and Becker, Stefan and Duffner, Stefan and Hicks, Stephen L and Golodetz, Stuart and Choi, Sunglok and Wu, Tianfu and Mauthner, Thomas and Pridmore, Tony and Hu, Weiming and H{\"{u}}bner, Wolfgang and Wang, Xiaomeng and Li, Xin and Shi, Xinchu and Zhao, Xu and Mei, Xue and Shizeng, Yao and Hua, Yang and Li, Yang and Lu, Yang and Li, Yuezun and Chen, Zhaoyun and Huang, Zehua and Chen, Zhe and Zhang, Zhe and He, Zhenyu and Hong, Zhibin},
booktitle = {European Conference on Computer Vision Workshop},
title = {{The Visual Object Tracking Vot2016 challenge results}},
opturl = {http://personal.ee.surrey.ac.uk/Personal/R.Bowden/publications/2016/Lebeda{\_}Vot2016.pdf},
year = {2016}
}

@article{Wagstaff2019,
  author    = {Edward Wagstaff and
               Fabian B. Fuchs and
               Martin Engelcke and
               Ingmar Posner and
               Michael A. Osborne},
  title     = {On the Limitations of Representing Functions on Sets},
  journal   = {International Conference on Machine Learning},
  year      = {2019},
}

@inproceedings{Wang2018optimization,
  title={An Optimization View on Dynamic Routing Between Capsules},
  author={Wang, Dilin and Liu, Qiang},
  booktitle={International Conference on Learning Representations Workshop},
  year={2018}
}

@article{Watters2017,
author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter W and Pascanu, Razvan and Tacchetti, Andrea},
journal = {Advances in Neural Information Processing Systems},
title = {{Visual Interaction Networks: Learning a Physics Simulator from Video}},
year = {2017}
}


@inproceedings{Weber2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Weber, Th{\'e}ophane and Racani{\`e}re, S{\'e}bastien and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo Jimenez and Badia, Adria Puigdom{\`e}nech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{Wen15,
  author    = {Longyin Wen and
               Dawei Du and
               Zhaowei Cai and
               Zhen Lei and
               Ming{-}Ching Chang and
               Honggang Qi and
               Jongwoo Lim and
               Ming{-}Hsuan Yang and
               Siwei Lyu},
  title     = {{DETRAC:} {A} New Benchmark and Protocol for Multi-Object Tracking},
  journal   = {arXiv},
  volume    = {1511.04136},
  year      = {2015},
  timestamp = {Mon, 13 Aug 2018 16:49:08 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Williams1992simple,
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author = {Williams, Ronald J},
  journal = {Machine learning},
  volume = {8},
  number = {3-4},
  pages = {229--256},
  year = {1992},
  publisher = {Springer}
}

@article{Xiang2015,
author = {Xiang, Yu and Alahi, Alexandre and Savarese, Silvio},
journal = {IEEE International Conference on Computer Vision},
title = {{Learning to Track: Online Multi- Object Tracking by Decision Making Multi-Object Tracking}},
year = {2015}
}

@inproceedings{Xiao2016track,
  title={Track and segment: An iterative unsupervised approach for video object proposals},
  author={Xiao, Fanyi and Jae Lee, Yong},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  pages={933--942},
  year={2016}
}

@inproceedings{Xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2048--2057},
  year={2015}
}

@inproceedings{Yamaguchi2011you,
  title={Who are you with and where are you going?},
  author={Yamaguchi, Kota and Berg, Alexander C and Ortiz, Luis E and Berg, Tamara L},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2011}
}

@article{Yi2019cleverer,
	title={CLEVRER: CoLlision Events for Video REpresentation and Reasoning},
	author={Kexin Yi and Chuang Gan and Yunzhu Li and Pushmeet Kohli and Jiajun Wu and Antonio Torralba and Joshua B. Tenenbaum},
	archivePrefix={arXiv},
	year={2019},
	eprint={1910.01442}
}

@article{Younger1967recognition,
  title={Recognition and parsing of context-free languages in time n3},
  author={Younger, Daniel H},
  journal={Information and control},
  volume={10},
  number={2},
  pages={189--208},
  year={1967},
  publisher={Elsevier}
}

@inproceedings{Yu2016unitbox,
abstract = {In present object detection systems, the deep convolutional neural networks (CNNs) are utilized to predict bounding boxes of object candidates, and have gained performance advantages over the traditional region proposal methods. However, existing deep CNN methods assume the object bounds to be four independent variables, which could be regressed by the l2 loss separately. Such an oversimplified assumption is contrary to the well-received observation, that those variables are correlated, resulting to less accurate localization. To address the issue, we firstly introduce a novel Intersection over Union (IoU) loss function for bounding box prediction, which regresses the four bounds of a predicted box as a whole unit. By taking the advantages of IoU loss and deep fully convolutional networks, the UnitBox is introduced, which performs accurate and efficient localization, shows robust to objects of varied shapes and scales, and converges fast. We apply UnitBox on face detection task and achieve the best performance among all published methods on the FDDB benchmark.},
archivePrefix = {arXiv},
arxivId = {1608.01471},
author = {Yu, Jiahui and Jiang, Yuning and Wang, Zhangyang and Cao, Zhimin and Huang, Thomas},
booktitle = {Proc. 2016 ACM Multimed. Conf.},
optdoi = {10.1145/2964284.2967274},
eprint = {1608.01471},
optisbn = {978-1-4503-3603-1},
keywords = {IoU loss,bounding box prediction,object detection},
organization = {ACM},
pages = {516--520},
title = {{UnitBox: An Advanced Object Detection Network}},
opturl = {http://optdoi.acm.org/10.1145/2964284.2967274},
year = {2016}
}

@inproceedings{Zaheer2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06114v3},
author = {Zaheer, Manzil and Kottur, Satwik and Ravanbhakhsh, Siamak and P{\'{o}}czos, Barnab{\'{a}}s and Salakhutdinov, Ruslan and Smola, Alexander},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {arXiv:1703.06114v3},
title = {{Deep Sets}},
year = {2017}
}


@article{Zhang2008,
author = {Zhang, Li and Li, Yuan and Nevatia, Ramakant},
journal = {IEEE Conference on Computer Vision and Pattern Recognition},
title = {{Global data association for multi-object tracking using network flows}},
year = {2008}
}

@inproceedings{Zhang2018fast,
  title={Fast Dynamic Routing Based on Weighted Kernel Density Estimation},
  author={Zhang, Suofei and Zhou, Quan and Wu, Xiaofu},
  booktitle={International Symposium on Artificial Intelligence and Robotics},
  pages={301--309},
  year={2018},
%   organization={Springer}
}

@article{Zhao20183d,
  title={3D Point-Capsule Networks},
  author={Zhao, Yongheng and Birdal, Tolga and Deng, Haowen and Tombari, Federico},
  journal={arXiv preprint arXiv:1812.10775},
  year={2018}
}

@inproceedings{KTHActivityRecognition,
	abstract = {Local space-time features capture local events in video and can be adapted to the size, the frequency and the veloc-ity of moving patterns. In this paper we demonstrate how such features can be used for recognizing complex motion patterns. We construct video representations in terms of lo-cal space-time features and integrate such representations with SVM classification schemes for recognition. For the purpose of evaluation we introduce a new video database containing 2391 sequences of six human actions performed by 25 people in four different scenarios. The presented re-sults of action recognition justify the proposed method and demonstrate its advantage compared to other relative ap-proaches for action recognition.},
	archivePrefix = {arXiv},
	arxivId = {1505.04868},
	author = {Schuldt, Christian and Laptev, Ivan and Caputo, Barbara},
	booktitle = {ICPR},
	optdoi = {10.1109/ICPR.2004.1334462},
	eprint = {1505.04868},
	optisbn = {0769521282},
	optissn = {10514651},
	pmid = {12171414},
	publisher = {IEEE},
	title = {{Recognizing human actions: A local SVM approach}},
	opturl = {http://ieeexplore.ieee.org/document/1334462/},
	year = {2004}
}

@inproceedings{Hu2017imsat,
	title={Learning Discrete Representations via Information Maximizing Self-augmented Training},
	author={Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},
	booktitle={International Conference on Machine Learning},
	pages={1558--1567},
	year={2017},
	%   organization={JMLR. org}
}

@inproceedings{Oyallon2015deep,
	title={Deep Roto-Translation Scattering for Object Classification},
	author={Oyallon, Edouard and Mallat, St{\'e}phane},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2865--2873},
	year={2015}
}

@inproceedings{Su2016crowd,
	title={Crowd Scene Understanding with Coherent Recurrent Neural Networks},
	author={Su, Hang and Dong, Yinpeng and Zhu, Jun and Ling, Haibin and Zhang, Bo},
	booktitle={International Joint Conferences on Artificial Intelligence},
	year={2016}
}

@article{Fernando2017soft,
	title={Soft + hardwired attention: An lstm framework for human trajectory prediction and abnormal event detection},
	author={Fernando, Tharindu and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
	journal={Neural networks},
	year={2017}
}

@inproceedings{Sadeghian2019sophie,
	title={Sophie: An attentive gan for predicting paths compliant to social and physical constraints},
	author={Sadeghian, Amir and Kosaraju, Vineet and Sadeghian, Ali and Hirose, Noriaki and Rezatofighi, Hamid and Savarese, Silvio},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2019}
}

@article{Ramachandran2019standalone,
	title={Stand-Alone Self-Attention in Vision Models},
	author={Prajit Ramachandran and Niki Parmar and Ashish Vaswani and Irwan Bello and Anselm Levskaya and Jonathon Shlens},
	archivePrefix={arXiv},
	year={2019},
	eprint={1906.05909}
}

@book{Rock73,
	title={Orientation and form},
	author={Rock, Irvin},
	year={1973},
	publisher={Academic Press}
}

@article{Ning2017,
	author = {Ning, Guanghan and Zhang, Zhi and Huang, Chen and He, Zhihai and Ren, Xiaobo and Wang, Haohong},
	journal = {IEEE International Symposium on Circuits and Systems},
	title = {{Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking}},
	year = {2017}
}

@inproceedings{Nam2016,
	author = {Nam, Hyeonseob and Han, Bohyung},
	journal = {IEEE Conference on Computer Vision and Pattern Recognition},
	title = {{Learning Multi-Domain Convolutional Neural Networks for Visual Tracking}},
	year = {2016}
}

@article{Babaeizadeh2017stochastic,
	title={Stochastic Variational Video Prediction},
	author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
	journal={CoRR},
	year={2017},
	archivePrefix = {arXiv},
	eprint = {1710.11252},
}

@article{Baker2019tooluse,
	title={Emergent Tool Use From Multi-Agent Autocurricula},
	author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
	archivePrefix = {arXiv},
	year={2019},
	eprint={1909.07528}
}

@inproceedings{Denton2018stochastic,
	title={Stochastic Video Generation with a Learned Prior},
	author={Denton, Emily and Fergus, Rob},
	booktitle={International Conference on Machjine Learning},
	year={2018}
}

@inproceedings{Keuper2018motion,
	title={Motion segmentation \& multiple object tracking by correlation co-clustering},
	author={Keuper, Margret and Tang, Siyu and Andres, Bjorn and Brox, Thomas and Schiele, Bernt},
	booktitle={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2018},
	publisher={IEEE}
}