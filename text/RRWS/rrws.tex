




\chapter{Revisiting Reweighted Wake-Sleep for Models with Stochastic Control Flow}


\begin{abstract}
  \Glspl{SCFM} are a class of generative models that involve branching on choices from discrete random variables.
  Amortized gradient-based learning of \glspl{SCFM} is challenging as most approaches targeting discrete variables rely on their continuous relaxations---which can be intractable in \glspl{SCFM}, as branching on relaxations requires evaluating \emph{all} (exponentially many) branching paths.
  Tractable alternatives mainly combine \acrshort{REINFORCE} with complex control-variate schemes to improve the variance of na\"ive estimators.
  Here, we revisit the \gls{RWS}~\citep{Bornschein2015reweighted} algorithm, and through extensive evaluations, show that it outperforms current state-of-the-art methods in learning \glspl{SCFM}.
  Further, in contrast to the \acrlong{IWAE}, we observe that \gls{RWS} learns better models \emph{and} inference networks with increasing numbers of particles.
  Our results suggest that \gls{RWS} is a competitive, often preferable, alternative for learning \glspl{SCFM}.
\end{abstract}
    
\input{text/RRWS/introduction}
\input{text/RRWS/background}
\input{text/RRWS/method}
\input{text/RRWS/experiments}
\input{text/RRWS/conclusion}

\subsubsection*{Acknowledgments}

TAL's research leading to these results is supported by EPSRC DTA and Google (project code DF6700) studentships.
AK's and YWT's research leading to these results are supported by funding from the European Research Council under the European Unionâ€™s Seventh Framework Programme (FP7/2007-2013) ERC grant agreement no. 617071.
NS is supported by EPSRC/MURI grant EP/N019474/1.
FW's research leading is supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1; DARPA PPAML through the U.S. AFRL under Cooperative Agreement FA8750-14-2-0006; Intel and DARPA D3M, under Cooperative Agreement FA8750-17-2-0093.


\begin{subappendices}
	\input{text/RRWS/appendix}
\end{subappendices}
