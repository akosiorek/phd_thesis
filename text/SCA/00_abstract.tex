%\vspace*{-1em}
%\begin{abstract}
%\vspace*{-.5em}
% 
% An object can be seen as a geometrically organized set of interrelated parts.
% A system that makes explicit use of these geometric relationships to recognize objects should be naturally robust to changes in viewpoint, because the intrinsic geometric relationships are viewpoint-invariant.
% We describe an unsupervised version of capsule networks, in which a neural encoder, which looks at all of the parts, is used to infer the presence and poses of object capsules.
% The encoder is trained by backpropagating through a decoder, which predicts the pose of each already discovered part using a mixture of pose predictions. 
% The parts are discovered directly from an image, in a similar manner, by using a neural encoder, which infers parts and their affine transformations.
% The corresponding decoder models each image pixel as a mixture of predictions made by affine-transformed parts.
% We learn object- and their part-capsules on unlabeled data, and then cluster the vectors of presences of object capsules.
% When told the names of these clusters, we achieve state-of-the-art results for unsupervised classification on \textsc{svhn} (55\%) and near state-of-the-art on \textsc{mnist} (98.5\%).
% 
Objects are composed of a set of geometrically organized parts. We introduce an unsupervised capsule autoencoder (\textsc{scae}), which explicitly uses geometric relationships between parts to reason about objects.
 Since these relationships do not depend on the viewpoint, our model is robust to viewpoint changes.
\textsc{Scae} consists of two stages.
In the first stage, the model predicts presences and poses of part templates directly from the image and tries to reconstruct the image by appropriately arranging the templates.
In the second stage, \textsc{scae} predicts parameters of a few object capsules, which are then used to reconstruct part poses.
Inference in this model is amortized and performed by off-the-shelf neural encoders, unlike in previous capsule networks.
We find that object capsule presences are highly informative of the object class, which leads to state-of-the-art results for unsupervised classification on \textsc{svhn} (55\%) and \textsc{mnist} (98.7\%).
%\end{abstract}